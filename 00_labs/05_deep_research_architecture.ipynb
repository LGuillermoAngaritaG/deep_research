{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8fcf9b",
   "metadata": {},
   "source": [
    "# Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600ccf1",
   "metadata": {},
   "source": [
    "Use Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c53afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_settings import BaseSettings\n",
    "import os\n",
    "from pydantic_ai import RunContext\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"pydantic\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"asyncio\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"web_deep_researcher\")\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY: str\n",
    "    MODEL_NAME: str\n",
    "    CONTEXT7_API_KEY: str\n",
    "    TAVILY_API_KEY: str\n",
    "    class Config:\n",
    "        #ignore extra fields\n",
    "        extra = \"ignore\"\n",
    "        env_file = \".env\"\n",
    "        \n",
    "class PlanOutput(BaseModel):\n",
    "    outline: str = Field(description=\"The outline of the report\")\n",
    "    \n",
    "class GetHumanInTheLoopInput(BaseModel):\n",
    "    \"\"\"Input for getting more information\"\"\"\n",
    "    questions: str\n",
    "\n",
    "class GetHumanInTheLoopOutput(BaseModel):\n",
    "    \"\"\"Response for getting more information\"\"\"\n",
    "    answer: str\n",
    "    \n",
    "class GetPlanInput(BaseModel):\n",
    "    \"\"\"Input for getting a plan\"\"\"\n",
    "    instructions_for_plan: str\n",
    "\n",
    "class GetPlanOutput(BaseModel):\n",
    "    \"\"\"Response for getting a plan\"\"\"\n",
    "    plan: str\n",
    "    \n",
    "class reportOutput(BaseModel):\n",
    "    report: str\n",
    "    \n",
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"The title/subtitle of the section\")\n",
    "    content: str = Field(description=\"The content of the section, that answers the title of the section\")\n",
    "    references: str = Field(description=\"The references of the section, that are used to answer the title of the section\")\n",
    "\n",
    "class documentationOutput(BaseModel):\n",
    "    sections: list[Section] = Field(description=\"The sections of the report, that are used to answer the outline\")\n",
    "    \n",
    "class web_deep_researcher:\n",
    "    def __init__(self):\n",
    "        self.settings = Settings()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = self.settings.GOOGLE_API_KEY\n",
    "    \n",
    "    async def execute(self, question:str):\n",
    "        # Create the plan\n",
    "        logger.info(f\"Creating the plan for the question: {question}\")\n",
    "        plan = await self.plan(question)\n",
    "        # Get the information\n",
    "        logger.info(f\"Getting the information for the plan: {plan}\")\n",
    "        information = await self.get_information(plan)\n",
    "        # Get the report\n",
    "        logger.info(f\"Getting the report for the information: {information}\")\n",
    "        report = await self.get_report(information, plan)\n",
    "        return report\n",
    "    # Define the Planning Agent\n",
    "    async def plan(self, question:str):\n",
    "        planning_agent = Agent(\n",
    "            model=self.settings.MODEL_NAME,\n",
    "            system_prompt=\"\"\"You are a planning assistant. Your Job is to create an outline for a report for an user. You have access to tools to help you answer questions.\n",
    "        1. Assess which tool you should use to answer the question.\n",
    "        2. Use get_human_in_the_loop to get user input in case of ambiguity. Provide your question.\n",
    "        3. Use create_plan to create a plan based on what you understand about what the user is asking for. The default outline is the following:\n",
    "            - Summary \n",
    "            - Introduction\n",
    "            - Sections and subsections\n",
    "            - Conclusion\n",
    "            - References\n",
    "        4. If you think the question is too complex or not relevant, first use get_human_in_the_loop to get user input. if user input is ambiguous, then respond with 'I don't know how to help you with that'.\n",
    "        Finally, respond once you have a final answer.\"\"\",\n",
    "            output_type=PlanOutput\n",
    "        )\n",
    "        # Tools\n",
    "        @planning_agent.tool\n",
    "        async def get_plan(_: RunContext[GetPlanInput], instructions_for_plan: str) -> GetPlanOutput:\n",
    "            outline_agent = Agent(self.settings.MODEL_NAME,\n",
    "                        instructions=\"You are an experienced planner for a research project, you will be given a query from the user and you need to make an outline of the report to give the user about it, and what to search for in the web in order to create the report\",\n",
    "                        output_type=GetPlanOutput)\n",
    "            result = await outline_agent.run(instructions_for_plan)\n",
    "            return GetPlanOutput(plan=result.output.plan)\n",
    "        \n",
    "        @planning_agent.tool\n",
    "        def get_human_in_the_loop(_: RunContext[GetHumanInTheLoopInput], question: str) -> GetHumanInTheLoopOutput:\n",
    "            input_str = input(f\"Please provide your input for the question > '{question}': \")\n",
    "            return GetHumanInTheLoopOutput(answer=input_str)\n",
    "        \n",
    "        nodes = []\n",
    "        # Run the Planning Agent\n",
    "        async with planning_agent.iter(\n",
    "            question,\n",
    "        ) as agent_run:\n",
    "            async for node in agent_run:\n",
    "                # Each node represents a step in the agent's execution\n",
    "                logger.info(f\"Node: {node}\")\n",
    "                nodes.append(node)\n",
    "                \n",
    "        result = nodes[-1].data.output.outline\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    # Define the Research Agent\n",
    "    async def get_information(self, plan:str):\n",
    "        tavily_server = MCPServerStreamableHTTP(\n",
    "            url =f'https://mcp.tavily.com/mcp/?tavilyApiKey={self.settings.TAVILY_API_KEY}'\n",
    "        )\n",
    "        mcp_agent = Agent(self.settings.MODEL_NAME, toolsets=[tavily_server], \n",
    "            instructions=\"\"\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\n",
    "\n",
    "                1. Review the provided outline\n",
    "\n",
    "                2. For each section and subsection in the outline:\n",
    "                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\n",
    "                b. Review the search results and identify the most relevant and reliable sources.\n",
    "                c. After fetching the content, analyze and summarize the information relevant to the outline section.\n",
    "\n",
    "                3. Write the report section by section, following the structure of the outline. For each section:\n",
    "                a. Provide a brief introduction to the topic.\n",
    "                b. Include relevant information gathered from your research.\n",
    "                c. Ensure that the content is well-organized and flows logically.\n",
    "                d. Use appropriate transitions between subsections and main sections.\n",
    "\n",
    "                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\n",
    "                - The title of the webpage or article\n",
    "                - The author (if available)\n",
    "                - The website name\n",
    "                - The URL\n",
    "                - The date you accessed the information\n",
    "                \"\"\",\n",
    "                    output_type=documentationOutput\n",
    "            )\n",
    "        # Run the Research Agent\n",
    "        async with mcp_agent:  \n",
    "            nodes = []\n",
    "            async with mcp_agent.iter(\n",
    "                f\"The outline of the report is: {plan}\",\n",
    "            ) as agent_run:\n",
    "                async for node in agent_run:\n",
    "                    # Each node represents a step in the agent's execution\n",
    "                    logger.info(f\"Node: {node}\")\n",
    "                    nodes.append(node)\n",
    "        result = nodes[-1].data.output.sections\n",
    "        return result\n",
    "    \n",
    "    # Run the Writer Agent\n",
    "    async def get_report(self, information:list[Section], plan:str):\n",
    "        writer_agent = Agent(self.settings.MODEL_NAME,\n",
    "                instructions=\"You are a writer, you write a report about a given outline, you use the information provided as well as your own knowledge to write the report\",\n",
    "                        output_type=reportOutput\n",
    "        )\n",
    "        result = await writer_agent.run(f\"\"\"Write a report about the following outline: {plan}\n",
    "        A Researcher has found the following information for each section: {information}\n",
    "        Please use this to create a comprehesive report\"\"\")\n",
    "        return result.output.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd4b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:web_deep_researcher:Creating the plan for the question: how can I use pydantic-ai\n",
      "INFO:web_deep_researcher:Node: UserPromptNode(user_prompt='how can I use pydantic-ai', instructions=None, instructions_functions=[], system_prompts=(\"You are a planning assistant. Your Job is to create an outline for a report for an user. You have access to tools to help you answer questions.\\n        1. Assess which tool you should use to answer the question.\\n        2. Use get_human_in_the_loop to get user input in case of ambiguity. Provide your question.\\n        3. Use create_plan to create a plan based on what you understand about what the user is asking for. The default outline is the following:\\n            - Summary \\n            - Introduction\\n            - Sections and subsections\\n            - Conclusion\\n            - References\\n        4. If you think the question is too complex or not relevant, first use get_human_in_the_loop to get user input. if user input is ambiguous, then respond with 'I don't know how to help you with that'.\\n        Finally, respond once you have a final answer.\",), system_prompt_functions=[], system_prompt_dynamic_functions={})\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[SystemPromptPart(content=\"You are a planning assistant. Your Job is to create an outline for a report for an user. You have access to tools to help you answer questions.\\n        1. Assess which tool you should use to answer the question.\\n        2. Use get_human_in_the_loop to get user input in case of ambiguity. Provide your question.\\n        3. Use create_plan to create a plan based on what you understand about what the user is asking for. The default outline is the following:\\n            - Summary \\n            - Introduction\\n            - Sections and subsections\\n            - Conclusion\\n            - References\\n        4. If you think the question is too complex or not relevant, first use get_human_in_the_loop to get user input. if user input is ambiguous, then respond with 'I don't know how to help you with that'.\\n        Finally, respond once you have a final answer.\", timestamp=datetime.datetime(2025, 9, 3, 19, 43, 45, 815224, tzinfo=datetime.timezone.utc)), UserPromptPart(content='how can I use pydantic-ai', timestamp=datetime.datetime(2025, 9, 3, 19, 43, 45, 815228, tzinfo=datetime.timezone.utc))]))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='get_human_in_the_loop', args={'question': \"It looks like you're asking a question about how to use 'pydantic-ai'. I can help create an outline for a report. Would you like me to create a report outline about 'pydantic-ai' or were you asking a different kind of question?\"}, tool_call_id='pyd_ai_78bb62f653b144829266b37ed61c1b26')], usage=RequestUsage(input_tokens=326, output_tokens=207, details={'thoughts_tokens': 129, 'text_prompt_tokens': 326}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 43, 47, 831313, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='c5q4aMusNJmkqtsPv-2pyQ8'))\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='get_human_in_the_loop', content=GetHumanInTheLoopOutput(answer='How can I use pydantic-ai to build agents'), tool_call_id='pyd_ai_78bb62f653b144829266b37ed61c1b26', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 17, 720128, tzinfo=datetime.timezone.utc))]))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='get_plan', args={'instructions_for_plan': 'Create a report outline on how to use pydantic-ai to build agents.'}, tool_call_id='pyd_ai_df64681709ba4069acd5e7d8ecd62bb9')], usage=RequestUsage(input_tokens=442, output_tokens=115, details={'thoughts_tokens': 81, 'text_prompt_tokens': 442}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 18, 962572, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='kpq4aICBPMOhqtsPhMfdwQw'))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='get_plan', content=GetPlanOutput(plan='Report Outline: How to Use Pydantic-AI to Build Agents\\n\\nI. Introduction\\n    A. The rise of AI Agents and the need for reliable interactions.\\n    B. Introduction to Pydantic-AI: What it is, its core purpose (data validation, parsing, and structuring).\\n    C. Thesis Statement: How Pydantic-AI enhances agent development by ensuring structured, reliable data exchange.\\n    D. Report Goals: What this report will cover.\\n\\nII. Understanding Pydantic-AI\\n    A. Core Concepts of Pydantic:\\n        1. `BaseModel` for data schema definition.\\n        2. Type hinting and automatic validation.\\n        3. Data parsing and serialization.\\n    B. Pydantic-AI Specifics (if distinct from core Pydantic relevant to AI):\\n        1. Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).\\n        2. How it helps enforce LLM output formats.\\n    C. Simple Examples: Defining a basic data structure with Pydantic-AI.\\n\\nIII. Fundamentals of AI Agents\\n    A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n    B. Key Components of an Agent:\\n        1. Large Language Models (LLMs).\\n        2. Tools/Functions: How agents interact with the external world.\\n        3. Memory: Short-term and long-term context retention.\\n        4. Reasoning and Planning.\\n        5. Action and Execution.\\n    C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nIV. The Synergy: Why Pydantic-AI for Agent Development?\\n    A. The Problem: Unreliable, unstructured outputs from LLMs.\\n    B. The Solution: Pydantic-AI for guaranteed data structures.\\n    C. Key Benefits:\\n        1. **Reliable Tool Definitions:** Defining function signatures and arguments.\\n        2. **Robust Response Parsing:** Ensuring agent outputs (actions, thoughts, observations) are consistently formatted.\\n        3. **Structured Agent State/Memory:** Managing conversation history, learned facts, and goals.\\n        4. **Reduced Boilerplate & Improved Readability.**\\n        5. **Enhanced Debugging and Error Handling.**\\n\\nV. Practical Guide: Building Agents with Pydantic-AI\\n    A. **Defining Agent Tools with Pydantic-AI:**\\n        1. Using `BaseModel` to describe tool input parameters.\\n        2. Examples: A search tool, a calculator tool, defined with Pydantic-AI.\\n        3. Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).\\n    B. **Structuring Agent Responses and Outputs:**\\n        1. Guiding LLMs to produce Pydantic-compatible JSON.\\n        2. Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).\\n        3. Handling parsing errors and retries.\\n    C. **Managing Agent State and Memory:**\\n        1. Using Pydantic models for storing conversation turns, facts, or observations.\\n        2. Example: A `ConversationHistory` model or an `AgentState` model.\\n    D. **Integration with Popular Agent Frameworks (Illustrative Examples):**\\n        1. How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).\\n        2. How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).\\n\\nVI. Advanced Concepts & Best Practices\\n    A. Nested Pydantic Models for Complex Agent Structures.\\n    B. Custom Validators for Specific Agent Logic.\\n    C. Error Handling and Fallback Mechanisms with Pydantic-AI.\\n    D. Testing Agent Behavior with Pydantic-AI Assertions.\\n    E. Performance Considerations for High-Throughput Agents.\\n\\nVII. Conclusion\\n    A. Recap of Pydantic-AI\\'s role in building robust and reliable AI agents.\\n    B. Future outlook for structured data in agent development.\\n    C. Final thoughts on efficiency and maintainability.\\n\\n\\nSearch Queries for Report Content:\\n\\n1.  \"Pydantic-AI documentation for agents\"\\n2.  \"Pydantic-AI for LLM structured output\"\\n3.  \"How to use Pydantic-AI with LangChain for tool definition\"\\n4.  \"Pydantic-AI `response_model` for agents\"\\n5.  \"Pydantic-AI examples for agent memory management\"\\n6.  \"Building conversational agents with Pydantic-AI\"\\n7.  \"Pydantic-AI for function calling in LLMs\"\\n8.  \"Structured data validation for AI agents with Pydantic-AI\"\\n9.  \"Pydantic-AI vs Pydantic for AI applications\"\\n10. \"Best practices for Pydantic-AI in agent development\"'), tool_call_id='pyd_ai_df64681709ba4069acd5e7d8ecd62bb9', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 30, 592494, tzinfo=datetime.timezone.utc))]))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'outline': 'Report Outline: How to Use Pydantic-AI to Build Agents\\n\\nI. Introduction\\n    A. The rise of AI Agents and the need for reliable interactions.\\n    B. Introduction to Pydantic-AI: What it is, its core purpose (data validation, parsing, and structuring).\\n    C. Thesis Statement: How Pydantic-AI enhances agent development by ensuring structured, reliable data exchange.\\n    D. Report Goals: What this report will cover.\\n\\nII. Understanding Pydantic-AI\\n    A. Core Concepts of Pydantic:\\n        1. `BaseModel` for data schema definition.\\n        2. Type hinting and automatic validation.\\n        3. Data parsing and serialization.\\n    B. Pydantic-AI Specifics (if distinct from core Pydantic relevant to AI):\\n        1. Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).\\n        2. How it helps enforce LLM output formats.\\n    C. Simple Examples: Defining a basic data structure with Pydantic-AI.\\n\\nIII. Fundamentals of AI Agents\\n    A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n    B. Key Components of an Agent:\\n        1. Large Language Models (LLMs).\\n        2. Tools/Functions: How agents interact with the external world.\\n        3. Memory: Short-term and long-term context retention.\\n        4. Reasoning and Planning.\\n        5. Action and Execution.\\n    C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nIV. The Synergy: Why Pydantic-AI for Agent Development?\\n    A. The Problem: Unreliable, unstructured outputs from LLMs.\\n    B. The Solution: Pydantic-AI for guaranteed data structures.\\n    C. Key Benefits:\\n        1. **Reliable Tool Definitions:** Defining function signatures and arguments.\\n        2. **Robust Response Parsing:** Ensuring agent outputs (actions, thoughts, observations) are consistently formatted.\\n        3. **Structured Agent State/Memory:** Managing conversation history, learned facts, and goals.\\n        4. **Reduced Boilerplate & Improved Readability.**\\n        5. **Enhanced Debugging and Error Handling.**\\n\\nV. Practical Guide: Building Agents with Pydantic-AI\\n    A. **Defining Agent Tools with Pydantic-AI:**\\n        1. Using `BaseModel` to describe tool input parameters.\\n        2. Examples: A search tool, a calculator tool, defined with Pydantic-AI.\\n        3. Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).\\n    B. **Structuring Agent Responses and Outputs:**\\n        1. Guiding LLMs to produce Pydantic-compatible JSON.\\n        2. Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).\\n        3. Handling parsing errors and retries.\\n    C. **Managing Agent State and Memory:**\\n        1. Using Pydantic models for storing conversation turns, facts, or observations.\\n        2. Example: A `ConversationHistory` model or an `AgentState` model.\\n    D. **Integration with Popular Agent Frameworks (Illustrative Examples):**\\n        1. How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).\\n        2. How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).\\n\\nVI. Advanced Concepts & Best Practices\\n    A. Nested Pydantic Models for Complex Agent Structures.\\n    B. Custom Validators for Specific Agent Logic.\\n    C. Error Handling and Fallback Mechanisms with Pydantic-AI.\\n    D. Testing Agent Behavior with Pydantic-AI Assertions.\\n    E. Performance Considerations for High-Throughput Agents.\\n\\nVII. Conclusion\\n    A. Recap of Pydantic-AI\\'s role in building robust and reliable AI agents.\\n    B. Future outlook for structured data in agent development.\\n    C. Final thoughts on efficiency and maintainability.\\n\\n\\nSearch Queries for Report Content:\\n\\n1.  \"Pydantic-AI documentation for agents\"\\n2.  \"Pydantic-AI for LLM structured output\"\\n3.  \"How to use Pydantic-AI with LangChain for tool definition\"\\n4.  \"Pydantic-AI `response_model` for agents\"\\n5.  \"Pydantic-AI examples for agent memory management\"\\n6.  \"Building conversational agents with Pydantic-AI\"\\n7.  \"Pydantic-AI for function calling in LLMs\"\\n8.  \"Structured data validation for AI agents with Pydantic-AI\"\\n9.  \"Pydantic-AI vs Pydantic for AI applications\"\\n10. \"Best practices for Pydantic-AI in agent development\"'}, tool_call_id='pyd_ai_5ff953e806a14f6dae862e1b162db52a')], usage=RequestUsage(input_tokens=1615, output_tokens=1250, details={'thoughts_tokens': 117, 'text_prompt_tokens': 1615}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 36, 786205, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='pJq4aNPkMcOhqtsPhMfdwQw'))\n",
      "INFO:web_deep_researcher:Node: End(data=FinalResult(output=PlanOutput(outline='Report Outline: How to Use Pydantic-AI to Build Agents\\n\\nI. Introduction\\n    A. The rise of AI Agents and the need for reliable interactions.\\n    B. Introduction to Pydantic-AI: What it is, its core purpose (data validation, parsing, and structuring).\\n    C. Thesis Statement: How Pydantic-AI enhances agent development by ensuring structured, reliable data exchange.\\n    D. Report Goals: What this report will cover.\\n\\nII. Understanding Pydantic-AI\\n    A. Core Concepts of Pydantic:\\n        1. `BaseModel` for data schema definition.\\n        2. Type hinting and automatic validation.\\n        3. Data parsing and serialization.\\n    B. Pydantic-AI Specifics (if distinct from core Pydantic relevant to AI):\\n        1. Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).\\n        2. How it helps enforce LLM output formats.\\n    C. Simple Examples: Defining a basic data structure with Pydantic-AI.\\n\\nIII. Fundamentals of AI Agents\\n    A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n    B. Key Components of an Agent:\\n        1. Large Language Models (LLMs).\\n        2. Tools/Functions: How agents interact with the external world.\\n        3. Memory: Short-term and long-term context retention.\\n        4. Reasoning and Planning.\\n        5. Action and Execution.\\n    C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nIV. The Synergy: Why Pydantic-AI for Agent Development?\\n    A. The Problem: Unreliable, unstructured outputs from LLMs.\\n    B. The Solution: Pydantic-AI for guaranteed data structures.\\n    C. Key Benefits:\\n        1. **Reliable Tool Definitions:** Defining function signatures and arguments.\\n        2. **Robust Response Parsing:** Ensuring agent outputs (actions, thoughts, observations) are consistently formatted.\\n        3. **Structured Agent State/Memory:** Managing conversation history, learned facts, and goals.\\n        4. **Reduced Boilerplate & Improved Readability.**\\n        5. **Enhanced Debugging and Error Handling.**\\n\\nV. Practical Guide: Building Agents with Pydantic-AI\\n    A. **Defining Agent Tools with Pydantic-AI:**\\n        1. Using `BaseModel` to describe tool input parameters.\\n        2. Examples: A search tool, a calculator tool, defined with Pydantic-AI.\\n        3. Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).\\n    B. **Structuring Agent Responses and Outputs:**\\n        1. Guiding LLMs to produce Pydantic-compatible JSON.\\n        2. Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).\\n        3. Handling parsing errors and retries.\\n    C. **Managing Agent State and Memory:**\\n        1. Using Pydantic models for storing conversation turns, facts, or observations.\\n        2. Example: A `ConversationHistory` model or an `AgentState` model.\\n    D. **Integration with Popular Agent Frameworks (Illustrative Examples):**\\n        1. How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).\\n        2. How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).\\n\\nVI. Advanced Concepts & Best Practices\\n    A. Nested Pydantic Models for Complex Agent Structures.\\n    B. Custom Validators for Specific Agent Logic.\\n    C. Error Handling and Fallback Mechanisms with Pydantic-AI.\\n    D. Testing Agent Behavior with Pydantic-AI Assertions.\\n    E. Performance Considerations for High-Throughput Agents.\\n\\nVII. Conclusion\\n    A. Recap of Pydantic-AI\\'s role in building robust and reliable AI agents.\\n    B. Future outlook for structured data in agent development.\\n    C. Final thoughts on efficiency and maintainability.\\n\\n\\nSearch Queries for Report Content:\\n\\n1.  \"Pydantic-AI documentation for agents\"\\n2.  \"Pydantic-AI for LLM structured output\"\\n3.  \"How to use Pydantic-AI with LangChain for tool definition\"\\n4.  \"Pydantic-AI `response_model` for agents\"\\n5.  \"Pydantic-AI examples for agent memory management\"\\n6.  \"Building conversational agents with Pydantic-AI\"\\n7.  \"Pydantic-AI for function calling in LLMs\"\\n8.  \"Structured data validation for AI agents with Pydantic-AI\"\\n9.  \"Pydantic-AI vs Pydantic for AI applications\"\\n10. \"Best practices for Pydantic-AI in agent development\"'), tool_name='final_result', tool_call_id='pyd_ai_5ff953e806a14f6dae862e1b162db52a'))\n",
      "INFO:web_deep_researcher:Getting the information for the plan: Report Outline: How to Use Pydantic-AI to Build Agents\n",
      "\n",
      "I. Introduction\n",
      "    A. The rise of AI Agents and the need for reliable interactions.\n",
      "    B. Introduction to Pydantic-AI: What it is, its core purpose (data validation, parsing, and structuring).\n",
      "    C. Thesis Statement: How Pydantic-AI enhances agent development by ensuring structured, reliable data exchange.\n",
      "    D. Report Goals: What this report will cover.\n",
      "\n",
      "II. Understanding Pydantic-AI\n",
      "    A. Core Concepts of Pydantic:\n",
      "        1. `BaseModel` for data schema definition.\n",
      "        2. Type hinting and automatic validation.\n",
      "        3. Data parsing and serialization.\n",
      "    B. Pydantic-AI Specifics (if distinct from core Pydantic relevant to AI):\n",
      "        1. Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).\n",
      "        2. How it helps enforce LLM output formats.\n",
      "    C. Simple Examples: Defining a basic data structure with Pydantic-AI.\n",
      "\n",
      "III. Fundamentals of AI Agents\n",
      "    A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\n",
      "    B. Key Components of an Agent:\n",
      "        1. Large Language Models (LLMs).\n",
      "        2. Tools/Functions: How agents interact with the external world.\n",
      "        3. Memory: Short-term and long-term context retention.\n",
      "        4. Reasoning and Planning.\n",
      "        5. Action and Execution.\n",
      "    C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\n",
      "\n",
      "IV. The Synergy: Why Pydantic-AI for Agent Development?\n",
      "    A. The Problem: Unreliable, unstructured outputs from LLMs.\n",
      "    B. The Solution: Pydantic-AI for guaranteed data structures.\n",
      "    C. Key Benefits:\n",
      "        1. **Reliable Tool Definitions:** Defining function signatures and arguments.\n",
      "        2. **Robust Response Parsing:** Ensuring agent outputs (actions, thoughts, observations) are consistently formatted.\n",
      "        3. **Structured Agent State/Memory:** Managing conversation history, learned facts, and goals.\n",
      "        4. **Reduced Boilerplate & Improved Readability.**\n",
      "        5. **Enhanced Debugging and Error Handling.**\n",
      "\n",
      "V. Practical Guide: Building Agents with Pydantic-AI\n",
      "    A. **Defining Agent Tools with Pydantic-AI:**\n",
      "        1. Using `BaseModel` to describe tool input parameters.\n",
      "        2. Examples: A search tool, a calculator tool, defined with Pydantic-AI.\n",
      "        3. Integration with LLM function calling mechanisms (e.g., OpenAI's tools).\n",
      "    B. **Structuring Agent Responses and Outputs:**\n",
      "        1. Guiding LLMs to produce Pydantic-compatible JSON.\n",
      "        2. Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).\n",
      "        3. Handling parsing errors and retries.\n",
      "    C. **Managing Agent State and Memory:**\n",
      "        1. Using Pydantic models for storing conversation turns, facts, or observations.\n",
      "        2. Example: A `ConversationHistory` model or an `AgentState` model.\n",
      "    D. **Integration with Popular Agent Frameworks (Illustrative Examples):**\n",
      "        1. How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).\n",
      "        2. How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).\n",
      "\n",
      "VI. Advanced Concepts & Best Practices\n",
      "    A. Nested Pydantic Models for Complex Agent Structures.\n",
      "    B. Custom Validators for Specific Agent Logic.\n",
      "    C. Error Handling and Fallback Mechanisms with Pydantic-AI.\n",
      "    D. Testing Agent Behavior with Pydantic-AI Assertions.\n",
      "    E. Performance Considerations for High-Throughput Agents.\n",
      "\n",
      "VII. Conclusion\n",
      "    A. Recap of Pydantic-AI's role in building robust and reliable AI agents.\n",
      "    B. Future outlook for structured data in agent development.\n",
      "    C. Final thoughts on efficiency and maintainability.\n",
      "\n",
      "\n",
      "Search Queries for Report Content:\n",
      "\n",
      "1.  \"Pydantic-AI documentation for agents\"\n",
      "2.  \"Pydantic-AI for LLM structured output\"\n",
      "3.  \"How to use Pydantic-AI with LangChain for tool definition\"\n",
      "4.  \"Pydantic-AI `response_model` for agents\"\n",
      "5.  \"Pydantic-AI examples for agent memory management\"\n",
      "6.  \"Building conversational agents with Pydantic-AI\"\n",
      "7.  \"Pydantic-AI for function calling in LLMs\"\n",
      "8.  \"Structured data validation for AI agents with Pydantic-AI\"\n",
      "9.  \"Pydantic-AI vs Pydantic for AI applications\"\n",
      "10. \"Best practices for Pydantic-AI in agent development\"\n",
      "INFO:mcp.client.streamable_http:Negotiated protocol version: 2025-06-18\n",
      "INFO:web_deep_researcher:Node: UserPromptNode(user_prompt='The outline of the report is: Report Outline: How to Use Pydantic-AI to Build Agents\\n\\nI. Introduction\\n    A. The rise of AI Agents and the need for reliable interactions.\\n    B. Introduction to Pydantic-AI: What it is, its core purpose (data validation, parsing, and structuring).\\n    C. Thesis Statement: How Pydantic-AI enhances agent development by ensuring structured, reliable data exchange.\\n    D. Report Goals: What this report will cover.\\n\\nII. Understanding Pydantic-AI\\n    A. Core Concepts of Pydantic:\\n        1. `BaseModel` for data schema definition.\\n        2. Type hinting and automatic validation.\\n        3. Data parsing and serialization.\\n    B. Pydantic-AI Specifics (if distinct from core Pydantic relevant to AI):\\n        1. Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).\\n        2. How it helps enforce LLM output formats.\\n    C. Simple Examples: Defining a basic data structure with Pydantic-AI.\\n\\nIII. Fundamentals of AI Agents\\n    A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n    B. Key Components of an Agent:\\n        1. Large Language Models (LLMs).\\n        2. Tools/Functions: How agents interact with the external world.\\n        3. Memory: Short-term and long-term context retention.\\n        4. Reasoning and Planning.\\n        5. Action and Execution.\\n    C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nIV. The Synergy: Why Pydantic-AI for Agent Development?\\n    A. The Problem: Unreliable, unstructured outputs from LLMs.\\n    B. The Solution: Pydantic-AI for guaranteed data structures.\\n    C. Key Benefits:\\n        1. **Reliable Tool Definitions:** Defining function signatures and arguments.\\n        2. **Robust Response Parsing:** Ensuring agent outputs (actions, thoughts, observations) are consistently formatted.\\n        3. **Structured Agent State/Memory:** Managing conversation history, learned facts, and goals.\\n        4. **Reduced Boilerplate & Improved Readability.**\\n        5. **Enhanced Debugging and Error Handling.**\\n\\nV. Practical Guide: Building Agents with Pydantic-AI\\n    A. **Defining Agent Tools with Pydantic-AI:**\\n        1. Using `BaseModel` to describe tool input parameters.\\n        2. Examples: A search tool, a calculator tool, defined with Pydantic-AI.\\n        3. Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).\\n    B. **Structuring Agent Responses and Outputs:**\\n        1. Guiding LLMs to produce Pydantic-compatible JSON.\\n        2. Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).\\n        3. Handling parsing errors and retries.\\n    C. **Managing Agent State and Memory:**\\n        1. Using Pydantic models for storing conversation turns, facts, or observations.\\n        2. Example: A `ConversationHistory` model or an `AgentState` model.\\n    D. **Integration with Popular Agent Frameworks (Illustrative Examples):**\\n        1. How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).\\n        2. How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).\\n\\nVI. Advanced Concepts & Best Practices\\n    A. Nested Pydantic Models for Complex Agent Structures.\\n    B. Custom Validators for Specific Agent Logic.\\n    C. Error Handling and Fallback Mechanisms with Pydantic-AI.\\n    D. Testing Agent Behavior with Pydantic-AI Assertions.\\n    E. Performance Considerations for High-Throughput Agents.\\n\\nVII. Conclusion\\n    A. Recap of Pydantic-AI\\'s role in building robust and reliable AI agents.\\n    B. Future outlook for structured data in agent development.\\n    C. Final thoughts on efficiency and maintainability.\\n\\n\\nSearch Queries for Report Content:\\n\\n1.  \"Pydantic-AI documentation for agents\"\\n2.  \"Pydantic-AI for LLM structured output\"\\n3.  \"How to use Pydantic-AI with LangChain for tool definition\"\\n4.  \"Pydantic-AI `response_model` for agents\"\\n5.  \"Pydantic-AI examples for agent memory management\"\\n6.  \"Building conversational agents with Pydantic-AI\"\\n7.  \"Pydantic-AI for function calling in LLMs\"\\n8.  \"Structured data validation for AI agents with Pydantic-AI\"\\n9.  \"Pydantic-AI vs Pydantic for AI applications\"\\n10. \"Best practices for Pydantic-AI in agent development\"', instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\", instructions_functions=[], system_prompts=(), system_prompt_functions=[], system_prompt_dynamic_functions={})\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[UserPromptPart(content='The outline of the report is: Report Outline: How to Use Pydantic-AI to Build Agents\\n\\nI. Introduction\\n    A. The rise of AI Agents and the need for reliable interactions.\\n    B. Introduction to Pydantic-AI: What it is, its core purpose (data validation, parsing, and structuring).\\n    C. Thesis Statement: How Pydantic-AI enhances agent development by ensuring structured, reliable data exchange.\\n    D. Report Goals: What this report will cover.\\n\\nII. Understanding Pydantic-AI\\n    A. Core Concepts of Pydantic:\\n        1. `BaseModel` for data schema definition.\\n        2. Type hinting and automatic validation.\\n        3. Data parsing and serialization.\\n    B. Pydantic-AI Specifics (if distinct from core Pydantic relevant to AI):\\n        1. Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).\\n        2. How it helps enforce LLM output formats.\\n    C. Simple Examples: Defining a basic data structure with Pydantic-AI.\\n\\nIII. Fundamentals of AI Agents\\n    A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n    B. Key Components of an Agent:\\n        1. Large Language Models (LLMs).\\n        2. Tools/Functions: How agents interact with the external world.\\n        3. Memory: Short-term and long-term context retention.\\n        4. Reasoning and Planning.\\n        5. Action and Execution.\\n    C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nIV. The Synergy: Why Pydantic-AI for Agent Development?\\n    A. The Problem: Unreliable, unstructured outputs from LLMs.\\n    B. The Solution: Pydantic-AI for guaranteed data structures.\\n    C. Key Benefits:\\n        1. **Reliable Tool Definitions:** Defining function signatures and arguments.\\n        2. **Robust Response Parsing:** Ensuring agent outputs (actions, thoughts, observations) are consistently formatted.\\n        3. **Structured Agent State/Memory:** Managing conversation history, learned facts, and goals.\\n        4. **Reduced Boilerplate & Improved Readability.**\\n        5. **Enhanced Debugging and Error Handling.**\\n\\nV. Practical Guide: Building Agents with Pydantic-AI\\n    A. **Defining Agent Tools with Pydantic-AI:**\\n        1. Using `BaseModel` to describe tool input parameters.\\n        2. Examples: A search tool, a calculator tool, defined with Pydantic-AI.\\n        3. Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).\\n    B. **Structuring Agent Responses and Outputs:**\\n        1. Guiding LLMs to produce Pydantic-compatible JSON.\\n        2. Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).\\n        3. Handling parsing errors and retries.\\n    C. **Managing Agent State and Memory:**\\n        1. Using Pydantic models for storing conversation turns, facts, or observations.\\n        2. Example: A `ConversationHistory` model or an `AgentState` model.\\n    D. **Integration with Popular Agent Frameworks (Illustrative Examples):**\\n        1. How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).\\n        2. How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).\\n\\nVI. Advanced Concepts & Best Practices\\n    A. Nested Pydantic Models for Complex Agent Structures.\\n    B. Custom Validators for Specific Agent Logic.\\n    C. Error Handling and Fallback Mechanisms with Pydantic-AI.\\n    D. Testing Agent Behavior with Pydantic-AI Assertions.\\n    E. Performance Considerations for High-Throughput Agents.\\n\\nVII. Conclusion\\n    A. Recap of Pydantic-AI\\'s role in building robust and reliable AI agents.\\n    B. Future outlook for structured data in agent development.\\n    C. Final thoughts on efficiency and maintainability.\\n\\n\\nSearch Queries for Report Content:\\n\\n1.  \"Pydantic-AI documentation for agents\"\\n2.  \"Pydantic-AI for LLM structured output\"\\n3.  \"How to use Pydantic-AI with LangChain for tool definition\"\\n4.  \"Pydantic-AI `response_model` for agents\"\\n5.  \"Pydantic-AI examples for agent memory management\"\\n6.  \"Building conversational agents with Pydantic-AI\"\\n7.  \"Pydantic-AI for function calling in LLMs\"\\n8.  \"Structured data validation for AI agents with Pydantic-AI\"\\n9.  \"Pydantic-AI vs Pydantic for AI applications\"\\n10. \"Best practices for Pydantic-AI in agent development\"', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 38, 249783, tzinfo=datetime.timezone.utc))], instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\"))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tavily_search', args={'query': 'rise of AI agents and need for reliable interactions'}, tool_call_id='pyd_ai_cba2d181ded04742a59f1535000d640a'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI introduction core purpose data validation parsing structuring'}, tool_call_id='pyd_ai_8b2228d7e2444264973db11f18896cde')], usage=RequestUsage(input_tokens=3599, output_tokens=449, details={'thoughts_tokens': 396, 'text_prompt_tokens': 3599}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 42, 191885, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='qpq4aLOyDZahqtsPxurJ-Q8'))\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tavily_search', content={'query': 'rise of AI agents and need for reliable interactions', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://roopco.com/ai-agents-make-human-interactions-more-meaningful/', 'title': 'How AI Agents Will Make Human Interactions More Meaningful', 'content': \"The rise of AI agents might actually make human interactions more meaningful. As these tools take over routine, repetitive tasks, they'll free us up to focus\", 'score': 0.69498676, 'raw_content': None}, {'url': 'https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence', 'title': 'The Rise of AI Agents—Collaborative Intelligence - CyberArk', 'content': 'AI agents, essentially machine identities, are increasingly autonomous systems designed to perform tasks, make decisions and continuously learn from their interactions with the environment. Unlike predefined workflows, AI agents operate as autonomous, adaptive entities that can perceive their environment, reason over complex inputs and iteratively refine their decision-making. * **AI agents:** Machine identities built for increasingly autonomous reasoning, capable of formulating goals, executing multi-step plans and refining their strategies based on feedback loops. * **Cybersecurity**: AI agents strengthen identity security, automating threat detection and mitigating real time risks. Unlike static rule-based systems, modern AI agents leverage probabilistic reasoning, reinforcement learning and multimodal data processing to refine their decision-making dynamically.', 'score': 0.5815176, 'raw_content': None}, {'url': 'https://www.oracle.com/ae/a/ocom/docs/applications/the-rise-of-ai-agents-unleashing-productivity-and-innovation-ae.pdf', 'title': '[PDF] The Rise of AI Agents: Unleashing Productivity and Innovation - Oracle', 'content': 'Using AI agents within Oracle Fusion Applications can help transform the way work gets done by automating complex tasks and helping to provide valuable insights efficiently, extensibly, and consistently. AI Agent use case example The Rise of AI Agents: Unleashing Productivity and Innovation 12 CX: Automated Customer Service Agent Today, Alex, a service agent, and her colleague Adam, a field service technician, work together as part of a larger service team to resolve customer issues.', 'score': 0.46905875, 'raw_content': None}, {'url': 'https://a16z.com/the-rise-of-computer-use-and-agentic-coworkers/', 'title': 'The Rise of Computer Use and Agentic Coworkers', 'content': 'Projects such as OpenAI’s ChatGPT Agent, Anthropic’s Claude, Google’s Project Mariner, and startups like Manus and Context offer a glimpse into what human-level AI agents, trained specifically for computer tasks, might achieve. In addition to using APIs like computers, these agents can also operate software like humans do when programmatic access isn’t possible — clicking through user interfaces, logging in, sending files, working with legacy software — so they can slot into existing workflows without needing major IT overhauls or custom integration. Together, these advances point to a broadly useful application: AI agents capable of handling a wide range of digital work without human input.', 'score': 0.41620392, 'raw_content': None}, {'url': 'https://www.gate39media.com/blog/the-rise-of-ai-agents', 'title': 'The Rise of AI Agents: Why You Need to Adjust Your Strategy', 'content': 'Jun 3, 2025·A truly effective AI strategy includes not just choosing the right tools, but defining how your team collaborates with these agents to drive performance,', 'score': 0.3900581, 'raw_content': None}], 'response_time': 1.37, 'request_id': '00d65c3b-eda1-49f0-b566-b774c98301b8'}, tool_call_id='pyd_ai_cba2d181ded04742a59f1535000d640a', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 44, 46644, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI introduction core purpose data validation parsing structuring', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://medium.com/@shouke.wei/the-power-of-pydantic-bringing-structure-and-validation-to-your-python-data-9de124362a6f', 'title': 'The Power of Pydantic: Bringing Structure and Validation to Your ...', 'content': \"Pydantic is a powerful library that uses Python's native type hints to provide runtime data validation, parsing, and serialization. It acts as a contract for\", 'score': 0.6929958, 'raw_content': None}, {'url': 'https://arxiv.org/html/2508.14123v1', 'title': 'AI Agents for Photonic Integrated Circuit Design Automation - arXiv', 'content': 'A Pydantic model is a Python data class that defines a strict schema for the expected output (field names and types) and automatically validates that the', 'score': 0.57666177, 'raw_content': None}, {'url': 'https://github.com/pydantic/pydantic-ai', 'title': 'Agent Framework / shim to use Pydantic with LLMs - GitHub', 'content': \"GitHub - pydantic/pydantic-ai: Agent Framework / shim to use Pydantic with LLMs Image 9: Pydantic AI Pydantic AI is a Python agent framework designed to make it less painful to build production grade applications with Generative AI. Similarly, virtually every agent framework and LLM library in Python uses Pydantic Validation, yet when we began to use LLMs in Pydantic Logfire, we couldn't find anything that gave us the same feeling. Why use Pydantic AI from pydantic\\\\_ai import Agent Here is a concise example using Pydantic AI to build a support agent for a bank: from pydantic\\\\_ai import Agent, RunContext # This pydantic model defines the structure of the output returned by the agent.\", 'score': 0.45377067, 'raw_content': None}, {'url': 'https://ai.pydantic.dev/api/agent/', 'title': 'pydantic_ai.agent - Pydantic AI', 'content': 'The type of data output by agent runs, used to validate the data returned by the model, defaults to str . event_stream_handler property. event_stream_handler:', 'score': 0.34920028, 'raw_content': None}, {'url': 'https://realpython.com/python-annotations/', 'title': 'Python 3.14 Preview: Lazy Annotations', 'content': 'When you instantiate your model later, Pydantic automatically validates the data and raises an error if any constraint is violated. Historically, the static and', 'score': 0.3460776, 'raw_content': None}], 'response_time': 1.18, 'request_id': 'd7ed1e4a-5879-45d9-abb8-6453fc2841c0'}, tool_call_id='pyd_ai_8b2228d7e2444264973db11f18896cde', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 43, 868433, tzinfo=datetime.timezone.utc))], instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\"))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tavily_search', args={'max_results': 3, 'query': 'Pydantic BaseModel data schema definition type hinting automatic validation data parsing serialization'}, tool_call_id='pyd_ai_dc0c9cd2fc9e446e9fa16e119b979649'), ToolCallPart(tool_name='tavily_search', args={'max_results': 3, 'query': 'Pydantic-AI features for LLM interactions response_model decorators structured output enforce LLM output formats'}, tool_call_id='pyd_ai_612564b8215d423a8785e036ac0440ff'), ToolCallPart(tool_name='tavily_search', args={'max_results': 2, 'query': 'Pydantic-AI simple example defining basic data structure'}, tool_call_id='pyd_ai_4a1602fbe86741c1821a2fc0794da43a')], usage=RequestUsage(input_tokens=5303, cache_read_tokens=2953, output_tokens=458, details={'cached_content_tokens': 2953, 'thoughts_tokens': 343, 'text_prompt_tokens': 5303, 'text_cache_tokens': 2953}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 47, 120399, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='r5q4aNaUCeLDqtsPy73SiQ0'))\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic BaseModel data schema definition type hinting automatic validation data parsing serialization', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://docs.pydantic.dev/latest/concepts/models/', 'title': 'Models - Pydantic', 'content': 'In Pydantic, the term \"validation\" refers to the process of instantiating a model (or other type) that adheres to specified types and constraints. Pydantic\\xa0...BaseModel·Serialization·JSON Schema·Fields', 'score': 0.98594, 'raw_content': None}, {'url': 'https://docs.pydantic.dev/latest/api/base_model/', 'title': 'BaseModel - Pydantic', 'content': \"r} should a single element representing the type or a two-tuple, the first element '                     'being the type and the second element the assigned value (either a default or the `Field()` function).',                     code='create-model-field-definitions',                 )              annotations[f_name] = f_def[0]             fields[f_name] = f_def[1]         else:             annotations[f_name] = f_def      if __module__ is None:         f = sys._getframe(1)         __module__ = f.f_globals['__name__']      namespace: dict[str, Any] = {'__annotations__': annotations, '__module__': __module__}     if __doc__:         namespace.update({'__doc__': __doc__})     if __validators__:         namespace.update(__validators__)     namespace.update(fields)     if __config__:         namespace['model_config'] = __config__     resolved_bases = types.resolve_bases(__base__)     meta, ns, kwds = types.prepare_class(model_name, resolved_bases, kwds=__cls_kwargs__)     if resolved_bases is not __base__:         ns['__orig_bases__'] = __base__     namespace.update(ns)      return meta(         model_name,         resolved_bases,         namespace,         __pydantic_reset_parent_namespace__=False,         _create_model_module=__module__,         **kwds,     )  ``` |\", 'score': 0.98154, 'raw_content': None}, {'url': 'https://realpython.com/python-pydantic/', 'title': 'Pydantic: Simplifying Data Validation in Python', 'content': '# Pydantic: Simplifying Data Validation in Python Pydantic is a powerful data validation and settings management library for Python, engineered to enhance the robustness and reliability of your codebase. Pydantic: Simplifying Data Validation in Python Pydantic is a powerful Python library that leverages type hints to help you easily validate and serialize your data schemas. From primitive Python types to highly nested data structures, Pydantic lets you validate and serialize nearly any Python object. You can use `pydantic-settings` to create models, similar to `BaseModel`, that parse and validate environment variables. * How to parse and validate environment variables with **`pydantic-settings`** Pydantic makes your code more robust and trustworthy, and it partially bridges the gap between Python’s ease of use and the built-in data validation of statically typed languages. Pydantic: Simplifying Data Validation in Python', 'score': 0.97845, 'raw_content': None}], 'response_time': 2.05, 'request_id': '7521588c-8203-40fc-9068-7a0074168cce'}, tool_call_id='pyd_ai_dc0c9cd2fc9e446e9fa16e119b979649', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 49, 682693, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI features for LLM interactions response_model decorators structured output enforce LLM output formats', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ai.pydantic.dev/', 'title': 'Pydantic AI', 'content': \"*Agent Framework / shim to use Pydantic with LLMs* Pydantic AI is a Python agent framework designed to make it less painful to build production grade Similarly, virtually every agent framework and LLM library in Python uses Pydantic Validation, yet when we began to use LLMs in Pydantic Logfire, we couldn't find anything that gave us the same feeling. from pydantic_ai import Agent Here is a concise example using Pydantic AI to build a support agent for a bank: from pydantic_ai import Agent, RunContext To understand the flow of the above runs, we can watch the agent in action using Pydantic Logfire. from pydantic_ai import Agent, RunContext The Pydantic AI documentation is available in the llms.txt format.\", 'score': 0.98592, 'raw_content': None}, {'url': 'https://medium.com/@speaktoharisudhan/structured-outputs-from-llm-using-pydantic-1a36e6c3aa07', 'title': 'Structured Outputs from LLM using Pydantic | by Harisudhan.S', 'content': 'class Output(BaseModel):    setup: str = Field(description=\"Give me the list of all the name of the characterse\")    punchline: str = Field(description=\"Give me the list of places if it is available\")    @validator(\"setup\")    def question_ends_with_question_mark(cls, field):        if field[-1] != \"?\":            raise ValueError(\"Badly formed question!\")        return fieldquery = \"\"# Set up a parser + inject instructions into the prompt template.parser = PydanticOutputParser(pydantic_object=Output)prompt = PromptTemplate(    template=\"Answer the user query.\\\\n{format_instructions}\\\\n{query}\\\\n\",    input_variables=[\"query\"],    partial_variables={\"format_instructions\": parser.get_format_instructions()},)chain = prompt | model | parserchain.invoke({\"query\": query}) class Output BaseModel str \"Give me the list of all the name of the characterse\" str \"Give me the list of places if it is available\"    @validator(\"setup\") \"setup\" \"setup\" def question_ends_with_question_markcls, field if 1 \"?\" raise\"Badly formed question!\" return \"\"', 'score': 0.98344, 'raw_content': None}, {'url': 'https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/', 'title': 'Enforce Structured Outputs from LLMs with PydanticAI - CodeCut', 'content': 'If you’re expecting clean, structured data, such as a JSON object with keys like ‘first\\\\_name’, ‘last\\\\_name’, ‘experience’, and ‘primary\\\\_skill’, you may find the model returning values in an unstructured form. input=\"Khuyen Tran is a data scientist with 5 years of experience, skilled in Python and machine learning.\", * Enforce structured JSON outputs from LLMs using Pydantic models instead of parsing unreliable text First, define a `Pydantic` Model that describes the expected structure of your agent’s output: Now, use the `output_type` parameter to connect this model to your agent: result = agent.run_sync(\\'Khuyen Tran is a data scientist with 5 years of experience, skilled in Python and machine learning.\\') first_name=\\'Khuyen\\' last_name=\\'Tran\\' experience_years=5 primary_skill=[\\'Python\\', \\'machine learning\\'] df = pd.DataFrame([result.output.model_dump()])', 'score': 0.97639, 'raw_content': None}], 'response_time': 2.51, 'request_id': '86256d23-c1fa-4275-bdc2-60371e4d6340'}, tool_call_id='pyd_ai_612564b8215d423a8785e036ac0440ff', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 50, 142206, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI simple example defining basic data structure', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.datacamp.com/tutorial/pydantic', 'title': 'Pydantic: A Guide With Practical Examples - DataCamp', 'content': \"Jun 25, 2025·Pydantic is Python's most popular data validation library that can turn type hints into runtime validation rules.\", 'score': 0.9851, 'raw_content': None}, {'url': 'https://realpython.com/python-pydantic/', 'title': 'Pydantic: Simplifying Data Validation in Python', 'content': '# Pydantic: Simplifying Data Validation in Python Pydantic is a powerful data validation and settings management library for Python, engineered to enhance the robustness and reliability of your codebase. Pydantic: Simplifying Data Validation in Python Pydantic is a powerful Python library that leverages type hints to help you easily validate and serialize your data schemas. From primitive Python types to highly nested data structures, Pydantic lets you validate and serialize nearly any Python object. You can use `pydantic-settings` to create models, similar to `BaseModel`, that parse and validate environment variables. * How to parse and validate environment variables with **`pydantic-settings`** Pydantic makes your code more robust and trustworthy, and it partially bridges the gap between Python’s ease of use and the built-in data validation of statically typed languages. Pydantic: Simplifying Data Validation in Python', 'score': 0.98336, 'raw_content': None}], 'response_time': 1.68, 'request_id': 'c8c00c44-eeab-4194-9d37-cd203d5e7ada'}, tool_call_id='pyd_ai_4a1602fbe86741c1821a2fc0794da43a', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 49, 326722, tzinfo=datetime.timezone.utc))], instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\"))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tavily_search', args={'query': 'definition of an AI Agent LLM as core tools memory planning capabilities'}, tool_call_id='pyd_ai_fed2369fadaa43d58bdf9b0e66fbf18c'), ToolCallPart(tool_name='tavily_search', args={'query': 'Key Components of an Agent Large Language Models LLMs Tools Functions Memory Reasoning Planning Action Execution'}, tool_call_id='pyd_ai_d0a85fccbc89479895064f57d8ff7707'), ToolCallPart(tool_name='tavily_search', args={'query': 'Common AI Agent Frameworks LangChain LlamaIndex'}, tool_call_id='pyd_ai_94d12ca4ee454beda40fa4f8c6c8c457')], usage=RequestUsage(input_tokens=7664, cache_read_tokens=4972, output_tokens=179, details={'cached_content_tokens': 4972, 'thoughts_tokens': 91, 'text_prompt_tokens': 7664, 'text_cache_tokens': 4972}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 52, 142518, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='tJq4aKWZCpOJqtsPqY-EgA0'))\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tavily_search', content={'query': 'definition of an AI Agent LLM as core tools memory planning capabilities', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.geeksforgeeks.org/artificial-intelligence/llm-agents/', 'title': 'LLM Agents - GeeksforGeeks', 'content': 'LLM agents are AI system that are powered by large language models (LLMs) and they extend the capabilities of traditional AI models by allowing for conversational interactions, task execution, reasoning and a degree of autonomy. ****5.**** ****Tools:**** LLM agents often utilize external resources or APIs that the agent can use to perform specific tasks such as retrieving data, making calculations or interacting with other systems. An LLM agent works by using a combination of the core language model and external components to interpret inputs, generate responses and perform tasks on its own. LLM agents are used across various industries due to their abilities to process large amounts of data, understand context and to perform complex tasks.', 'score': 0.6742441, 'raw_content': None}, {'url': 'https://inference-docs.cerebras.ai/agent-bootcamp/section-1', 'title': 'Introduction to AI Agents - Build with Cerebras Inference', 'content': 'By incorporating components such as planning, memory, and tool access, AI agents can interact with various environments, reason through their actions, and enhance their own outputs. ## \\u200b AI Agent Control Flow That said, the most common components found in agentic workflows are tool use, planning, reflection, and memory. Tool use extends an LLM’s capabilities by enabling an AI agent to interact with its environment using tools essential for completing assigned tasks. When handling complex workflows, AI agents must execute several intermediate steps to complete their assigned tasks. During this planning phase, the AI agent must consider factors such as the user’s request, the available tools, and the information needed to complete each subsequent step.', 'score': 0.65861565, 'raw_content': None}, {'url': 'https://www.promptingguide.ai/agents/components', 'title': 'Agent Components - Prompt Engineering Guide', 'content': \"AI agents require three fundamental capabilities to effectively tackle complex tasks: planning abilities, tool utilization, and memory management. Without robust planning abilities, an agent cannot effectively automate complex tasks, which defeats its primary purpose. ## Tool Utilization: Extending the Agent's Capabilities These tools enable the agent to execute its planned actions, turning abstract strategies into concrete results. Memory systems allow agents to store and retrieve information gathered from external tools, enabling iterative improvement and building upon previous knowledge. The synergy between planning capabilities, tool utilization, and memory systems forms the foundation of effective AI agents. While each component has its current limitations, understanding these core capabilities is crucial for developing and working with AI agents.\", 'score': 0.6219319, 'raw_content': None}, {'url': 'https://cloud.google.com/discover/what-are-ai-agents', 'title': 'What are AI agents? Definition, examples, and types | Google Cloud', 'content': 'AI agents are software systems that use AI to pursue goals and complete tasks on behalf of users. They show reasoning, planning, and memory.', 'score': 0.43828082, 'raw_content': None}, {'url': 'https://www.promptingguide.ai/research/llm-agents', 'title': 'LLM Agents - Prompt Engineering Guide', 'content': '* HuggingGPT (opens in a new tab) - an LLM-powered agent that leverages LLMs as a task planner to connect various existing AI models (based on descriptions) to solve AI tasks. * AutoGen (opens in a new tab): a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. * AgentVerse (opens in a new tab): designed to facilitate the deployment of multiple LLM-based agents in various applications. * LLM Powered Autonomous Agents (opens in a new tab) * Introduction to LLM Agents (opens in a new tab) * Building Your First LLM Agent Application (opens in a new tab) * Awesome LLM agents (opens in a new tab) * Awesome LLM-Powered Agent (opens in a new tab)', 'score': 0.41948205, 'raw_content': None}], 'response_time': 2.36, 'request_id': 'ac546b9c-0575-4da8-8366-2c5ad286cd19'}, tool_call_id='pyd_ai_fed2369fadaa43d58bdf9b0e66fbf18c', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 54, 995638, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Key Components of an Agent Large Language Models LLMs Tools Functions Memory Reasoning Planning Action Execution', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://workos.com/blog/mcp-features-guide', 'title': 'Understanding MCP features: Tools, Resources, Prompts, Sampling ...', 'content': 'Tools are specific actions your MCP server exposes to a client, like **built-in functions or APIs** that an LLM can call during a conversation. The real power of MCP shines when multiple servers, tools, resources, and prompts work seamlessly together. Instead of every MCP server needing its own AI model connection (which is expensive and complex), it can say: *“Hey client, you already have access to Claude or GPT—can you run this piece of reasoning for me and give me the result?”* * The client prompts the user: “The server wants to use your AI model to rank activities for your preferences. Clients provide these roots to servers when they start or when users open new folders.', 'score': 0.41677347, 'raw_content': None}, {'url': 'https://priceroberts.com/Podcast/', 'title': 'PriceRoberts | Inspiring Tech Leaders | Technology Leader', 'content': 'A powerful AI agent developed by Butterfly Effect, a little-known Chinese startup. Why does it matter? China is shifting from Large Language Models (LLMs) to', 'score': 0.20211264, 'raw_content': None}, {'url': 'https://www.usaii.org/ai-insights/blog', 'title': 'AI Blogs | AI Insights | AI Trends | AI Articles | AI News - USAII', 'content': 'Explore an open-book approach to Retrieval Augmented Generation (RAG) architecture and the inside story of large language models (LLMs). Read for more details!', 'score': 0.15285267, 'raw_content': None}, {'url': 'https://sipb.mit.edu/planet/', 'title': 'Planet SIPB', 'content': 'When training large scale LLMs, there is a large assortment of parallelization strategies which you can employ to scale your training runs to work on more', 'score': 0.12606281, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Intelligent_agent', 'title': 'Intelligent agent - Wikipedia', 'content': '[Jump to content](https://en.wikipedia.org/wiki/Intelligent_agent#bodyContent) *   [Main page](https://en.wikipedia.org/wiki/Main_Page \"Visit the main page [z]\") *   [Random article](https://en.wikipedia.org/wiki/Special:Random \"Visit a randomly selected article [x]\") *   [(Top)](https://en.wikipedia.org/wiki/Intelligent_agent#) *   [2 Objective function](https://en.wikipedia.org/wiki/Intelligent_agent#Objective_function) *   [3 Agent function](https://en.wikipedia.org/wiki/Intelligent_agent#Agent_function) *   [4.1.5 Learning agents](https://en.wikipedia.org/wiki/Intelligent_agent#Learning_agents) *   [4.2 Weiss\\'s classification](https://en.wikipedia.org/wiki/Intelligent_agent#Weiss\\'s_classification) *   [4.3 Other](https://en.wikipedia.org/wiki/Intelligent_agent#Other) *   [5 Hierarchies of agents](https://en.wikipedia.org/wiki/Intelligent_agent#Hierarchies_of_agents) *   [6.1 Agentic AI](https://en.wikipedia.org/wiki/Intelligent_agent#Agentic_AI) *   [6.1.1 Autonomous capabilities](https://en.wikipedia.org/wiki/Intelligent_agent#Autonomous_capabilities) *   [6.1.3 Applications](https://en.wikipedia.org/wiki/Intelligent_agent#Applications) *   [6.1.4 Proposed benefits](https://en.wikipedia.org/wiki/Intelligent_agent#Proposed_benefits) *   [6.1.5 Concerns](https://en.wikipedia.org/wiki/Intelligent_agent#Concerns) *   [6.1.5.1 Possible mitigation](https://en.wikipedia.org/wiki/Intelligent_agent#Possible_mitigation) *   [7 Applications](https://en.wikipedia.org/wiki/Intelligent_agent#Applications_2) *   [8 See also](https://en.wikipedia.org/wiki/Intelligent_agent#See_also) *   [9 References](https://en.wikipedia.org/wiki/Intelligent_agent#References) *   [10 Sources](https://en.wikipedia.org/wiki/Intelligent_agent#Sources) *   [Article](https://en.wikipedia.org/wiki/Intelligent_agent \"View the content page [c]\") *   [Talk](https://en.wikipedia.org/wiki/Talk:Intelligent_agent \"Discuss improvements to the content page [t]\") *   [Read](https://en.wikipedia.org/wiki/Intelligent_agent) *   [Read](https://en.wikipedia.org/wiki/Intelligent_agent) *   [What links here](https://en.wikipedia.org/wiki/Special:WhatLinksHere/Intelligent_agent \"List of all English Wikipedia pages containing links to this page [j]\") 34 languages[Add topic](https://en.wikipedia.org/wiki/Intelligent_agent#)', 'score': 0.06442369, 'raw_content': None}], 'response_time': 1.84, 'request_id': 'c2cf279d-4c3b-4630-a28c-6d3746ae46dc'}, tool_call_id='pyd_ai_d0a85fccbc89479895064f57d8ff7707', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 54, 476652, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Common AI Agent Frameworks LangChain LlamaIndex', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.ibm.com/think/insights/top-ai-agent-frameworks', 'title': 'AI Agent Frameworks: Choosing the Right Foundation for Your ... - IBM', 'content': \"This is where AI agent frameworks come in. Agentic frameworks are the building blocks for developing, deploying and managing AI agents. AI agents ## Popular AI agent frameworks LangChain is another open-source framework for building LLM-powered applications, including chatbots\\xa0such as ChatGPT and AI agents. LangChain is useful for developing simple AI agents with straightforward workflows. LlamaIndex is an open-source data orchestration framework for building generative AI\\xa0(gen AI) and agentic AI solutions. IBM AI agent development\\xa0 IBM AI agents and assistants Explore AI agents Automate your complex workflows and create breakthrough productivity with one of the industry's most comprehensive set of capabilities for helping businesses build, customize and manage AI agents and assistants. Explore watsonx.ai agent development\", 'score': 0.85967577, 'raw_content': None}, {'url': 'https://medium.com/@ajayverma23/navigating-the-ai-framework-landscape-llamaindex-langchain-and-beyond-e377bbc0e1c4', 'title': 'Navigating the AI Framework Landscape: LlamaIndex, LangChain ...', 'content': 'Description: LangChain is another framework aimed at building applications with large language models. As the field of artificial intelligence continues to evolve, developers have access to a variety of frameworks designed to facilitate the integration of large language models (LLMs) into applications. Frameworks like LlamaIndex and LangChain are excellent choices for those focusing on large language models, while TensorFlow and PyTorch offer robust solutions for deep learning tasks. Conversely, if you need a flexible framework capable of handling complex workflows and integrating various AI components, LangChain is more suitable.By understanding the strengths and weaknesses of each framework, developers can make informed decisions that align with their specific needs, ultimately leading to more effective applications powered by large language models.', 'score': 0.82795376, 'raw_content': None}, {'url': 'https://langfuse.com/blog/2025-03-19-ai-agent-comparison', 'title': 'Comparing Open-Source AI Agent Frameworks - Langfuse Blog', 'content': 'This post offers an in-depth look at some of the leading open-source AI agent frameworks out there: **LangGraph, the OpenAI Agents SDK, Smolagents, CrewAI, AutoGen, Semantic Kernel, LlamaIndex agents, Strands Agents, and Pydantic AI agents**. [How to trace the OpenAI Agents SDK with Langfuse →](/integrations/frameworks/openai-agents) [How to trace CrewAI agents with Langfuse →](/integrations/frameworks/crewai) [How to trace AutoGen agents with Langfuse →](/integrations/frameworks/autogen) [How to trace LlamaIndex Agents with Langfuse →](/integrations/frameworks/llamaindex-workflows) [Strands Agents SDK](https://strandsagents.com) is a model-agnostic agent framework that runs anywhere and supports multiple model providers with reasoning and tool use, including **Amazon Bedrock**, Anthropic, OpenAI, Ollama, and others via LiteLLM. ![Strands Agents trace visualization in Langfuse](https://langfuse.com/images/cookbook/integration_aws_strands_agents/strands-agents-trace.png) [How to trace Strands Agents with Langfuse →](/integrations/frameworks/strands-agents)', 'score': 0.7827459, 'raw_content': None}, {'url': 'https://www.reddit.com/r/LLMDevs/comments/1i4742r/best_framework_to_build_ai_agents_like_crew_ai/', 'title': 'Best Framework to build AI Agents like (crew Ai, Langchain, AutoGen)', 'content': \"Jan 18, 2025·Frameworks like LangChain and LlamaIndex are simple to use and great for non-tech folks. However, to offer that simplicity, they default\\xa0...Langchain vs LlamaIndex vs CrewAI vs Custom? Which framework ...What's the best framework for production‑grade AI agents right now?More results from www.reddit.com\", 'score': 0.76173395, 'raw_content': None}, {'url': 'https://www.turing.com/resources/ai-agent-frameworks', 'title': 'A Detailed Comparison of Top 6 AI Agent Frameworks in 2025 - Turing', 'content': \"LangGraph[1] is a powerful open-source library within the LangChain ecosystem, designed specifically for building stateful, multi-actor applications powered by LLMs. It extends LangChain's capabilities by introducing the ability to create and manage cyclical graphs, a key feature for developing sophisticated agent runtimes. CrewAI[21] is an open-source Python framework designed to simplify the development and management of multi-agent AI systems. Microsoft Semantic Kernel[29] is a lightweight, open-source software development kit (SDK) that enables developers to seamlessly integrate the latest AI agents and models into their applications. Microsoft AutoGen[37] is an open-source programming framework designed to simplify the development of AI agents and enable cooperation among multiple agents to solve complex tasks.\", 'score': 0.73138535, 'raw_content': None}], 'response_time': 1.3, 'request_id': '7a3c00d9-d59e-4a3a-bf6a-482c6bc12817'}, tool_call_id='pyd_ai_94d12ca4ee454beda40fa4f8c6c8c457', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 53, 967660, tzinfo=datetime.timezone.utc))], instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\"))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tavily_search', args={'query': 'unreliable unstructured outputs from LLMs problem'}, tool_call_id='pyd_ai_810de3eb50be45d59aa57375f7822446'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI for guaranteed data structures solution'}, tool_call_id='pyd_ai_711beb8a5c894d66b41084ea854c3208'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI benefits reliable tool definitions agent output parsing structured agent state memory reduced boilerplate improved readability enhanced debugging error handling'}, tool_call_id='pyd_ai_7328203e5d20445b96a5167c96f915a2')], usage=RequestUsage(input_tokens=11428, cache_read_tokens=7018, output_tokens=552, details={'cached_content_tokens': 7018, 'thoughts_tokens': 462, 'text_prompt_tokens': 11428, 'text_cache_tokens': 7018}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 44, 58, 984642, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='u5q4aIQ6w6Gq2w-Ex93BDA'))\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tavily_search', content={'query': 'unreliable unstructured outputs from LLMs problem', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.reddit.com/r/MachineLearning/comments/1dyxiw4/d_is_anyone_else_having_trouble_with_the/', 'title': '[D] Is anyone else having trouble with the unstructured output from ...', 'content': \"Jul 9, 2024·Basically used Pydantic output parsers to turn messy LLM responses into clean, structured data that's easy to use in our applications.LLMs and Structured Output: struggling to make it work : r/LLMDevs[Discussion] Can we make LLM outputs reliable when using ... - RedditMore results from www.reddit.com\", 'score': 0.7031221, 'raw_content': None}, {'url': 'https://coralogix.com/ai-blog/llms-insecure-output-handling-best-practices-and-prevention/', 'title': \"LLM's Insecure Output Handling: Best Practices and Prevention\", 'content': 'Insecure Output Handling in Large Language Models (LLMs) is a critical vulnerability identified in the OWASP Top 10 for LLM Applications. Hallucinations and model uncertainty contribute significantly to insecure output handling in LLMs. When an LLM generates hallucinated content with high confidence, downstream systems or users may act on this incorrect information, potentially leading to security vulnerabilities or erroneous decision-making. 2. **Implement regular threat modeling and security testing**: Analyze the application architecture and data flow to identify potential vulnerabilities in LLM output handling. These case studies highlight the importance of implementing robust security measures when handling LLM outputs, including proper validation, sanitization, and access controls. Insecure output handling in LLMs refers to insufficient validation, sanitization, and handling of LLM-generated outputs before use.', 'score': 0.61112726, 'raw_content': None}, {'url': 'https://lightup.ai/data-inconsistency-unstructured-data', 'title': \"4 Out of 4 LLMs Got It Wrong: Testing Data Inconsistency - Lightup's AI\", 'content': 'Feb 25, 2025·Inconsistent information in unstructured data, such as documents, can significantly degrade the accuracy and reliability of Large Language Model', 'score': 0.609455, 'raw_content': None}, {'url': 'https://stackoverflow.blog/2025/06/30/reliability-for-unreliable-llms/', 'title': 'Reliability for unreliable LLMs - The Stack Overflow Blog', 'content': '“You need certain tools and processes to really ensure that those systems behave the way you want to.” This article will go into some of the processes and technologies that may inject a little bit of determinism into GenAI workflows. As Qian Li said, “It’s checkpointing your application.” When your Gen AI application or agent processes a prompt, inferences data, or calls tools, durable execution tools store the result. In a world where everyone is building GenAI into their software, you can adapt some standard processes to make the non-determinism of LLMs a little more reliable: sanitize your inputs and outputs, observe as much of the process as possible, and ensure your processes run once and only once.', 'score': 0.60805947, 'raw_content': None}, {'url': 'https://latitude-blog.ghost.io/blog/5-steps-to-handle-llm-output-failures/', 'title': '5 Steps to Handle LLM Output Failures - Ghost', 'content': \"Learn essential steps for effectively managing LLM output failures, from problem detection to long-term system improvements. 1.   **Spot the Problem**: Monitor for issues like formatting mistakes, vague responses, or unsafe outputs. 2.   **Find the Cause**: Check for unclear prompts, model limitations, or system errors. Use logging systems to track key metrics like response times, error rates, and token usage. Tools such as Latitude's monitoring features can provide oversight across various model versions and prompt setups. If neither prompt quality nor model constraints explain the failure, it’s time to debug. Making small adjustments to prompts can quickly resolve issues with LLM outputs without overhauling your system. *   **Performance Monitoring**: Keep an eye on metrics like accuracy, consistency, processing time, and error rates.\", 'score': 0.56575525, 'raw_content': None}], 'response_time': 0.89, 'request_id': '47fc0508-0ad5-4dc4-a720-3324e6172fde'}, tool_call_id='pyd_ai_810de3eb50be45d59aa57375f7822446', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 0, 386677, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI for guaranteed data structures solution', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.technovera.com/it-blogs/pydanticai-the-next-generation-ai-agent-framework-for-llms/', 'title': 'PydanticAI: The Next-Generation AI Agent Framework for LLMs', 'content': \"Jan 6, 2025·PydanticAI's strong and flexible validation algorithms guarantee flawless handling of complicated data structures, making it ideal for a wide\", 'score': 0.77792513, 'raw_content': None}, {'url': 'https://evincedev.com/generative-ai-applications-development-with-pydanticai', 'title': 'Pydantic AI Development Services | Reliable Data Modeling by ...', 'content': 'Pydantic AI Development Services | Reliable Data Modeling by EvinceDev Why Choose EvinceDev for Pydantic AI Development? *   **Experts in Data Validation and Modeling**EvinceDev specializes in integrating Pydantic AI to ensure your AI systems work with precise, validated data structures. *   **Faster Development with Reliable Data Handling**By leveraging Pydantic AI, we help reduce errors and streamline AI pipeline development, accelerating delivery. Pydantic AI provides a powerful library for data validation and modeling, ensuring efficient AI application development. **EvinceDev** uses LangChain to develop complex, **multi-step AI workflows** that automate tasks and enhance user engagement, turning simple models into powerful solutions. **EvinceDev** uses LangChain to develop complex, **multi-step AI workflows** that automate tasks and enhance user engagement, turning simple models into powerful solutions.', 'score': 0.72278196, 'raw_content': None}, {'url': 'https://cuttlesoft.com/blog/2024/12/11/pydantic-ai-building-smarter-type-safe-ai-agents/', 'title': 'Pydantic.ai: Building Smarter, Type-Safe AI Agents - Cuttlesoft', 'content': \"# Pydantic.ai: Building Smarter, Type-Safe AI Agents Rather than just watching from the sidelines, they decided to tackle the challenges of AI development head-on, leveraging their deep expertise in data validation to build a framework that addresses the real-world complexities developers face when working with LLMs. The result is Pydantic.ai, a ground-up rethinking of how AI frameworks should work. First, let's build a recipe generator that showcases Pydantic.ai's structured output capabilities. from pydantic_ai import Agent Since Pydantic.ai handles all the validation and type-checking, you can focus on building features rather than wrestling with data structures. The AI isn't just making educated guesses anymore – it's making recommendations based on real-time weather data, filtered through business logic that we control.\", 'score': 0.5843666, 'raw_content': None}, {'url': 'https://medium.com/@ashutoshsharmaengg/pydantic-for-ai-your-blueprint-for-robust-data-applications-part-1-4-b65c35fb6996', 'title': 'Pydantic for AI: Your Blueprint for Robust Data Applications (Part 1/4)', 'content': \"May 28, 2025·This article has laid the groundwork for understanding Pydantic's fundamental role in bringing structure and reliability to your AI applications.\", 'score': 0.53502613, 'raw_content': None}, {'url': 'https://stephencollins.tech/posts/how-to-use-pydantic-ai-for-structured-outputs-with-multimodal-llms', 'title': 'How to Use PydanticAI with Multimodal LLMs - Stephen Collins.tech', 'content': 'Pydantic models are used to define structured outputs, which ensures that the data extracted from inputs, like invoices, matches the required format. Key takeaways include the importance of Pydantic models for output validation, using agents for modular code organization, the ability to pass data between agents, and the necessity of testing with mock services to ensure reliability. It combines the strength of **Pydantic schemas** with agent-based workflows, ensuring data validation, clean structure, and reusability. 1. **Invoice Processing Agent**: Extract structured details like total amount, sender, and line items from an invoice image. PydanticAI agents orchestrate workflows, using **tools** to interact with the service and validate outputs. \"\"\"Test the invoice processing agent with a mock LLM service.\"\"\"', 'score': 0.44391435, 'raw_content': None}], 'response_time': 1.41, 'request_id': 'ce05b4dc-2861-437f-a193-2a884c1010e2'}, tool_call_id='pyd_ai_711beb8a5c894d66b41084ea854c3208', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 0, 891710, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI benefits reliable tool definitions agent output parsing structured agent state memory reduced boilerplate improved readability enhanced debugging error handling', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Building your own CLI Coding Agent with Pydantic -AI', 'url': 'https://martinfowler.com/articles/build-own-coding-agent.html', 'content': \"Aug 27, 2025 · Building your own CLI Coding Agent with Pydantic-AI Learning by doing CLI coding agents are a fundamentally different tool to chatbots or autocomplete tools - they're agents that can read code, run tests, and update a codebase.\", 'score': 0.47256237, 'raw_content': None}, {'title': 'What is Pydantic ? | by LEARNMYCOURSE | Medium', 'url': 'https://learnmycourse.medium.com/what-is-pydantic-751ba6f452c5', 'content': 'Why is Pydantic Used in Generative AI? Pydantic plays a crucial role in Generative AI workflows, particularly in data validation, model inputs/outputs, and API integration. Generative AI models, such as those built with LangChain, OpenAI, or Hugging Face, require structured inputs and outputs. • Validating API responses from generative models. 2. Building AI APIs (FastAPI + Pydantic) FastAPI (a popular AI API framework) natively supports Pydantic for request validation and response modeling. Pydantic is essential in Generative AI for data validation, structured inputs/outputs, API development, and configuration management. Image 14: A Comprehensive Guide on Agent Development with Pydantic AI: Beginner to Advanced Image 20: Building a Multi-Agent AI System with LangGraph and LangSmith Image 23: Generative AI', 'score': 0.3706587, 'raw_content': None}, {'title': 'Pydantic : A Guide With Practical Examples | DataCamp', 'url': 'https://www.datacamp.com/tutorial/pydantic', 'content': 'Jun 25, 2025 · Pydantic is Python’s most popular data validation library that can turn type hints into runtime validation rules. Instead of writing dozens of if isinstance() checks and custom validation functions, you define your data structure once using familiar Python syntax.', 'score': 0.3127377, 'raw_content': None}, {'title': 'Welcome to Pydantic - Pydantic documentation (en)', 'url': 'https://pydantic.com.cn/en/', 'content': 'Pydantic . Pydantic is the most widely used data validation library for Python. Fast and extensible, Pydantic plays nicely with your linters/IDE/brain. Define how data should be in pure, canonical Python 3.8+; validate it with Pydantic.', 'score': 0.26643586, 'raw_content': None}, {'title': 'Introduction to Python Pydantic Library - GeeksforGeeks', 'url': 'https://www.geeksforgeeks.org/python/introduction-to-python-pydantic-library/', 'content': \"Pydantic is a data validation and settings management library that leverages Python's type annotations to provide powerful and easy-to-use tools for ensuring our data is in the correct format. Pydantic is a Python library that helps us in defining and validating data models easily. Pydantic makes this process easy by allowing us to define our data structure using Python classes and automatically validating the data against these structures. * Pydantic automatically checks that the data fits the model's structure and types. A Pydantic model is a Python class that inherits from **`BaseModel`** and is used to define the structure, validation, and parsing logic for our data. ****Pydantic**** is a powerful and flexible library for data validation, parsing, and settings management in Python.\", 'score': 0.26142564, 'raw_content': None}], 'response_time': 3.53, 'request_id': 'c796efa1-0751-4517-9e9b-168e727b8473'}, tool_call_id='pyd_ai_7328203e5d20445b96a5167c96f915a2', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 3, 1815, tzinfo=datetime.timezone.utc))], instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\"))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI define agent tools input parameters examples search calculator OpenAI function calling'}, tool_call_id='pyd_ai_201d34b2d3f149d28c41759fc8598bd9'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI structuring agent responses outputs Pydantic-compatible JSON response_model PydanticOutputParser parsing errors retries'}, tool_call_id='pyd_ai_9bab8fb920f74a988b294d9e9292ac13'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI managing agent state memory Pydantic models conversation history AgentState example'}, tool_call_id='pyd_ai_50ff4b95846448c2bdf08e84093331cf'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI integration LangChain create_structured_output_chain tool decorators LlamaIndex PydanticProgram structured outputs'}, tool_call_id='pyd_ai_8a8e512e46df4547b20336b98a463290')], usage=RequestUsage(input_tokens=14678, cache_read_tokens=11067, output_tokens=297, details={'cached_content_tokens': 11067, 'thoughts_tokens': 146, 'text_prompt_tokens': 14678, 'text_cache_tokens': 11067}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 7, 142771, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='w5q4aLmjCpS7qtsP3ojJsQw'))\n",
      "INFO:web_deep_researcher:Node: ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI define agent tools input parameters examples search calculator OpenAI function calling', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ai.pydantic.dev/api/tools/', 'title': 'pydantic_ai.tools - Pydantic AI', 'content': 'Definition of a function that can prepare a tool definition at call time. ... This type is used to define tools parameters (aka arguments) in ToolDefinition.', 'score': 0.60358196, 'raw_content': None}, {'url': 'https://medium.com/@tam.tamanna18/building-next-level-rag-with-strategies-for-better-ai-answers-7aae54e51b5e', 'title': 'Building Next-Level RAG with Strategies for Better AI Answers', 'content': 'Missing: input parameters calling', 'score': 0.29675663, 'raw_content': None}, {'url': 'https://medium.com/data-science-collective/building-a-data-analyst-agent-with-streamlit-and-pydantic-ai-step-by-step-guide-part-1-6403fd2ec243', 'title': 'Building a Data Analyst Agent with Streamlit and Pydantic-AI - Medium', 'content': '# Building a Data Analyst Agent with Streamlit and Pydantic-AI Welcome to Part 1 of our hands-on tutorial series where we embark on a truly modern adventure: building your very own Data Analyst Agent using **pydantic-ai.** Pydantic-ai is a powerful, Python-native framework that lets you build agents (think: supercharged bots) equipped with tools for data processing, validation, and integration with language models like GPT. If you’re new to Medium, create a new account to read this story on us. ## More from Vipul Kumar and Data Science Collective ## Build Your Own Deep Research Agentic App with Streamlit and Pydantic AI ## Introducing Atomic Agents 2.0\\u200a—\\u200aThe Enterprise & Production-Friendly Way to Build AI Agents', 'score': 0.2568977, 'raw_content': None}, {'url': 'https://ai.pydantic.dev/api/usage/', 'title': 'pydantic_ai.usage - Pydantic AI', 'content': '\"\"\"      requests: int = 0     \"\"\"Number of requests made to the LLM API.\"\"\"      input_tokens: int = 0     \"\"\"Total number of text input/prompt tokens.\"\"\"      cache_write_tokens: int = 0     \"\"\"Total number of tokens written to the cache.\"\"\"     cache_read_tokens: int = 0     \"\"\"Total number of tokens read from the cache.\"\"\"      input_audio_tokens: int = 0     \"\"\"Total number of audio input tokens.\"\"\"     cache_audio_read_tokens: int = 0     \"\"\"Total number of audio tokens read from the cache.\"\"\"      output_tokens: int = 0     \"\"\"Total number of text output/completion tokens.\"\"\"      details: dict[str, int] = dataclasses.field(default_factory=dict)     \"\"\"Any extra details returned by the model.\"\"\"      def incr(self, incr_usage: RunUsage | RequestUsage) -> None:         \"\"\"Increment the usage in place. \"\"\"         if isinstance(incr_usage, RunUsage):             self.requests += incr_usage.requests         return _incr_usage_tokens(self, incr_usage)      def __add__(self, other: RunUsage | RequestUsage) -> RunUsage:         \"\"\"Add two RunUsages together.', 'score': 0.16353923, 'raw_content': None}, {'url': 'https://auth0.com/blog/secure-third-party-tool-calling-python-fastapi-auth0-langchain-langgraph/', 'title': 'Secure Third-Party Tool Calling: A Guide to LangGraph Tool ... - Auth0', 'content': 'In our last article about LangChain and First Party tool calling, we created an application to manage a fictional Zoo company: the Zoo AI. The management application It was divided into two projects: a traditional REST API backend protected with Auth0 and with Role-Based Access Control (RBAC), and a LangChain integrated project with a frontend in which Zoo employees were able to send messages to an AI that would decide the best course of action based on the situation and the user role. You’ll learn how to protect a FastAPI API with Auth0 and to implement agent frontend that uses LangChain tool calling to interact with it securely. with_send_email_gmail = auth0_ai.with_federated_connection(  ask_for_veterinarian_supplies_tool = with_send_email_gmail(  ask_for_cleaning_supplies_tool = with_send_email_gmail( ', 'score': 0.062749125, 'raw_content': None}], 'response_time': 1.29, 'request_id': 'f14d0cd3-ca15-4b0c-be25-dd2955c772c6'}, tool_call_id='pyd_ai_201d34b2d3f149d28c41759fc8598bd9', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 8, 941368, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI structuring agent responses outputs Pydantic-compatible JSON response_model PydanticOutputParser parsing errors retries', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Agents - Pydantic AI', 'url': 'https://ai.pydantic.dev/agents/', 'content': 'Model (Run) Settings. Pydantic AI offers a settings.ModelSettings structure to help you fine tune your requests. Model errors . If models behave unexpectedly (e.g., the retry limit is exceeded, or their API returns 503), agent runs will raise UnexpectedModelBehavior.', 'score': 0.5008063, 'raw_content': None}, {'title': 'Unexpected string validation error in Langchain Pydantic output parser', 'url': 'https://stackoverflow.com/questions/78591465/unexpected-string-validation-error-in-langchain-pydantic-output-parser', 'content': '# Unexpected string validation error in Langchain Pydantic output parser The docs do not seem correct - If I follow this exactly (i.e. use `with_structured_output` exclusively, without an output parser) then the output is a dict, not Pydantic class. from langchain.output_parsers import PydanticOutputParser Output parsers in Langchain receive a string, not structured data. > Output parsers are classes that help structure language model responses. Follow up question: Why does my example above using with\\\\_structured\\\\_ouput return a dict while the example in the docs returns the model (without needing to `.parse_obj`)? Find the answer to your question by asking. Error when using a custom Pydantic class for structured output with Langchain', 'score': 0.4767995, 'raw_content': None}, {'title': 'PydanticOutputParser failing with gpt-4o - works with gpt-4-turbo...', 'url': 'https://github.com/langchain-ai/langchain/discussions/21635', 'content': \"suggestives_ parser = PydanticOutputParser ( pydantic _object=SuggestiveQuestions).Modify the Language Model Prompt: If the output structure still doesn't match, consider modifying the prompt to ensure the output from gpt-4o aligns with your Pydantic model 's expectations.\", 'score': 0.44463772, 'raw_content': None}, {'title': \"Control LLM output with LangChain's structured and Pydantic output ...\", 'url': 'https://atamel.dev/posts/2024/12-09_control_llm_output_langchain_structured_pydantic/', 'content': \"# Control LLM output with LangChain's structured and Pydantic output parsers In my previous Control LLM output with response type and schema post, I talked about how you can define a JSON response schema and Vertex AI makes sure the output of the In this post, I show how you can implement a similar response schema using LangChain’s structured output parser output_parser = StructuredOutputParser.from_response_schemas(response_schemas) to make sure LLM outputs conform to that model and also get the output parsed into Python classes. Define a Pydantic output parser with the `Recipes` class and get the format instructions: output_parser = PydanticOutputParser(pydantic_object=Recipes) Format instructions: The output should be formatted as a JSON instance that conforms to the JSON schema below.\", 'score': 0.36215726, 'raw_content': None}, {'title': 'Supercharging Your AI Agents with Pydantic ... - DEV Community', 'url': 'https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk', 'content': 'Supercharging Your AI Agents with Pydantic: A Developer\\'s Guide 🚀 - DEV Community Image 8: Cover image for Supercharging Your AI Agents with Pydantic: A Developer\\'s Guide 🚀 Pydantic doesn\\'t just validate - it tries to convert data to the right type when possible. Let\\'s look at how developers are using Pydantic with AI agents in the wild: Define Pydantic models that capture exactly what you need from your AI agent. recommendation = ProductRecommendation.model_validate_json(ai_response) print(f\"AI output validation failed: {e}\") recommendation = MovieRecommendation.model_validate_json(ai_response) print(f\"Error validating AI response: {e}\") from pydantic import BaseModel, Field, validator Pydantic is more than just a validation library - it\\'s your AI agent\\'s best friend! The next time you\\'re building an AI agent, take the time to define your data models with Pydantic.', 'score': 0.35655922, 'raw_content': None}], 'response_time': 3.86, 'request_id': '6ba98ce6-f79f-448c-9c4a-bb5aed73f1c1'}, tool_call_id='pyd_ai_9bab8fb920f74a988b294d9e9292ac13', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 11, 511856, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI managing agent state memory Pydantic models conversation history AgentState example', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://github.com/pydantic/pydantic-ai/issues/196', 'title': 'Memory Implementation #196 - pydantic/pydantic-ai - GitHub', 'content': '{{ message }} ### samuelcolvin commented on Dec 9, 2024 We definitely don\\'t want to anoint a specific database in PydanticAI, we could perhaps have some kind of abstract storage class with some basic implementations to store and load messages, but I wonder how useful that would actually be? ### dsolito commented on Dec 9, 2024 from pydantic_ai.messages import Message \"\"\"State manager for chat history.\"\"\" description=\"Chat conversation history\", def append_messages(self, new_messages: List[Message]) -> None: \"\"\"Add new messages to history.\"\"\" return f\"This conversation has {len(ctx.deps.messages)} previous messages.\" message_history=chat_state.messages # Update history with new messages chat_state.append_messages(result.new_messages()) ### samuelcolvin commented on Dec 10, 2024 ### sydney-runkle commented on Dec 10, 2024 ### pietz commented on Dec 16, 2024 Memory Implementation · Issue #196 · pydantic/pydantic-ai', 'score': 0.6496014, 'raw_content': None}, {'url': 'https://ai.pydantic.dev/message-history/', 'title': 'Messages and chat history - Pydantic AI', 'content': \"The primary use of message histories in Pydantic AI is to maintain context across multiple agent runs. result2 = agent.run_sync('Explain?', message_history=result1.new_messages()) In the example below, we reuse the message from the first agent run, which uses the `openai:gpt-4o` model, in a second agent run using the `google-gla:gemini-1.5-pro` model. message_history = [ # When you run the agent, the history processor will filter out ModelResponse messages # result = agent.run_sync('What about 3+3?', message_history=message_history) You can use the `history_processor` to only keep the recent messages: agent = Agent('openai:gpt-4o', history_processors=[keep_recent_messages]) # result = agent.run_sync('What did we discuss?', message_history=long_conversation_history) summary = await summarize_agent.run(message_history=oldest_messages) agent = Agent('openai:gpt-4o', history_processors=[summarize_old_messages]) def test_history_processor(function_model: FunctionModel, received_messages: list[ModelMessage]): message_history = [ agent.run_sync('Question 2', message_history=message_history) agent = Agent('openai:gpt-4o', history_processors=[filter_responses, summarize_old_messages])\", 'score': 0.63452125, 'raw_content': None}, {'url': 'https://learnitnow.medium.com/unlock-your-ais-memory-a-practical-guide-to-pydantic-ai-agents-mongodb-09476ddc2963', 'title': \"Unlock Your AI's Memory: A Practical Guide to Pydantic-AI Agents ...\", 'content': '(MongoDB configuration and MongoHistoryAdapter will be added later) ...# Define your Pydantic model for the tool\\'s inputclass FlightBookingInput(BaseModel):    origin: str = Field(description=\"The departure city or airport code, e.g., \\'Delhi\\' or \\'DEL\\'\")    destination: str = Field(description=\"The arrival city or airport code, e.g., \\'Bangalore\\' or \\'BLR\\'\")    departure_date: str = Field(description=\"The date of departure in YYYY-MM-DD format, e.g., \\'2025-06-25\\'\")    return_date: str | None = Field(None, description=\"The date of return in YYYY-MM-DD format (optional for one-way flights)\")    num_passengers: int = Field(1, description=\"The number of passengers (default is 1)\")# Agent definitionagent = Agent(    \\'google-gla:gemini-2.0-flash-exp\\', # Specify the LLM model to use    system_prompt=\"\"\"    You are a highly intelligent and helpful flight booking assistant. Load existing messages from MongoDB    stored_docs = list(messages_collection.find({SESSION_ID_FIELD: session_id}).sort(\"created_at\", pymongo.ASCENDING))    if stored_docs:        # Load the simple dicts first        simple_history_for_db = mongo_adapter.load_json_to_python(stored_docs)        # Convert them to pydantic-ai\\'s message objects for the agent        # The load_json_to_python method now directly returns ModelRequest/ModelResponse        message_history_for_agent = simple_history_for_db # Renamed for clarity in this example    print(f\"Loaded {len(message_history_for_agent)} messages from history for session \\'{session_id}\\'.\")    if not message_history_for_agent:        print(\"Welcome to the Flight Booking Assistant!', 'score': 0.6337056, 'raw_content': None}, {'url': 'https://scenario.langwatch.ai/agent-integration/pydantic-ai/', 'title': 'Pydantic AI Integration - What is Scenario? - LangWatch', 'content': 'Aug 1, 2025·Pydantic AI agents work seamlessly with Scenario through the AgentAdapter interface. The key is managing conversation history and handling the', 'score': 0.572078, 'raw_content': None}, {'url': 'https://ai.pydantic.dev/agents/', 'title': 'Agents - Pydantic AI', 'content': \"Agents are Pydantic AI's primary interface for interacting with LLMs. In some use cases a single Agent will control an entire application or component.Pydantic_ai.agent·Pydantic_ai.models·Pydantic_ai.usage·Pydantic_ai.settings\", 'score': 0.4902606, 'raw_content': None}], 'response_time': 1.35, 'request_id': '83338d73-a4de-4b06-b5f9-7d22628ac445'}, tool_call_id='pyd_ai_50ff4b95846448c2bdf08e84093331cf', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 9, 4128, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='tavily_search', content={'query': 'Pydantic-AI integration LangChain create_structured_output_chain tool decorators LlamaIndex PydanticProgram structured outputs', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://python.langchain.com/api_reference/langchain/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html', 'title': 'create_structured_output_chain — LangChain documentation', 'content': \"# create\\\\_structured\\\\_output\\\\_chain# langchain.chains.openai\\\\_functions.base.create\\\\_structured\\\\_output\\\\_chain( :   *output\\\\_schema: dict[str, Any] | type[BaseModel]*, :   *output\\\\_key: str = 'function'*, ) → LLMChain#:   Deprecated since version 0.1.1: Use `with_structured_output()` instead. [Legacy] Create an LLMChain that uses an OpenAI function to get a structured output. :   * **output\\\\_schema** (*dict**[**str**,* *Any**]* *|* *type**[**BaseModel**]*) – Either a dictionary or pydantic.BaseModel class. * **llm** (*BaseLanguageModel*) – Language model to use, assumed to support the OpenAI function-calling API. * **output\\\\_key** (*str*) – The key to use when returning the output in LLMChain.\\\\_\\\\_call\\\\_\\\\_. * **output\\\\_parser** (*BaseLLMOutputParser* *|* *None*) – BaseLLMOutputParser to use for parsing model outputs. :   An LLMChain that will pass the given function to the model. from langchain.chains.openai_functions import create_structured_output_chain chain = create_structured_output_chain(Dog, llm, prompt) Examples using create\\\\_structured\\\\_output\\\\_chain\", 'score': 0.6768127, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=Rpg9TQtqqhE', 'title': 'AI Structured Outputs with LLMs, LlamaIndex & Pydantic - YouTube', 'content': \"AI Structured Outputs with LLMs, LlamaIndex & Pydantic\\nBugBytes\\n47800 subscribers\\n141 likes\\n3803 views\\n4 Aug 2025\\n🙏 Join our channel to get access to perks:\\nhttps://www.youtube.com/channel/UCTwxaBjziKfy6y_uWu30orA/join\\n\\n☕️ 𝗕𝘂𝘆 𝗺𝗲 𝗮 𝗰𝗼𝗳𝗳𝗲𝗲:\\nTo support the channel and encourage new videos, please consider buying a coffee here:\\nhttps://ko-fi.com/bugbytes\\n\\nIn this video, we'll look at how to take LLM text output, and convert it to a structured format using Pydantic model classes. We'll look at how to achieve this with LlamaIndex Structured LLMs.\\n\\n📌 𝗖𝗵𝗮𝗽𝘁𝗲𝗿𝘀:\\n00:00 Intro to Structured Outputs\\n01:20 Introduction to LlamaIndex and Pydantic\\n05:38 Data Extraction - PDF raw text to Pydantic model via OpenAI model\\n\\n𝗦𝗼𝗰𝗶𝗮𝗹 𝗠𝗲𝗱𝗶𝗮:\\n📖 Blog: https://bugbytes.io/posts/\\n👾 Github: https://github.com/bugbytes-io/\\n\\n📚 𝗙𝘂𝗿𝘁𝗵𝗲𝗿 𝗿𝗲𝗮𝗱𝗶𝗻𝗴 𝗮𝗻𝗱 𝗶𝗻𝗳𝗼𝗿𝗺𝗮𝘁𝗶𝗼𝗻:\\nSample PDF: https://slicedinvoices.com/pdf/wordpress-pdf-invoice-plugin-sample.pdf\\nLlamaIndex: https://www.llamaindex.ai/\\nLlamaIndex Structured Data Extraction: https://docs.llamaindex.ai/en/stable/understanding/extraction/\\nPydantic Playlist: https://youtube.com/playlist?list=PL-2EBeDYMIbT1M9S9PEFlqJ9SgFYYbIKp\\n\\n#llms #llamaindex #openai\\n14 comments\\n\", 'score': 0.5889134, 'raw_content': None}, {'url': 'https://python.langchain.com/docs/concepts/structured_outputs/', 'title': 'Structured outputs - ️   LangChain', 'content': 'LangChain provides a method, `with_structured_output()`, that automates the process of binding the schema to the model and parsing the output. bind_tools([tool1,  tool2]) structured_model = model_with_tools.with_structured_output(schema) structured_model =  model_with_tools. # Incorrect - will cause tool resolution errors structured_model = model.with_structured_output(schema) structured_model =  model. with_structured_output(schema) broken_model = structured_model.bind_tools([tool1, tool2]) broken_model =  structured_model. with_structured_output(method = \"json_mode\") ai_msg = model.invoke(\"Return a JSON object with key \\'random_ints\\' and a value of 10 random ints in [0-99]\") ai_msg =  model. 2. In addition, the model needs to be instructed to *always* use the tool when we want to enforce structured output, which is a provider specific setting. This both binds the schema to the model as a tool and parses the output to the specified output schema.', 'score': 0.5660431, 'raw_content': None}, {'url': 'https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/', 'title': 'Pydantic Programs - LlamaIndex', 'content': 'Pydantic Programs are a lower-level abstraction for structured output extraction, converting input strings into structured Pydantic objects. They are generic', 'score': 0.54477775, 'raw_content': None}, {'url': 'https://github.com/pydantic/pydantic-ai/issues/582', 'title': 'Structured outputs as an alternative to Tool Calling #582 - GitHub', 'content': 'Jan 1, 2025·Issue Description: Currently, pydantic-ai implements structured output solely using tool-calling APIs from model providers.', 'score': 0.51032627, 'raw_content': None}], 'response_time': 5.39, 'request_id': '31e45fc7-1e93-4848-8721-be88a1af650d'}, tool_call_id='pyd_ai_8a8e512e46df4547b20336b98a463290', timestamp=datetime.datetime(2025, 9, 3, 19, 45, 13, 187893, tzinfo=datetime.timezone.utc))], instructions=\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the DuckDuckGo MCP server. Follow these steps to complete the task:\\n\\n                1. Review the provided outline\\n\\n                2. For each section and subsection in the outline:\\n                a. Use the DuckDuckGo MCP server to search for current information related to the topic.\\n                b. Review the search results and identify the most relevant and reliable sources.\\n                c. After fetching the content, analyze and summarize the information relevant to the outline section.\\n\\n                3. Write the report section by section, following the structure of the outline. For each section:\\n                a. Provide a brief introduction to the topic.\\n                b. Include relevant information gathered from your research.\\n                c. Ensure that the content is well-organized and flows logically.\\n                d. Use appropriate transitions between subsections and main sections.\\n\\n                4. Throughout the writing process, keep track of the sources you've used. For each source, note:\\n                - The title of the webpage or article\\n                - The author (if available)\\n                - The website name\\n                - The URL\\n                - The date you accessed the information\"))\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:web_deep_researcher:Node: CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'sections': [{'title': 'I. Introduction', 'references': 'The Rise of AI Agents—Collaborative Intelligence - CyberArk (https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence); Introduction to AI Agents - Build with Cerebras Inference (https://inference-docs.cerebras.ai/agent-bootcamp/section-1); Agent Components - Prompt Engineering Guide (https://www.promptingguide.ai/agents/components); Pydantic AI (https://ai.pydantic.dev/); The Power of Pydantic: Bringing Structure and Validation to Your ... (https://medium.com/@shouke.wei/the-power-of-pydantic-bringing-structure-and-validation-to-your-python-data-9de124362a6f); Pydantic: Simplifying Data Validation in Python (https://realpython.com/python-pydantic/)', 'content': \"The landscape of artificial intelligence is rapidly evolving, with AI agents emerging as a transformative force. These autonomous systems are designed to perform complex tasks, make informed decisions, and continuously learn from their interactions within various environments. From automating intricate workflows to enhancing human-computer collaboration, the rise of AI agents promises unprecedented levels of productivity and innovation. However, this increased autonomy also brings a critical need for reliable and predictable interactions. As AI agents become more deeply integrated into critical systems, ensuring their outputs are structured, validated, and consistently reliable is paramount to prevent errors, maintain data integrity, and foster trust.\\n\\nThis report introduces Pydantic-AI, a powerful framework built upon the robust data validation capabilities of Pydantic, specifically tailored for the development of AI agents. Pydantic's core purpose lies in its ability to define data schemas using Python type hints, enabling runtime data validation, parsing, and serialization. Pydantic-AI extends these capabilities to the realm of large language models (LLMs) and agentic workflows, providing a crucial mechanism for enforcing structured and reliable data exchange.\\n\\nThe central thesis of this report is that Pydantic-AI significantly enhances AI agent development by guaranteeing structured, validated data exchange throughout the agent's lifecycle—from tool definitions to response parsing and memory management. This foundational assurance leads to more robust, predictable, and maintainable AI applications.\\n\\nThis report will explore the core concepts of Pydantic-AI, delve into the fundamental components of AI agents, and illustrate the powerful synergy between them. It will provide a practical guide to building agents with Pydantic-AI, covering tool definition, response structuring, and memory management, alongside its integration with popular agent frameworks. Finally, it will discuss advanced concepts and best practices for leveraging Pydantic-AI to create highly reliable and efficient AI agents.\"}, {'references': 'Models - Pydantic (https://docs.pydantic.dev/latest/concepts/models/); Pydantic: Simplifying Data Validation in Python (https://realpython.com/python-pydantic/); Supercharging Your AI Agents with Pydantic ... - DEV Community (https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk); Pydantic AI (https://ai.pydantic.dev/); Enforce Structured Outputs from LLMs with PydanticAI - CodeCut (https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/); Structured Outputs from LLM using Pydantic | by Harisudhan.S (https://medium.com/@speaktoharisudhan/structured-outputs-from-llm-using-pydantic-1a36e6c3aa07); Pydantic: A Guide With Practical Examples - DataCamp (https://www.datacamp.com/tutorial/pydantic)', 'title': 'II. Understanding Pydantic-AI', 'content': 'Pydantic-AI is an agent framework that builds upon the established foundation of Pydantic, a highly regarded Python library for data validation and settings management. To fully grasp Pydantic-AI\\'s utility, it\\'s essential to first understand the core concepts of Pydantic itself.\\n\\n### A. Core Concepts of Pydantic\\n\\n1.  **`BaseModel` for data schema definition.** At the heart of Pydantic is the `BaseModel` class. By inheriting from `BaseModel`, developers can define explicit data schemas using standard Python type hints. This declarative approach creates a clear contract for the structure and types of expected data.\\n\\n2.  **Type hinting and automatic validation.** Pydantic leverages Python\\'s native type hints to perform automatic runtime validation. When data is passed to a `BaseModel`, Pydantic rigorously checks whether it conforms to the defined types and any additional constraints, raising informative errors if discrepancies are found. This significantly reduces boilerplate code traditionally used for manual validation.\\n\\n3.  **Data parsing and serialization.** Beyond validation, Pydantic excels at data parsing and serialization. It can intelligently convert incoming data (e.g., from JSON or forms) into the correct Python types and objects defined by the `BaseModel`. Conversely, it can easily serialize Pydantic models back into structured formats like JSON, making data exchange seamless.\\n\\n### B. Pydantic-AI Specifics\\n\\nPydantic-AI extends Pydantic\\'s core capabilities with features specifically designed for the unique challenges of AI and Large Language Model (LLM) interactions. While Pydantic provides the underlying validation engine, Pydantic-AI acts as a specialized layer to apply this power to agent development.\\n\\n1.  **Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).** Pydantic-AI functions as a dedicated agent framework for working with LLMs, aiming to streamline the development of production-grade generative AI applications. It directly integrates Pydantic models to define and enforce structured outputs from LLMs. Concepts like an `output_type` parameter in Pydantic-AI agents allow developers to link a Pydantic model, ensuring the LLM\\'s response adheres to that specific structure.\\n\\n2.  **How it helps enforce LLM output formats.** One of the primary challenges with LLMs is their tendency to produce varied and unstructured text. Pydantic-AI tackles this by enabling developers to define a `Pydantic` Model that dictates the precise structure and types of the expected LLM output. This model acts as a blueprint, guiding the LLM (often through prompt instructions or function calling mechanisms) to generate Pydantic-compatible JSON. Frameworks often use mechanisms like `PydanticOutputParser` to parse the LLM\\'s raw string output into a validated Pydantic object, making the output reliably structured for downstream processing.\\n\\n### C. Simple Examples: Defining a basic data structure with Pydantic-AI\\n\\nA simple Pydantic-AI data structure would look identical to a standard Pydantic `BaseModel`. For instance, to define a structured output for an agent that extracts user information:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\nclass UserInfo(BaseModel):\\n    name: str = Field(description=\"The full name of the user\")\\n    age: int = Field(description=\"The age of the user\")\\n    email: str | None = Field(None, description=\"The user\\'s email address, if available\")\\n    is_subscribed: bool = Field(False, description=\"Whether the user is subscribed to the newsletter\")\\n\\n# An AI agent could be instructed to output data conforming to this UserInfo model.\\n```\\n\\nThis `UserInfo` model, when integrated with a Pydantic-AI agent, would ensure that any extracted user information from an LLM adheres to these specified types and fields, providing a reliable and validated data object.'}, {'content': \"To appreciate the value Pydantic-AI brings, it's crucial to understand the foundational architecture and components of AI agents.\\n\\n### A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n\\nAn AI agent is an increasingly autonomous software system that utilizes Large Language Models (LLMs) as its central intelligence. Unlike simpler AI models, agents are designed to perceive their environment, interpret complex inputs, reason through problems, make decisions, and perform tasks. Their enhanced capabilities stem from integrating several key components: planning abilities to strategize, tool utilization to interact with the external world, and memory systems to retain context and learn from past experiences. This combination allows them to execute multi-step plans and adapt their strategies dynamically.\\n\\n### B. Key Components of an Agent\\n\\n1.  **Large Language Models (LLMs).** The LLM serves as the agent's brain, providing the ability to understand natural language, generate human-like text, and perform complex reasoning tasks. It's responsible for interpreting user requests, generating internal thoughts, and formulating responses.\\n\\n2.  **Tools/Functions: How agents interact with the external world.** Tools are external resources, APIs, or specific functions that extend the LLM's capabilities. Agents use tools to perform actions in the real world, such as searching the internet, making calculations, sending emails, or interacting with databases. These tools allow the agent to move beyond purely linguistic tasks and perform concrete operations.\\n\\n3.  **Memory: Short-term and long-term context retention.** Memory systems enable agents to store and retrieve information, maintaining a persistent context across multiple interactions. Short-term memory might include the current conversation history, while long-term memory could store learned facts, user preferences, or past experiences, allowing the agent to build upon prior knowledge and iterative improvement.\\n\\n4.  **Reasoning and Planning.** Agents employ reasoning to analyze problems, interpret inputs, and determine the best course of action. Planning involves breaking down complex goals into a series of manageable steps. During this phase, the agent considers the user's request, available tools, and the necessary information to achieve its objective, formulating a logical sequence of operations.\\n\\n5.  **Action and Execution.** Once a plan is formulated, the agent executes the actions. This often involves calling specific tools with appropriate parameters to interact with the environment and achieve the desired outcomes. The results of these actions are then fed back into the agent's reasoning process.\\n\\n### C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nSeveral open-source frameworks have emerged to facilitate the development and deployment of AI agents. **LangChain** is a widely used framework known for building LLM-powered applications and agents, offering components for chaining operations, managing conversational memory, and integrating tools. It's particularly useful for developing agents with straightforward to complex workflows. **LlamaIndex** is another prominent data orchestration framework focused on integrating LLMs with external data sources, making it excellent for retrieval-augmented generation (RAG) and agentic solutions that require structured data extraction and querying. These frameworks provide the architectural scaffolding upon which sophisticated AI agents can be built.\", 'references': 'The Rise of AI Agents—Collaborative Intelligence - CyberArk (https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence); LLM Agents - GeeksforGeeks (https://www.geeksforGeeks.org/artificial-intelligence/llm-agents/); Introduction to AI Agents - Build with Cerebras Inference (https://inference-docs.cerebras.ai/agent-bootcamp/section-1); Agent Components - Prompt Engineering Guide (https://www.promptingguide.ai/agents/components); Understanding MCP features: Tools, Resources, Prompts, Sampling ... (https://workos.com/blog/mcp-features-guide); AI Agent Frameworks: Choosing the Right Foundation for Your ... - IBM (https://www.ibm.com/think/insights/top-ai-agent-frameworks); Navigating the AI Framework Landscape: LlamaIndex, LangChain ... (https://medium.com/@ajayverma23/navigating-the-ai-framework-landscape-llamaindex-langchain-and-beyond-e377bbc0e1c4); Comparing Open-Source AI Agent Frameworks - Langfuse Blog (https://langfuse.com/blog/2025-03-19-ai-agent-comparison)', 'title': 'III. Fundamentals of AI Agents'}, {'content': \"The burgeoning field of AI agents presents both immense opportunities and significant challenges, particularly concerning the reliability and structure of data. Pydantic-AI emerges as a crucial solution, forging a powerful synergy with agent development by addressing these inherent complexities.\\n\\n### A. The Problem: Unreliable, unstructured outputs from LLMs.\\n\\nOne of the most persistent challenges in building production-ready AI applications is the inherent unpredictability of Large Language Model (LLM) outputs. LLMs, by their nature, are designed for flexibility and creativity, often generating text that is unstructured, inconsistent, or even prone to 'hallucinations'—producing confidently presented but incorrect information. This lack of a guaranteed, structured format makes it exceedingly difficult to reliably integrate LLM responses into downstream systems, which often require precise data types and schemas. Developers frequently grapple with parsing errors, ambiguous responses, and the general unreliability of extracting specific pieces of information from free-form text, leading to fragile and difficult-to-maintain applications.\\n\\n### B. The Solution: Pydantic-AI for guaranteed data structures.\\n\\nPydantic-AI directly addresses the problem of unstructured LLM outputs by leveraging Pydantic's robust data validation and modeling capabilities. It allows developers to define explicit, type-hinted data schemas for virtually any data exchange within an agent's workflow. By enforcing these predefined structures, Pydantic-AI ensures that the data generated by LLMs, whether it's an agent's action, an observation, or a tool's output, conforms to a precise and expected format. This guarantee of structured data transforms unreliable text into actionable, validated Python objects, significantly enhancing the determinism and reliability of AI agents.\\n\\n### C. Key Benefits:\\n\\nThe integration of Pydantic-AI into agent development yields several critical benefits:\\n\\n1.  **Reliable Tool Definitions:** Pydantic-AI empowers developers to define the input parameters for agent tools with explicit `BaseModel` schemas. This ensures that when an LLM decides to use a tool, the arguments it generates are automatically validated against the defined schema, preventing incorrect function calls and ensuring tools receive consistently formatted data. This creates a clear and reliable contract for tool interaction.\\n\\n2.  **Robust Response Parsing:** With Pydantic-AI, agent outputs—such as the agent's 'thought' process, the 'action' it decides to take, or the 'observation' from a tool—can be constrained to a specific Pydantic model. This means that LLM responses are not just free-form text but structured JSON that can be reliably parsed and validated into Python objects, making subsequent processing and decision-making far more robust.\\n\\n3.  **Structured Agent State/Memory:** Pydantic models are exceptionally well-suited for managing an agent's internal state and memory. Conversation histories, learned facts, long-term goals, and other crucial contextual information can be stored as Pydantic-validated objects. This ensures consistency and easy retrieval of memory components, allowing agents to maintain coherent context and learn effectively across interactions.\\n\\n4.  **Reduced Boilerplate & Improved Readability:** By leveraging Python type hints and `BaseModel`, Pydantic-AI significantly reduces the amount of boilerplate code typically required for manual data validation and parsing. This leads to cleaner, more concise, and highly readable agent code, allowing developers to focus more on agent logic and less on data wrangling.\\n\\n5.  **Enhanced Debugging and Error Handling:** The automatic validation provided by Pydantic-AI catches data inconsistencies and type errors at runtime, often with clear and informative error messages. This greatly enhances the debugging process, allowing developers to quickly pinpoint issues related to malformed LLM outputs or incorrect data flows. It also facilitates the implementation of robust error-handling and retry mechanisms, making agents more resilient to unexpected inputs.\", 'references': \"[D] Is anyone else having trouble with the unstructured output from ... (https://www.reddit.com/r/MachineLearning/comments/1dyxiw4/d_is_anyone_else_having_trouble_with_the/); LLM's Insecure Output Handling: Best Practices and Prevention (https://coralogix.com/ai-blog/llms-insecure-output-handling-best-practices-and-prevention/); Reliability for unreliable LLMs - The Stack Overflow Blog (https://stackoverflow.blog/2025/06/30/reliability-for-unreliable-llms/); PydanticAI: The Next-Generation AI Agent Framework for LLMs (https://www.technovera.com/it-blogs/pydanticai-the-next-generation-ai-agent-framework-for-llms/); Pydantic AI Development Services | Reliable Data Modeling by EvinceDev (https://evincedev.com/generative-ai-applications-development-with-pydanticai); Pydantic.ai: Building Smarter, Type-Safe AI Agents - Cuttlesoft (https://cuttlesoft.com/blog/2024/12/11/pydantic-ai-building-smarter-type-safe-ai-agents/); Pydantic : A Guide With Practical Examples | DataCamp (https://www.datacamp.com/tutorial/pydantic); Introduction to Python Pydantic Library - GeeksforGeeks (https://www.geeksforgeeks.org/python/introduction-to-python-pydantic-library/); What is Pydantic ? | by LEARNMYCOURSE | Medium (https://learnmycourse.medium.com/what-is-pydantic-751ba6f452c5); Building your own CLI Coding Agent with Pydantic -AI (https://martinfowler.com/articles/build-own-coding-agent.html)\", 'title': 'IV. The Synergy: Why Pydantic-AI for Agent Development?'}, {'title': 'V. Practical Guide: Building Agents with Pydantic-AI', 'content': 'Building effective AI agents requires careful structuring of interactions, from defining the capabilities of tools to managing conversational context. Pydantic-AI provides a robust framework for ensuring these interactions are type-safe, validated, and reliable.\\n\\n### A. Defining Agent Tools with Pydantic-AI:\\n\\nAgent tools allow LLMs to interact with the external world. Pydantic-AI simplifies the definition of these tools and their input parameters, ensuring clarity and reliability in function calls.\\n\\n1.  **Using `BaseModel` to describe tool input parameters.** The most fundamental step is to use Pydantic\\'s `BaseModel` to define the schema for a tool\\'s expected input. This creates a clear, self-documenting contract for the arguments the tool accepts, complete with type hints and descriptions.\\n\\n2.  **Examples: A search tool, a calculator tool, defined with Pydantic-AI.** Consider a `SearchTool` or a `CalculatorTool`. Their input parameters can be precisely defined using `BaseModel`:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n\\n    class SearchInput(BaseModel):\\n        query: str = Field(description=\"The search query to execute\")\\n        num_results: int = Field(5, description=\"Maximum number of search results to return\")\\n\\n    class CalculatorInput(BaseModel):\\n        expression: str = Field(description=\"The mathematical expression to evaluate, e.g., \\'2 + 2 * 3\\'\")\\n    ```\\n\\n    A practical example from Pydantic-AI demonstrates defining tool inputs for a flight booking agent:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n\\n    class FlightBookingInput(BaseModel):\\n        origin: str = Field(description=\"The departure city or airport code, e.g., \\'Delhi\\' or \\'DEL\\'\")\\n        destination: str = Field(description=\"The arrival city or airport code, e.g., \\'Bangalore\\' or \\'BLR\\'\")\\n        departure_date: str = Field(description=\"The date of departure in YYYY-MM-DD format, e.g., \\'2025-06-25\\'\")\\n        return_date: str | None = Field(None, description=\"The date of return in YYYY-MM-DD format (optional for one-way flights)\")\\n        num_passengers: int = Field(1, description=\"The number of passengers (default is 1)\")\\n    ```\\n\\n3.  **Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).** These Pydantic `BaseModel` schemas for tool inputs can be directly provided to LLM function calling mechanisms (like those offered by OpenAI). The LLM is then instructed to generate function call arguments that conform precisely to these defined Pydantic models. This integration ensures that the LLM\\'s intent to use a tool translates into a validated and executable function call.\\n\\n### B. Structuring Agent Responses and Outputs:\\n\\nEnsuring that an agent\\'s internal thoughts, actions, and observations are consistently formatted is crucial for reliable agentic behavior. Pydantic-AI provides powerful mechanisms for this.\\n\\n1.  **Guiding LLMs to produce Pydantic-compatible JSON.** By defining a `BaseModel` for the expected output structure, developers can effectively guide LLMs to generate responses in a JSON format that is compatible with that Pydantic model. This transforms the LLM\\'s free-form text generation into structured data output.\\n\\n2.  **Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).** In frameworks like LangChain, a `PydanticOutputParser` can be used. This parser takes a Pydantic `BaseModel` and generates formatting instructions that are injected into the LLM\\'s prompt, instructing it to produce JSON conforming to the model. The parser then takes the LLM\\'s string output and parses it into a Pydantic object, validating it in the process. Pydantic-AI agents themselves often offer an `output_type` parameter to directly link a Pydantic model to the agent\\'s output, achieving similar structured output enforcement.\\n\\n3.  **Handling parsing errors and retries.** Pydantic\\'s inherent validation capabilities mean that if an LLM fails to produce output conforming to the `BaseModel`, a `ValidationError` is raised. Pydantic-AI agents can also raise `UnexpectedModelBehavior` for issues like exceeding retry limits. Developers can implement robust error handling by catching these validation errors and implementing retry mechanisms, such as re-prompting the LLM with more explicit instructions or adjusting the model\\'s parameters, to encourage a correct output format.\\n\\n### C. Managing Agent State and Memory:\\n\\nMaintaining context and memory is vital for conversational and intelligent agents. Pydantic models provide an excellent way to structure and manage this state.\\n\\n1.  **Using Pydantic models for storing conversation turns, facts, or observations.** Pydantic models can define the schema for various memory components, such as individual `Message` objects within a conversation or `Fact` objects representing learned information. This ensures that memory elements are stored consistently and are easily retrievable for the agent\\'s reasoning process.\\n\\n2.  **Example: A `ConversationHistory` model or an `AgentState` model.** While specific Pydantic-AI frameworks might use different naming conventions, the principle involves creating `BaseModel` classes to represent the agent\\'s evolving state. For instance, a `Message` model could capture speaker, content, and timestamp, and a list of these messages would form the `ConversationHistory`. Similarly, an `AgentState` model might aggregate various pieces of information like `current_goal: str`, `known_facts: List[Fact]`, and `conversation_history: List[Message]`:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n    from typing import List, Literal\\n    from datetime import datetime\\n\\n    class Message(BaseModel):\\n        role: Literal[\"user\", \"agent\", \"tool\"] = Field(description=\"The role of the message sender\")\\n        content: str = Field(description=\"The content of the message\")\\n        timestamp: datetime = Field(default_factory=datetime.now, description=\"Timestamp of the message\")\\n\\n    class Fact(BaseModel):\\n        topic: str = Field(description=\"The topic of the learned fact\")\\n        detail: str = Field(description=\"The detailed information of the fact\")\\n        source: str | None = Field(None, description=\"Optional source of the fact\")\\n\\n    class AgentState(BaseModel):\\n        current_goal: str = Field(description=\"The agent\\'s current primary objective\")\\n        known_facts: List[Fact] = Field(default_factory=list, description=\"A list of facts the agent has learned\")\\n        conversation_history: List[Message] = Field(default_factory=list, description=\"The chronological history of messages\")\\n    ```\\n\\n    This structured approach to memory allows for clear state management and facilitates advanced agent behaviors like reflection and self-correction.\\n\\n### D. Integration with Popular Agent Frameworks (Illustrative Examples):\\n\\nPydantic-AI concepts are widely adopted and integrated into leading AI agent frameworks, enhancing their capabilities for structured interactions.\\n\\n1.  **How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).** LangChain leverages Pydantic extensively for structured outputs and tool definitions. Historically, `create_structured_output_chain` (now deprecated in favor of `with_structured_output()`) allowed developers to create LLM chains that produced structured outputs based on Pydantic `BaseModel` schemas using OpenAI\\'s function calling API. The `with_structured_output()` method directly automates the process of binding a Pydantic schema to the LLM as a tool and then parsing its output into the specified Pydantic object, streamlining the creation of reliable, type-safe agent interactions.\\n\\n2.  **How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).** LlamaIndex, an orchestration framework for LLM applications, also embraces Pydantic for structured data extraction. `PydanticPrograms` in LlamaIndex serve as a lower-level abstraction specifically designed to convert raw LLM text outputs into structured Pydantic objects. This is crucial for tasks like extracting specific entities or information from documents into a predefined schema, ensuring that the data is ready for further processing and analysis within the LlamaIndex ecosystem.', 'references': \"pydantic_ai.tools - Pydantic AI (https://ai.pydantic.dev/api/tools/); Unlock Your AI's Memory: A Practical Guide to Pydantic-AI Agents ... - Medium (https://learnitnow.medium.com/unlock-your-ais-memory-a-practical-guide-to-pydantic-ai-agents-mongodb-09476ddc2963); Supercharging Your AI Agents with Pydantic ... - DEV Community (https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk); Control LLM output with LangChain's structured and Pydantic output ... (https://atamel.dev/posts/2024/12-09_control_llm_output_langchain_structured_pydantic/); Enforce Structured Outputs from LLMs with PydanticAI - CodeCut (https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/); Agents - Pydantic AI (https://ai.pydantic.dev/agents/); Memory Implementation #196 - pydantic/pydantic-ai - GitHub (https://github.com/pydantic/pydantic-ai/issues/196); Messages and chat history - Pydantic AI (https://ai.pydantic.dev/message-history/); create_structured_output_chain — LangChain documentation (https://python.langchain.com/api_reference/langchain/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html); Structured outputs - ️ LangChain (https://python.langchain.com/docs/concepts/structured_outputs/); Pydantic Programs - LlamaIndex (https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/); AI Structured Outputs with LLMs, LlamaIndex & Pydantic - YouTube (https://www.youtube.com/watch?v=Rpg9TQtqqhE)\"}]}, tool_call_id='pyd_ai_5b060e5aebd64b3eaf9ac29f84862875'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI nested models complex agent structures'}, tool_call_id='pyd_ai_f9fd3a2da0de4391b78d07d854923fb2'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI custom validators specific agent logic'}, tool_call_id='pyd_ai_07649f75941740229522bddd8942367e'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI error handling fallback mechanisms'}, tool_call_id='pyd_ai_f9d33f7f07144dc8bd0fecae91c81971'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI testing agent behavior assertions'}, tool_call_id='pyd_ai_7d522fa3072e47e1bdb3f80735ddb832'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI performance considerations high-throughput agents'}, tool_call_id='pyd_ai_2d949b20a2014869ba2aa991ad278e41'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI future outlook structured data agent development'}, tool_call_id='pyd_ai_6162f602b2c74c4ba12e1ace5952b117'), ToolCallPart(tool_name='tavily_search', args={'query': 'Pydantic-AI efficiency maintainability final thoughts'}, tool_call_id='pyd_ai_225dbdb916b04990b3b18bce2d62d21f')], usage=RequestUsage(input_tokens=20346, cache_read_tokens=14142, output_tokens=12604, details={'cached_content_tokens': 14142, 'thoughts_tokens': 6000, 'text_prompt_tokens': 20346, 'text_cache_tokens': 14142}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 46, 12, 295578, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='BJu4aJmoCtWsmtkPopSruAw'))\n",
      "INFO:web_deep_researcher:Node: End(data=FinalResult(output=documentationOutput(sections=[Section(title='I. Introduction', content=\"The landscape of artificial intelligence is rapidly evolving, with AI agents emerging as a transformative force. These autonomous systems are designed to perform complex tasks, make informed decisions, and continuously learn from their interactions within various environments. From automating intricate workflows to enhancing human-computer collaboration, the rise of AI agents promises unprecedented levels of productivity and innovation. However, this increased autonomy also brings a critical need for reliable and predictable interactions. As AI agents become more deeply integrated into critical systems, ensuring their outputs are structured, validated, and consistently reliable is paramount to prevent errors, maintain data integrity, and foster trust.\\n\\nThis report introduces Pydantic-AI, a powerful framework built upon the robust data validation capabilities of Pydantic, specifically tailored for the development of AI agents. Pydantic's core purpose lies in its ability to define data schemas using Python type hints, enabling runtime data validation, parsing, and serialization. Pydantic-AI extends these capabilities to the realm of large language models (LLMs) and agentic workflows, providing a crucial mechanism for enforcing structured and reliable data exchange.\\n\\nThe central thesis of this report is that Pydantic-AI significantly enhances AI agent development by guaranteeing structured, validated data exchange throughout the agent's lifecycle—from tool definitions to response parsing and memory management. This foundational assurance leads to more robust, predictable, and maintainable AI applications.\\n\\nThis report will explore the core concepts of Pydantic-AI, delve into the fundamental components of AI agents, and illustrate the powerful synergy between them. It will provide a practical guide to building agents with Pydantic-AI, covering tool definition, response structuring, and memory management, alongside its integration with popular agent frameworks. Finally, it will discuss advanced concepts and best practices for leveraging Pydantic-AI to create highly reliable and efficient AI agents.\", references='The Rise of AI Agents—Collaborative Intelligence - CyberArk (https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence); Introduction to AI Agents - Build with Cerebras Inference (https://inference-docs.cerebras.ai/agent-bootcamp/section-1); Agent Components - Prompt Engineering Guide (https://www.promptingguide.ai/agents/components); Pydantic AI (https://ai.pydantic.dev/); The Power of Pydantic: Bringing Structure and Validation to Your ... (https://medium.com/@shouke.wei/the-power-of-pydantic-bringing-structure-and-validation-to-your-python-data-9de124362a6f); Pydantic: Simplifying Data Validation in Python (https://realpython.com/python-pydantic/)'), Section(title='II. Understanding Pydantic-AI', content='Pydantic-AI is an agent framework that builds upon the established foundation of Pydantic, a highly regarded Python library for data validation and settings management. To fully grasp Pydantic-AI\\'s utility, it\\'s essential to first understand the core concepts of Pydantic itself.\\n\\n### A. Core Concepts of Pydantic\\n\\n1.  **`BaseModel` for data schema definition.** At the heart of Pydantic is the `BaseModel` class. By inheriting from `BaseModel`, developers can define explicit data schemas using standard Python type hints. This declarative approach creates a clear contract for the structure and types of expected data.\\n\\n2.  **Type hinting and automatic validation.** Pydantic leverages Python\\'s native type hints to perform automatic runtime validation. When data is passed to a `BaseModel`, Pydantic rigorously checks whether it conforms to the defined types and any additional constraints, raising informative errors if discrepancies are found. This significantly reduces boilerplate code traditionally used for manual validation.\\n\\n3.  **Data parsing and serialization.** Beyond validation, Pydantic excels at data parsing and serialization. It can intelligently convert incoming data (e.g., from JSON or forms) into the correct Python types and objects defined by the `BaseModel`. Conversely, it can easily serialize Pydantic models back into structured formats like JSON, making data exchange seamless.\\n\\n### B. Pydantic-AI Specifics\\n\\nPydantic-AI extends Pydantic\\'s core capabilities with features specifically designed for the unique challenges of AI and Large Language Model (LLM) interactions. While Pydantic provides the underlying validation engine, Pydantic-AI acts as a specialized layer to apply this power to agent development.\\n\\n1.  **Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).** Pydantic-AI functions as a dedicated agent framework for working with LLMs, aiming to streamline the development of production-grade generative AI applications. It directly integrates Pydantic models to define and enforce structured outputs from LLMs. Concepts like an `output_type` parameter in Pydantic-AI agents allow developers to link a Pydantic model, ensuring the LLM\\'s response adheres to that specific structure.\\n\\n2.  **How it helps enforce LLM output formats.** One of the primary challenges with LLMs is their tendency to produce varied and unstructured text. Pydantic-AI tackles this by enabling developers to define a `Pydantic` Model that dictates the precise structure and types of the expected LLM output. This model acts as a blueprint, guiding the LLM (often through prompt instructions or function calling mechanisms) to generate Pydantic-compatible JSON. Frameworks often use mechanisms like `PydanticOutputParser` to parse the LLM\\'s raw string output into a validated Pydantic object, making the output reliably structured for downstream processing.\\n\\n### C. Simple Examples: Defining a basic data structure with Pydantic-AI\\n\\nA simple Pydantic-AI data structure would look identical to a standard Pydantic `BaseModel`. For instance, to define a structured output for an agent that extracts user information:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\nclass UserInfo(BaseModel):\\n    name: str = Field(description=\"The full name of the user\")\\n    age: int = Field(description=\"The age of the user\")\\n    email: str | None = Field(None, description=\"The user\\'s email address, if available\")\\n    is_subscribed: bool = Field(False, description=\"Whether the user is subscribed to the newsletter\")\\n\\n# An AI agent could be instructed to output data conforming to this UserInfo model.\\n```\\n\\nThis `UserInfo` model, when integrated with a Pydantic-AI agent, would ensure that any extracted user information from an LLM adheres to these specified types and fields, providing a reliable and validated data object.', references='Models - Pydantic (https://docs.pydantic.dev/latest/concepts/models/); Pydantic: Simplifying Data Validation in Python (https://realpython.com/python-pydantic/); Supercharging Your AI Agents with Pydantic ... - DEV Community (https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk); Pydantic AI (https://ai.pydantic.dev/); Enforce Structured Outputs from LLMs with PydanticAI - CodeCut (https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/); Structured Outputs from LLM using Pydantic | by Harisudhan.S (https://medium.com/@speaktoharisudhan/structured-outputs-from-llm-using-pydantic-1a36e6c3aa07); Pydantic: A Guide With Practical Examples - DataCamp (https://www.datacamp.com/tutorial/pydantic)'), Section(title='III. Fundamentals of AI Agents', content=\"To appreciate the value Pydantic-AI brings, it's crucial to understand the foundational architecture and components of AI agents.\\n\\n### A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n\\nAn AI agent is an increasingly autonomous software system that utilizes Large Language Models (LLMs) as its central intelligence. Unlike simpler AI models, agents are designed to perceive their environment, interpret complex inputs, reason through problems, make decisions, and perform tasks. Their enhanced capabilities stem from integrating several key components: planning abilities to strategize, tool utilization to interact with the external world, and memory systems to retain context and learn from past experiences. This combination allows them to execute multi-step plans and adapt their strategies dynamically.\\n\\n### B. Key Components of an Agent\\n\\n1.  **Large Language Models (LLMs).** The LLM serves as the agent's brain, providing the ability to understand natural language, generate human-like text, and perform complex reasoning tasks. It's responsible for interpreting user requests, generating internal thoughts, and formulating responses.\\n\\n2.  **Tools/Functions: How agents interact with the external world.** Tools are external resources, APIs, or specific functions that extend the LLM's capabilities. Agents use tools to perform actions in the real world, such as searching the internet, making calculations, sending emails, or interacting with databases. These tools allow the agent to move beyond purely linguistic tasks and perform concrete operations.\\n\\n3.  **Memory: Short-term and long-term context retention.** Memory systems enable agents to store and retrieve information, maintaining a persistent context across multiple interactions. Short-term memory might include the current conversation history, while long-term memory could store learned facts, user preferences, or past experiences, allowing the agent to build upon prior knowledge and iterative improvement.\\n\\n4.  **Reasoning and Planning.** Agents employ reasoning to analyze problems, interpret inputs, and determine the best course of action. Planning involves breaking down complex goals into a series of manageable steps. During this phase, the agent considers the user's request, available tools, and the necessary information to achieve its objective, formulating a logical sequence of operations.\\n\\n5.  **Action and Execution.** Once a plan is formulated, the agent executes the actions. This often involves calling specific tools with appropriate parameters to interact with the environment and achieve the desired outcomes. The results of these actions are then fed back into the agent's reasoning process.\\n\\n### C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nSeveral open-source frameworks have emerged to facilitate the development and deployment of AI agents. **LangChain** is a widely used framework known for building LLM-powered applications and agents, offering components for chaining operations, managing conversational memory, and integrating tools. It's particularly useful for developing agents with straightforward to complex workflows. **LlamaIndex** is another prominent data orchestration framework focused on integrating LLMs with external data sources, making it excellent for retrieval-augmented generation (RAG) and agentic solutions that require structured data extraction and querying. These frameworks provide the architectural scaffolding upon which sophisticated AI agents can be built.\", references='The Rise of AI Agents—Collaborative Intelligence - CyberArk (https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence); LLM Agents - GeeksforGeeks (https://www.geeksforGeeks.org/artificial-intelligence/llm-agents/); Introduction to AI Agents - Build with Cerebras Inference (https://inference-docs.cerebras.ai/agent-bootcamp/section-1); Agent Components - Prompt Engineering Guide (https://www.promptingguide.ai/agents/components); Understanding MCP features: Tools, Resources, Prompts, Sampling ... (https://workos.com/blog/mcp-features-guide); AI Agent Frameworks: Choosing the Right Foundation for Your ... - IBM (https://www.ibm.com/think/insights/top-ai-agent-frameworks); Navigating the AI Framework Landscape: LlamaIndex, LangChain ... (https://medium.com/@ajayverma23/navigating-the-ai-framework-landscape-llamaindex-langchain-and-beyond-e377bbc0e1c4); Comparing Open-Source AI Agent Frameworks - Langfuse Blog (https://langfuse.com/blog/2025-03-19-ai-agent-comparison)'), Section(title='IV. The Synergy: Why Pydantic-AI for Agent Development?', content=\"The burgeoning field of AI agents presents both immense opportunities and significant challenges, particularly concerning the reliability and structure of data. Pydantic-AI emerges as a crucial solution, forging a powerful synergy with agent development by addressing these inherent complexities.\\n\\n### A. The Problem: Unreliable, unstructured outputs from LLMs.\\n\\nOne of the most persistent challenges in building production-ready AI applications is the inherent unpredictability of Large Language Model (LLM) outputs. LLMs, by their nature, are designed for flexibility and creativity, often generating text that is unstructured, inconsistent, or even prone to 'hallucinations'—producing confidently presented but incorrect information. This lack of a guaranteed, structured format makes it exceedingly difficult to reliably integrate LLM responses into downstream systems, which often require precise data types and schemas. Developers frequently grapple with parsing errors, ambiguous responses, and the general unreliability of extracting specific pieces of information from free-form text, leading to fragile and difficult-to-maintain applications.\\n\\n### B. The Solution: Pydantic-AI for guaranteed data structures.\\n\\nPydantic-AI directly addresses the problem of unstructured LLM outputs by leveraging Pydantic's robust data validation and modeling capabilities. It allows developers to define explicit, type-hinted data schemas for virtually any data exchange within an agent's workflow. By enforcing these predefined structures, Pydantic-AI ensures that the data generated by LLMs, whether it's an agent's action, an observation, or a tool's output, conforms to a precise and expected format. This guarantee of structured data transforms unreliable text into actionable, validated Python objects, significantly enhancing the determinism and reliability of AI agents.\\n\\n### C. Key Benefits:\\n\\nThe integration of Pydantic-AI into agent development yields several critical benefits:\\n\\n1.  **Reliable Tool Definitions:** Pydantic-AI empowers developers to define the input parameters for agent tools with explicit `BaseModel` schemas. This ensures that when an LLM decides to use a tool, the arguments it generates are automatically validated against the defined schema, preventing incorrect function calls and ensuring tools receive consistently formatted data. This creates a clear and reliable contract for tool interaction.\\n\\n2.  **Robust Response Parsing:** With Pydantic-AI, agent outputs—such as the agent's 'thought' process, the 'action' it decides to take, or the 'observation' from a tool—can be constrained to a specific Pydantic model. This means that LLM responses are not just free-form text but structured JSON that can be reliably parsed and validated into Python objects, making subsequent processing and decision-making far more robust.\\n\\n3.  **Structured Agent State/Memory:** Pydantic models are exceptionally well-suited for managing an agent's internal state and memory. Conversation histories, learned facts, long-term goals, and other crucial contextual information can be stored as Pydantic-validated objects. This ensures consistency and easy retrieval of memory components, allowing agents to maintain coherent context and learn effectively across interactions.\\n\\n4.  **Reduced Boilerplate & Improved Readability:** By leveraging Python type hints and `BaseModel`, Pydantic-AI significantly reduces the amount of boilerplate code typically required for manual data validation and parsing. This leads to cleaner, more concise, and highly readable agent code, allowing developers to focus more on agent logic and less on data wrangling.\\n\\n5.  **Enhanced Debugging and Error Handling:** The automatic validation provided by Pydantic-AI catches data inconsistencies and type errors at runtime, often with clear and informative error messages. This greatly enhances the debugging process, allowing developers to quickly pinpoint issues related to malformed LLM outputs or incorrect data flows. It also facilitates the implementation of robust error-handling and retry mechanisms, making agents more resilient to unexpected inputs.\", references=\"[D] Is anyone else having trouble with the unstructured output from ... (https://www.reddit.com/r/MachineLearning/comments/1dyxiw4/d_is_anyone_else_having_trouble_with_the/); LLM's Insecure Output Handling: Best Practices and Prevention (https://coralogix.com/ai-blog/llms-insecure-output-handling-best-practices-and-prevention/); Reliability for unreliable LLMs - The Stack Overflow Blog (https://stackoverflow.blog/2025/06/30/reliability-for-unreliable-llms/); PydanticAI: The Next-Generation AI Agent Framework for LLMs (https://www.technovera.com/it-blogs/pydanticai-the-next-generation-ai-agent-framework-for-llms/); Pydantic AI Development Services | Reliable Data Modeling by EvinceDev (https://evincedev.com/generative-ai-applications-development-with-pydanticai); Pydantic.ai: Building Smarter, Type-Safe AI Agents - Cuttlesoft (https://cuttlesoft.com/blog/2024/12/11/pydantic-ai-building-smarter-type-safe-ai-agents/); Pydantic : A Guide With Practical Examples | DataCamp (https://www.datacamp.com/tutorial/pydantic); Introduction to Python Pydantic Library - GeeksforGeeks (https://www.geeksforgeeks.org/python/introduction-to-python-pydantic-library/); What is Pydantic ? | by LEARNMYCOURSE | Medium (https://learnmycourse.medium.com/what-is-pydantic-751ba6f452c5); Building your own CLI Coding Agent with Pydantic -AI (https://martinfowler.com/articles/build-own-coding-agent.html)\"), Section(title='V. Practical Guide: Building Agents with Pydantic-AI', content='Building effective AI agents requires careful structuring of interactions, from defining the capabilities of tools to managing conversational context. Pydantic-AI provides a robust framework for ensuring these interactions are type-safe, validated, and reliable.\\n\\n### A. Defining Agent Tools with Pydantic-AI:\\n\\nAgent tools allow LLMs to interact with the external world. Pydantic-AI simplifies the definition of these tools and their input parameters, ensuring clarity and reliability in function calls.\\n\\n1.  **Using `BaseModel` to describe tool input parameters.** The most fundamental step is to use Pydantic\\'s `BaseModel` to define the schema for a tool\\'s expected input. This creates a clear, self-documenting contract for the arguments the tool accepts, complete with type hints and descriptions.\\n\\n2.  **Examples: A search tool, a calculator tool, defined with Pydantic-AI.** Consider a `SearchTool` or a `CalculatorTool`. Their input parameters can be precisely defined using `BaseModel`:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n\\n    class SearchInput(BaseModel):\\n        query: str = Field(description=\"The search query to execute\")\\n        num_results: int = Field(5, description=\"Maximum number of search results to return\")\\n\\n    class CalculatorInput(BaseModel):\\n        expression: str = Field(description=\"The mathematical expression to evaluate, e.g., \\'2 + 2 * 3\\'\")\\n    ```\\n\\n    A practical example from Pydantic-AI demonstrates defining tool inputs for a flight booking agent:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n\\n    class FlightBookingInput(BaseModel):\\n        origin: str = Field(description=\"The departure city or airport code, e.g., \\'Delhi\\' or \\'DEL\\'\")\\n        destination: str = Field(description=\"The arrival city or airport code, e.g., \\'Bangalore\\' or \\'BLR\\'\")\\n        departure_date: str = Field(description=\"The date of departure in YYYY-MM-DD format, e.g., \\'2025-06-25\\'\")\\n        return_date: str | None = Field(None, description=\"The date of return in YYYY-MM-DD format (optional for one-way flights)\")\\n        num_passengers: int = Field(1, description=\"The number of passengers (default is 1)\")\\n    ```\\n\\n3.  **Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).** These Pydantic `BaseModel` schemas for tool inputs can be directly provided to LLM function calling mechanisms (like those offered by OpenAI). The LLM is then instructed to generate function call arguments that conform precisely to these defined Pydantic models. This integration ensures that the LLM\\'s intent to use a tool translates into a validated and executable function call.\\n\\n### B. Structuring Agent Responses and Outputs:\\n\\nEnsuring that an agent\\'s internal thoughts, actions, and observations are consistently formatted is crucial for reliable agentic behavior. Pydantic-AI provides powerful mechanisms for this.\\n\\n1.  **Guiding LLMs to produce Pydantic-compatible JSON.** By defining a `BaseModel` for the expected output structure, developers can effectively guide LLMs to generate responses in a JSON format that is compatible with that Pydantic model. This transforms the LLM\\'s free-form text generation into structured data output.\\n\\n2.  **Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).** In frameworks like LangChain, a `PydanticOutputParser` can be used. This parser takes a Pydantic `BaseModel` and generates formatting instructions that are injected into the LLM\\'s prompt, instructing it to produce JSON conforming to the model. The parser then takes the LLM\\'s string output and parses it into a Pydantic object, validating it in the process. Pydantic-AI agents themselves often offer an `output_type` parameter to directly link a Pydantic model to the agent\\'s output, achieving similar structured output enforcement.\\n\\n3.  **Handling parsing errors and retries.** Pydantic\\'s inherent validation capabilities mean that if an LLM fails to produce output conforming to the `BaseModel`, a `ValidationError` is raised. Pydantic-AI agents can also raise `UnexpectedModelBehavior` for issues like exceeding retry limits. Developers can implement robust error handling by catching these validation errors and implementing retry mechanisms, such as re-prompting the LLM with more explicit instructions or adjusting the model\\'s parameters, to encourage a correct output format.\\n\\n### C. Managing Agent State and Memory:\\n\\nMaintaining context and memory is vital for conversational and intelligent agents. Pydantic models provide an excellent way to structure and manage this state.\\n\\n1.  **Using Pydantic models for storing conversation turns, facts, or observations.** Pydantic models can define the schema for various memory components, such as individual `Message` objects within a conversation or `Fact` objects representing learned information. This ensures that memory elements are stored consistently and are easily retrievable for the agent\\'s reasoning process.\\n\\n2.  **Example: A `ConversationHistory` model or an `AgentState` model.** While specific Pydantic-AI frameworks might use different naming conventions, the principle involves creating `BaseModel` classes to represent the agent\\'s evolving state. For instance, a `Message` model could capture speaker, content, and timestamp, and a list of these messages would form the `ConversationHistory`. Similarly, an `AgentState` model might aggregate various pieces of information like `current_goal: str`, `known_facts: List[Fact]`, and `conversation_history: List[Message]`:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n    from typing import List, Literal\\n    from datetime import datetime\\n\\n    class Message(BaseModel):\\n        role: Literal[\"user\", \"agent\", \"tool\"] = Field(description=\"The role of the message sender\")\\n        content: str = Field(description=\"The content of the message\")\\n        timestamp: datetime = Field(default_factory=datetime.now, description=\"Timestamp of the message\")\\n\\n    class Fact(BaseModel):\\n        topic: str = Field(description=\"The topic of the learned fact\")\\n        detail: str = Field(description=\"The detailed information of the fact\")\\n        source: str | None = Field(None, description=\"Optional source of the fact\")\\n\\n    class AgentState(BaseModel):\\n        current_goal: str = Field(description=\"The agent\\'s current primary objective\")\\n        known_facts: List[Fact] = Field(default_factory=list, description=\"A list of facts the agent has learned\")\\n        conversation_history: List[Message] = Field(default_factory=list, description=\"The chronological history of messages\")\\n    ```\\n\\n    This structured approach to memory allows for clear state management and facilitates advanced agent behaviors like reflection and self-correction.\\n\\n### D. Integration with Popular Agent Frameworks (Illustrative Examples):\\n\\nPydantic-AI concepts are widely adopted and integrated into leading AI agent frameworks, enhancing their capabilities for structured interactions.\\n\\n1.  **How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).** LangChain leverages Pydantic extensively for structured outputs and tool definitions. Historically, `create_structured_output_chain` (now deprecated in favor of `with_structured_output()`) allowed developers to create LLM chains that produced structured outputs based on Pydantic `BaseModel` schemas using OpenAI\\'s function calling API. The `with_structured_output()` method directly automates the process of binding a Pydantic schema to the LLM as a tool and then parsing its output into the specified Pydantic object, streamlining the creation of reliable, type-safe agent interactions.\\n\\n2.  **How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).** LlamaIndex, an orchestration framework for LLM applications, also embraces Pydantic for structured data extraction. `PydanticPrograms` in LlamaIndex serve as a lower-level abstraction specifically designed to convert raw LLM text outputs into structured Pydantic objects. This is crucial for tasks like extracting specific entities or information from documents into a predefined schema, ensuring that the data is ready for further processing and analysis within the LlamaIndex ecosystem.', references=\"pydantic_ai.tools - Pydantic AI (https://ai.pydantic.dev/api/tools/); Unlock Your AI's Memory: A Practical Guide to Pydantic-AI Agents ... - Medium (https://learnitnow.medium.com/unlock-your-ais-memory-a-practical-guide-to-pydantic-ai-agents-mongodb-09476ddc2963); Supercharging Your AI Agents with Pydantic ... - DEV Community (https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk); Control LLM output with LangChain's structured and Pydantic output ... (https://atamel.dev/posts/2024/12-09_control_llm_output_langchain_structured_pydantic/); Enforce Structured Outputs from LLMs with PydanticAI - CodeCut (https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/); Agents - Pydantic AI (https://ai.pydantic.dev/agents/); Memory Implementation #196 - pydantic/pydantic-ai - GitHub (https://github.com/pydantic/pydantic-ai/issues/196); Messages and chat history - Pydantic AI (https://ai.pydantic.dev/message-history/); create_structured_output_chain — LangChain documentation (https://python.langchain.com/api_reference/langchain/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html); Structured outputs - ️ LangChain (https://python.langchain.com/docs/concepts/structured_outputs/); Pydantic Programs - LlamaIndex (https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/); AI Structured Outputs with LLMs, LlamaIndex & Pydantic - YouTube (https://www.youtube.com/watch?v=Rpg9TQtqqhE)\")]), tool_name='final_result', tool_call_id='pyd_ai_5b060e5aebd64b3eaf9ac29f84862875'))\n",
      "INFO:web_deep_researcher:Getting the report for the information: [Section(title='I. Introduction', content=\"The landscape of artificial intelligence is rapidly evolving, with AI agents emerging as a transformative force. These autonomous systems are designed to perform complex tasks, make informed decisions, and continuously learn from their interactions within various environments. From automating intricate workflows to enhancing human-computer collaboration, the rise of AI agents promises unprecedented levels of productivity and innovation. However, this increased autonomy also brings a critical need for reliable and predictable interactions. As AI agents become more deeply integrated into critical systems, ensuring their outputs are structured, validated, and consistently reliable is paramount to prevent errors, maintain data integrity, and foster trust.\\n\\nThis report introduces Pydantic-AI, a powerful framework built upon the robust data validation capabilities of Pydantic, specifically tailored for the development of AI agents. Pydantic's core purpose lies in its ability to define data schemas using Python type hints, enabling runtime data validation, parsing, and serialization. Pydantic-AI extends these capabilities to the realm of large language models (LLMs) and agentic workflows, providing a crucial mechanism for enforcing structured and reliable data exchange.\\n\\nThe central thesis of this report is that Pydantic-AI significantly enhances AI agent development by guaranteeing structured, validated data exchange throughout the agent's lifecycle—from tool definitions to response parsing and memory management. This foundational assurance leads to more robust, predictable, and maintainable AI applications.\\n\\nThis report will explore the core concepts of Pydantic-AI, delve into the fundamental components of AI agents, and illustrate the powerful synergy between them. It will provide a practical guide to building agents with Pydantic-AI, covering tool definition, response structuring, and memory management, alongside its integration with popular agent frameworks. Finally, it will discuss advanced concepts and best practices for leveraging Pydantic-AI to create highly reliable and efficient AI agents.\", references='The Rise of AI Agents—Collaborative Intelligence - CyberArk (https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence); Introduction to AI Agents - Build with Cerebras Inference (https://inference-docs.cerebras.ai/agent-bootcamp/section-1); Agent Components - Prompt Engineering Guide (https://www.promptingguide.ai/agents/components); Pydantic AI (https://ai.pydantic.dev/); The Power of Pydantic: Bringing Structure and Validation to Your ... (https://medium.com/@shouke.wei/the-power-of-pydantic-bringing-structure-and-validation-to-your-python-data-9de124362a6f); Pydantic: Simplifying Data Validation in Python (https://realpython.com/python-pydantic/)'), Section(title='II. Understanding Pydantic-AI', content='Pydantic-AI is an agent framework that builds upon the established foundation of Pydantic, a highly regarded Python library for data validation and settings management. To fully grasp Pydantic-AI\\'s utility, it\\'s essential to first understand the core concepts of Pydantic itself.\\n\\n### A. Core Concepts of Pydantic\\n\\n1.  **`BaseModel` for data schema definition.** At the heart of Pydantic is the `BaseModel` class. By inheriting from `BaseModel`, developers can define explicit data schemas using standard Python type hints. This declarative approach creates a clear contract for the structure and types of expected data.\\n\\n2.  **Type hinting and automatic validation.** Pydantic leverages Python\\'s native type hints to perform automatic runtime validation. When data is passed to a `BaseModel`, Pydantic rigorously checks whether it conforms to the defined types and any additional constraints, raising informative errors if discrepancies are found. This significantly reduces boilerplate code traditionally used for manual validation.\\n\\n3.  **Data parsing and serialization.** Beyond validation, Pydantic excels at data parsing and serialization. It can intelligently convert incoming data (e.g., from JSON or forms) into the correct Python types and objects defined by the `BaseModel`. Conversely, it can easily serialize Pydantic models back into structured formats like JSON, making data exchange seamless.\\n\\n### B. Pydantic-AI Specifics\\n\\nPydantic-AI extends Pydantic\\'s core capabilities with features specifically designed for the unique challenges of AI and Large Language Model (LLM) interactions. While Pydantic provides the underlying validation engine, Pydantic-AI acts as a specialized layer to apply this power to agent development.\\n\\n1.  **Features designed for AI/LLM interactions (e.g., `response_model` decorators, structured output).** Pydantic-AI functions as a dedicated agent framework for working with LLMs, aiming to streamline the development of production-grade generative AI applications. It directly integrates Pydantic models to define and enforce structured outputs from LLMs. Concepts like an `output_type` parameter in Pydantic-AI agents allow developers to link a Pydantic model, ensuring the LLM\\'s response adheres to that specific structure.\\n\\n2.  **How it helps enforce LLM output formats.** One of the primary challenges with LLMs is their tendency to produce varied and unstructured text. Pydantic-AI tackles this by enabling developers to define a `Pydantic` Model that dictates the precise structure and types of the expected LLM output. This model acts as a blueprint, guiding the LLM (often through prompt instructions or function calling mechanisms) to generate Pydantic-compatible JSON. Frameworks often use mechanisms like `PydanticOutputParser` to parse the LLM\\'s raw string output into a validated Pydantic object, making the output reliably structured for downstream processing.\\n\\n### C. Simple Examples: Defining a basic data structure with Pydantic-AI\\n\\nA simple Pydantic-AI data structure would look identical to a standard Pydantic `BaseModel`. For instance, to define a structured output for an agent that extracts user information:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\nclass UserInfo(BaseModel):\\n    name: str = Field(description=\"The full name of the user\")\\n    age: int = Field(description=\"The age of the user\")\\n    email: str | None = Field(None, description=\"The user\\'s email address, if available\")\\n    is_subscribed: bool = Field(False, description=\"Whether the user is subscribed to the newsletter\")\\n\\n# An AI agent could be instructed to output data conforming to this UserInfo model.\\n```\\n\\nThis `UserInfo` model, when integrated with a Pydantic-AI agent, would ensure that any extracted user information from an LLM adheres to these specified types and fields, providing a reliable and validated data object.', references='Models - Pydantic (https://docs.pydantic.dev/latest/concepts/models/); Pydantic: Simplifying Data Validation in Python (https://realpython.com/python-pydantic/); Supercharging Your AI Agents with Pydantic ... - DEV Community (https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk); Pydantic AI (https://ai.pydantic.dev/); Enforce Structured Outputs from LLMs with PydanticAI - CodeCut (https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/); Structured Outputs from LLM using Pydantic | by Harisudhan.S (https://medium.com/@speaktoharisudhan/structured-outputs-from-llm-using-pydantic-1a36e6c3aa07); Pydantic: A Guide With Practical Examples - DataCamp (https://www.datacamp.com/tutorial/pydantic)'), Section(title='III. Fundamentals of AI Agents', content=\"To appreciate the value Pydantic-AI brings, it's crucial to understand the foundational architecture and components of AI agents.\\n\\n### A. Definition of an AI Agent: LLM as the core, with tools, memory, and planning capabilities.\\n\\nAn AI agent is an increasingly autonomous software system that utilizes Large Language Models (LLMs) as its central intelligence. Unlike simpler AI models, agents are designed to perceive their environment, interpret complex inputs, reason through problems, make decisions, and perform tasks. Their enhanced capabilities stem from integrating several key components: planning abilities to strategize, tool utilization to interact with the external world, and memory systems to retain context and learn from past experiences. This combination allows them to execute multi-step plans and adapt their strategies dynamically.\\n\\n### B. Key Components of an Agent\\n\\n1.  **Large Language Models (LLMs).** The LLM serves as the agent's brain, providing the ability to understand natural language, generate human-like text, and perform complex reasoning tasks. It's responsible for interpreting user requests, generating internal thoughts, and formulating responses.\\n\\n2.  **Tools/Functions: How agents interact with the external world.** Tools are external resources, APIs, or specific functions that extend the LLM's capabilities. Agents use tools to perform actions in the real world, such as searching the internet, making calculations, sending emails, or interacting with databases. These tools allow the agent to move beyond purely linguistic tasks and perform concrete operations.\\n\\n3.  **Memory: Short-term and long-term context retention.** Memory systems enable agents to store and retrieve information, maintaining a persistent context across multiple interactions. Short-term memory might include the current conversation history, while long-term memory could store learned facts, user preferences, or past experiences, allowing the agent to build upon prior knowledge and iterative improvement.\\n\\n4.  **Reasoning and Planning.** Agents employ reasoning to analyze problems, interpret inputs, and determine the best course of action. Planning involves breaking down complex goals into a series of manageable steps. During this phase, the agent considers the user's request, available tools, and the necessary information to achieve its objective, formulating a logical sequence of operations.\\n\\n5.  **Action and Execution.** Once a plan is formulated, the agent executes the actions. This often involves calling specific tools with appropriate parameters to interact with the environment and achieve the desired outcomes. The results of these actions are then fed back into the agent's reasoning process.\\n\\n### C. Common Agent Frameworks (brief mention): LangChain, LlamaIndex, etc.\\n\\nSeveral open-source frameworks have emerged to facilitate the development and deployment of AI agents. **LangChain** is a widely used framework known for building LLM-powered applications and agents, offering components for chaining operations, managing conversational memory, and integrating tools. It's particularly useful for developing agents with straightforward to complex workflows. **LlamaIndex** is another prominent data orchestration framework focused on integrating LLMs with external data sources, making it excellent for retrieval-augmented generation (RAG) and agentic solutions that require structured data extraction and querying. These frameworks provide the architectural scaffolding upon which sophisticated AI agents can be built.\", references='The Rise of AI Agents—Collaborative Intelligence - CyberArk (https://www.cyberark.com/resources/blog/the-rise-of-ai-agents-collaborative-intelligence); LLM Agents - GeeksforGeeks (https://www.geeksforGeeks.org/artificial-intelligence/llm-agents/); Introduction to AI Agents - Build with Cerebras Inference (https://inference-docs.cerebras.ai/agent-bootcamp/section-1); Agent Components - Prompt Engineering Guide (https://www.promptingguide.ai/agents/components); Understanding MCP features: Tools, Resources, Prompts, Sampling ... (https://workos.com/blog/mcp-features-guide); AI Agent Frameworks: Choosing the Right Foundation for Your ... - IBM (https://www.ibm.com/think/insights/top-ai-agent-frameworks); Navigating the AI Framework Landscape: LlamaIndex, LangChain ... (https://medium.com/@ajayverma23/navigating-the-ai-framework-landscape-llamaindex-langchain-and-beyond-e377bbc0e1c4); Comparing Open-Source AI Agent Frameworks - Langfuse Blog (https://langfuse.com/blog/2025-03-19-ai-agent-comparison)'), Section(title='IV. The Synergy: Why Pydantic-AI for Agent Development?', content=\"The burgeoning field of AI agents presents both immense opportunities and significant challenges, particularly concerning the reliability and structure of data. Pydantic-AI emerges as a crucial solution, forging a powerful synergy with agent development by addressing these inherent complexities.\\n\\n### A. The Problem: Unreliable, unstructured outputs from LLMs.\\n\\nOne of the most persistent challenges in building production-ready AI applications is the inherent unpredictability of Large Language Model (LLM) outputs. LLMs, by their nature, are designed for flexibility and creativity, often generating text that is unstructured, inconsistent, or even prone to 'hallucinations'—producing confidently presented but incorrect information. This lack of a guaranteed, structured format makes it exceedingly difficult to reliably integrate LLM responses into downstream systems, which often require precise data types and schemas. Developers frequently grapple with parsing errors, ambiguous responses, and the general unreliability of extracting specific pieces of information from free-form text, leading to fragile and difficult-to-maintain applications.\\n\\n### B. The Solution: Pydantic-AI for guaranteed data structures.\\n\\nPydantic-AI directly addresses the problem of unstructured LLM outputs by leveraging Pydantic's robust data validation and modeling capabilities. It allows developers to define explicit, type-hinted data schemas for virtually any data exchange within an agent's workflow. By enforcing these predefined structures, Pydantic-AI ensures that the data generated by LLMs, whether it's an agent's action, an observation, or a tool's output, conforms to a precise and expected format. This guarantee of structured data transforms unreliable text into actionable, validated Python objects, significantly enhancing the determinism and reliability of AI agents.\\n\\n### C. Key Benefits:\\n\\nThe integration of Pydantic-AI into agent development yields several critical benefits:\\n\\n1.  **Reliable Tool Definitions:** Pydantic-AI empowers developers to define the input parameters for agent tools with explicit `BaseModel` schemas. This ensures that when an LLM decides to use a tool, the arguments it generates are automatically validated against the defined schema, preventing incorrect function calls and ensuring tools receive consistently formatted data. This creates a clear and reliable contract for tool interaction.\\n\\n2.  **Robust Response Parsing:** With Pydantic-AI, agent outputs—such as the agent's 'thought' process, the 'action' it decides to take, or the 'observation' from a tool—can be constrained to a specific Pydantic model. This means that LLM responses are not just free-form text but structured JSON that can be reliably parsed and validated into Python objects, making subsequent processing and decision-making far more robust.\\n\\n3.  **Structured Agent State/Memory:** Pydantic models are exceptionally well-suited for managing an agent's internal state and memory. Conversation histories, learned facts, long-term goals, and other crucial contextual information can be stored as Pydantic-validated objects. This ensures consistency and easy retrieval of memory components, allowing agents to maintain coherent context and learn effectively across interactions.\\n\\n4.  **Reduced Boilerplate & Improved Readability:** By leveraging Python type hints and `BaseModel`, Pydantic-AI significantly reduces the amount of boilerplate code typically required for manual data validation and parsing. This leads to cleaner, more concise, and highly readable agent code, allowing developers to focus more on agent logic and less on data wrangling.\\n\\n5.  **Enhanced Debugging and Error Handling:** The automatic validation provided by Pydantic-AI catches data inconsistencies and type errors at runtime, often with clear and informative error messages. This greatly enhances the debugging process, allowing developers to quickly pinpoint issues related to malformed LLM outputs or incorrect data flows. It also facilitates the implementation of robust error-handling and retry mechanisms, making agents more resilient to unexpected inputs.\", references=\"[D] Is anyone else having trouble with the unstructured output from ... (https://www.reddit.com/r/MachineLearning/comments/1dyxiw4/d_is_anyone_else_having_trouble_with_the/); LLM's Insecure Output Handling: Best Practices and Prevention (https://coralogix.com/ai-blog/llms-insecure-output-handling-best-practices-and-prevention/); Reliability for unreliable LLMs - The Stack Overflow Blog (https://stackoverflow.blog/2025/06/30/reliability-for-unreliable-llms/); PydanticAI: The Next-Generation AI Agent Framework for LLMs (https://www.technovera.com/it-blogs/pydanticai-the-next-generation-ai-agent-framework-for-llms/); Pydantic AI Development Services | Reliable Data Modeling by EvinceDev (https://evincedev.com/generative-ai-applications-development-with-pydanticai); Pydantic.ai: Building Smarter, Type-Safe AI Agents - Cuttlesoft (https://cuttlesoft.com/blog/2024/12/11/pydantic-ai-building-smarter-type-safe-ai-agents/); Pydantic : A Guide With Practical Examples | DataCamp (https://www.datacamp.com/tutorial/pydantic); Introduction to Python Pydantic Library - GeeksforGeeks (https://www.geeksforgeeks.org/python/introduction-to-python-pydantic-library/); What is Pydantic ? | by LEARNMYCOURSE | Medium (https://learnmycourse.medium.com/what-is-pydantic-751ba6f452c5); Building your own CLI Coding Agent with Pydantic -AI (https://martinfowler.com/articles/build-own-coding-agent.html)\"), Section(title='V. Practical Guide: Building Agents with Pydantic-AI', content='Building effective AI agents requires careful structuring of interactions, from defining the capabilities of tools to managing conversational context. Pydantic-AI provides a robust framework for ensuring these interactions are type-safe, validated, and reliable.\\n\\n### A. Defining Agent Tools with Pydantic-AI:\\n\\nAgent tools allow LLMs to interact with the external world. Pydantic-AI simplifies the definition of these tools and their input parameters, ensuring clarity and reliability in function calls.\\n\\n1.  **Using `BaseModel` to describe tool input parameters.** The most fundamental step is to use Pydantic\\'s `BaseModel` to define the schema for a tool\\'s expected input. This creates a clear, self-documenting contract for the arguments the tool accepts, complete with type hints and descriptions.\\n\\n2.  **Examples: A search tool, a calculator tool, defined with Pydantic-AI.** Consider a `SearchTool` or a `CalculatorTool`. Their input parameters can be precisely defined using `BaseModel`:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n\\n    class SearchInput(BaseModel):\\n        query: str = Field(description=\"The search query to execute\")\\n        num_results: int = Field(5, description=\"Maximum number of search results to return\")\\n\\n    class CalculatorInput(BaseModel):\\n        expression: str = Field(description=\"The mathematical expression to evaluate, e.g., \\'2 + 2 * 3\\'\")\\n    ```\\n\\n    A practical example from Pydantic-AI demonstrates defining tool inputs for a flight booking agent:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n\\n    class FlightBookingInput(BaseModel):\\n        origin: str = Field(description=\"The departure city or airport code, e.g., \\'Delhi\\' or \\'DEL\\'\")\\n        destination: str = Field(description=\"The arrival city or airport code, e.g., \\'Bangalore\\' or \\'BLR\\'\")\\n        departure_date: str = Field(description=\"The date of departure in YYYY-MM-DD format, e.g., \\'2025-06-25\\'\")\\n        return_date: str | None = Field(None, description=\"The date of return in YYYY-MM-DD format (optional for one-way flights)\")\\n        num_passengers: int = Field(1, description=\"The number of passengers (default is 1)\")\\n    ```\\n\\n3.  **Integration with LLM function calling mechanisms (e.g., OpenAI\\'s tools).** These Pydantic `BaseModel` schemas for tool inputs can be directly provided to LLM function calling mechanisms (like those offered by OpenAI). The LLM is then instructed to generate function call arguments that conform precisely to these defined Pydantic models. This integration ensures that the LLM\\'s intent to use a tool translates into a validated and executable function call.\\n\\n### B. Structuring Agent Responses and Outputs:\\n\\nEnsuring that an agent\\'s internal thoughts, actions, and observations are consistently formatted is crucial for reliable agentic behavior. Pydantic-AI provides powerful mechanisms for this.\\n\\n1.  **Guiding LLMs to produce Pydantic-compatible JSON.** By defining a `BaseModel` for the expected output structure, developers can effectively guide LLMs to generate responses in a JSON format that is compatible with that Pydantic model. This transforms the LLM\\'s free-form text generation into structured data output.\\n\\n2.  **Using `response_model` or `PydanticOutputParser` (or similar concepts in Pydantic-AI).** In frameworks like LangChain, a `PydanticOutputParser` can be used. This parser takes a Pydantic `BaseModel` and generates formatting instructions that are injected into the LLM\\'s prompt, instructing it to produce JSON conforming to the model. The parser then takes the LLM\\'s string output and parses it into a Pydantic object, validating it in the process. Pydantic-AI agents themselves often offer an `output_type` parameter to directly link a Pydantic model to the agent\\'s output, achieving similar structured output enforcement.\\n\\n3.  **Handling parsing errors and retries.** Pydantic\\'s inherent validation capabilities mean that if an LLM fails to produce output conforming to the `BaseModel`, a `ValidationError` is raised. Pydantic-AI agents can also raise `UnexpectedModelBehavior` for issues like exceeding retry limits. Developers can implement robust error handling by catching these validation errors and implementing retry mechanisms, such as re-prompting the LLM with more explicit instructions or adjusting the model\\'s parameters, to encourage a correct output format.\\n\\n### C. Managing Agent State and Memory:\\n\\nMaintaining context and memory is vital for conversational and intelligent agents. Pydantic models provide an excellent way to structure and manage this state.\\n\\n1.  **Using Pydantic models for storing conversation turns, facts, or observations.** Pydantic models can define the schema for various memory components, such as individual `Message` objects within a conversation or `Fact` objects representing learned information. This ensures that memory elements are stored consistently and are easily retrievable for the agent\\'s reasoning process.\\n\\n2.  **Example: A `ConversationHistory` model or an `AgentState` model.** While specific Pydantic-AI frameworks might use different naming conventions, the principle involves creating `BaseModel` classes to represent the agent\\'s evolving state. For instance, a `Message` model could capture speaker, content, and timestamp, and a list of these messages would form the `ConversationHistory`. Similarly, an `AgentState` model might aggregate various pieces of information like `current_goal: str`, `known_facts: List[Fact]`, and `conversation_history: List[Message]`:\\n\\n    ```python\\n    from pydantic import BaseModel, Field\\n    from typing import List, Literal\\n    from datetime import datetime\\n\\n    class Message(BaseModel):\\n        role: Literal[\"user\", \"agent\", \"tool\"] = Field(description=\"The role of the message sender\")\\n        content: str = Field(description=\"The content of the message\")\\n        timestamp: datetime = Field(default_factory=datetime.now, description=\"Timestamp of the message\")\\n\\n    class Fact(BaseModel):\\n        topic: str = Field(description=\"The topic of the learned fact\")\\n        detail: str = Field(description=\"The detailed information of the fact\")\\n        source: str | None = Field(None, description=\"Optional source of the fact\")\\n\\n    class AgentState(BaseModel):\\n        current_goal: str = Field(description=\"The agent\\'s current primary objective\")\\n        known_facts: List[Fact] = Field(default_factory=list, description=\"A list of facts the agent has learned\")\\n        conversation_history: List[Message] = Field(default_factory=list, description=\"The chronological history of messages\")\\n    ```\\n\\n    This structured approach to memory allows for clear state management and facilitates advanced agent behaviors like reflection and self-correction.\\n\\n### D. Integration with Popular Agent Frameworks (Illustrative Examples):\\n\\nPydantic-AI concepts are widely adopted and integrated into leading AI agent frameworks, enhancing their capabilities for structured interactions.\\n\\n1.  **How Pydantic-AI fits into LangChain (e.g., `create_structured_output_chain`, `tool` decorators).** LangChain leverages Pydantic extensively for structured outputs and tool definitions. Historically, `create_structured_output_chain` (now deprecated in favor of `with_structured_output()`) allowed developers to create LLM chains that produced structured outputs based on Pydantic `BaseModel` schemas using OpenAI\\'s function calling API. The `with_structured_output()` method directly automates the process of binding a Pydantic schema to the LLM as a tool and then parsing its output into the specified Pydantic object, streamlining the creation of reliable, type-safe agent interactions.\\n\\n2.  **How Pydantic-AI fits into LlamaIndex (e.g., `PydanticProgram` for structured outputs).** LlamaIndex, an orchestration framework for LLM applications, also embraces Pydantic for structured data extraction. `PydanticPrograms` in LlamaIndex serve as a lower-level abstraction specifically designed to convert raw LLM text outputs into structured Pydantic objects. This is crucial for tasks like extracting specific entities or information from documents into a predefined schema, ensuring that the data is ready for further processing and analysis within the LlamaIndex ecosystem.', references=\"pydantic_ai.tools - Pydantic AI (https://ai.pydantic.dev/api/tools/); Unlock Your AI's Memory: A Practical Guide to Pydantic-AI Agents ... - Medium (https://learnitnow.medium.com/unlock-your-ais-memory-a-practical-guide-to-pydantic-ai-agents-mongodb-09476ddc2963); Supercharging Your AI Agents with Pydantic ... - DEV Community (https://dev.to/sweetpapa/supercharging-your-ai-agents-with-pydantic-a-developers-guide-3hmk); Control LLM output with LangChain's structured and Pydantic output ... (https://atamel.dev/posts/2024/12-09_control_llm_output_langchain_structured_pydantic/); Enforce Structured Outputs from LLMs with PydanticAI - CodeCut (https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/); Agents - Pydantic AI (https://ai.pydantic.dev/agents/); Memory Implementation #196 - pydantic/pydantic-ai - GitHub (https://github.com/pydantic/pydantic-ai/issues/196); Messages and chat history - Pydantic AI (https://ai.pydantic.dev/message-history/); create_structured_output_chain — LangChain documentation (https://python.langchain.com/api_reference/langchain/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html); Structured outputs - ️ LangChain (https://python.langchain.com/docs/concepts/structured_outputs/); Pydantic Programs - LlamaIndex (https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program/); AI Structured Outputs with LLMs, LlamaIndex & Pydantic - YouTube (https://www.youtube.com/watch?v=Rpg9TQtqqhE)\")]\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "ename": "UnexpectedModelBehavior",
     "evalue": "Content field missing from Gemini response, body:\nsdk_http_response=HttpResponse(\n  headers=<dict len=11>\n) candidates=[Candidate(\n  finish_reason=<FinishReason.MALFORMED_FUNCTION_CALL: 'MALFORMED_FUNCTION_CALL'>,\n  index=0\n)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='DJy4aLDFL4CRmtkP9LaviA0' usage_metadata=GenerateContentResponseUsageMetadata(\n  prompt_token_count=7580,\n  prompt_tokens_details=[\n    ModalityTokenCount(\n      modality=<MediaModality.TEXT: 'TEXT'>,\n      token_count=7580\n    ),\n  ],\n  total_token_count=7580\n) automatic_function_calling_history=[] parsed=None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedModelBehavior\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m web_deep_researcher = web_deep_researcher()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m web_deep_researcher.execute(\u001b[33m\"\u001b[39m\u001b[33mhow can I use pydantic-ai\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mweb_deep_researcher.execute\u001b[39m\u001b[34m(self, question)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Get the report\u001b[39;00m\n\u001b[32m     69\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGetting the report for the information: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minformation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m report = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_report(information, plan)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m report\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 166\u001b[39m, in \u001b[36mweb_deep_researcher.get_report\u001b[39m\u001b[34m(self, information, plan)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_report\u001b[39m(\u001b[38;5;28mself\u001b[39m, information:\u001b[38;5;28mlist\u001b[39m[Section], plan:\u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    162\u001b[39m     writer_agent = Agent(\u001b[38;5;28mself\u001b[39m.settings.MODEL_NAME,\n\u001b[32m    163\u001b[39m             instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are a writer, you write a report about a given outline, you use the information provided as well as your own knowledge to write the report\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    164\u001b[39m                     output_type=reportOutput\n\u001b[32m    165\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m writer_agent.run(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mWrite a report about the following outline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplan\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33m    A Researcher has found the following information for each section: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minformation\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33m    Please use this to create a comprehesive report\u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.output.report\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py:211\u001b[39m, in \u001b[36mAbstractAgent.run\u001b[39m\u001b[34m(self, user_prompt, output_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name, toolsets, event_stream_handler)\u001b[39m\n\u001b[32m    198\u001b[39m event_stream_handler = event_stream_handler \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.event_stream_handler\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    201\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    202\u001b[39m     output_type=output_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    209\u001b[39m     toolsets=toolsets,\n\u001b[32m    210\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    212\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event_stream_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    213\u001b[39m             \u001b[38;5;28mself\u001b[39m.is_model_request_node(node) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_call_tools_node(node)\n\u001b[32m    214\u001b[39m         ):\n\u001b[32m    215\u001b[39m             \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m node.stream(agent_run.ctx) \u001b[38;5;28;01mas\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_ai/run.py:149\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    147\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, OutputDataT] | End[FinalResult[OutputDataT]]:\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(node=next_node):\n\u001b[32m    151\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py:761\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    759\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py:734\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persistence.record_run(node_snapshot_id):\n\u001b[32m    733\u001b[39m         ctx = GraphRunContext(\u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.deps)\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m         \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._snapshot_id = \u001b[38;5;28mself\u001b[39m._next_node.get_snapshot_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:297\u001b[39m, in \u001b[36mModelRequestNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._did_stream:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# `self._result` gets set when exiting the `stream` contextmanager, so hitting this\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# means that the stream was started but not finished before `run()` was called\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.AgentRunError(\u001b[33m'\u001b[39m\u001b[33mYou must finish streaming before calling run()\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_request(ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:339\u001b[39m, in \u001b[36mModelRequestNode._make_request\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    338\u001b[39m model_settings, model_request_parameters, message_history, _ = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_request(ctx)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m model_response = \u001b[38;5;28;01mawait\u001b[39;00m ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n\u001b[32m    340\u001b[39m ctx.state.usage.requests += \u001b[32m1\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish_handling(ctx, model_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_ai/models/google.py:199\u001b[39m, in \u001b[36mGoogleModel.request\u001b[39m\u001b[34m(self, messages, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    197\u001b[39m model_settings = cast(GoogleModelSettings, model_settings \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[32m    198\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(messages, \u001b[38;5;28;01mFalse\u001b[39;00m, model_settings, model_request_parameters)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personal_repos/deep_research/00_labs/.venv/lib/python3.12/site-packages/pydantic_ai/models/google.py:385\u001b[39m, in \u001b[36mGoogleModel._process_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    383\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedModelBehavior(\u001b[33m'\u001b[39m\u001b[33mSafety settings triggered\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(response))\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedModelBehavior(\n\u001b[32m    386\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mContent field missing from Gemini response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(response)\n\u001b[32m    387\u001b[39m         )  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    388\u001b[39m parts = candidate.content.parts \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    389\u001b[39m vendor_id = response.response_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mUnexpectedModelBehavior\u001b[39m: Content field missing from Gemini response, body:\nsdk_http_response=HttpResponse(\n  headers=<dict len=11>\n) candidates=[Candidate(\n  finish_reason=<FinishReason.MALFORMED_FUNCTION_CALL: 'MALFORMED_FUNCTION_CALL'>,\n  index=0\n)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='DJy4aLDFL4CRmtkP9LaviA0' usage_metadata=GenerateContentResponseUsageMetadata(\n  prompt_token_count=7580,\n  prompt_tokens_details=[\n    ModalityTokenCount(\n      modality=<MediaModality.TEXT: 'TEXT'>,\n      token_count=7580\n    ),\n  ],\n  total_token_count=7580\n) automatic_function_calling_history=[] parsed=None"
     ]
    }
   ],
   "source": [
    "web_deep_researcher = web_deep_researcher()\n",
    "result = await web_deep_researcher.execute(\"how can I use pydantic-ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7d57c",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f4a39",
   "metadata": {},
   "source": [
    "https://docs.yugabyte.com/preview/sample-data/northwind/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b2468",
   "metadata": {},
   "source": [
    "# Software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c44f77",
   "metadata": {},
   "source": [
    "context7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89598e3f",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf209eea",
   "metadata": {},
   "source": [
    "https://github.com/chroma-core/chroma-mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd2b20",
   "metadata": {},
   "source": [
    "# All porpuse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
