{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f66c58e",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this Lab is to demonstrate how to create a simple Agent using Pydantic AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142fbb13",
   "metadata": {},
   "source": [
    "# LLM Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa70278",
   "metadata": {},
   "source": [
    "We define the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f3cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "import os\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY: str\n",
    "    MODEL_NAME: str\n",
    "    CONTEXT7_API_KEY: str\n",
    "    class Config:\n",
    "        #ignore extra fields\n",
    "        extra = \"ignore\"\n",
    "        env_file = \".env\"\n",
    "\n",
    "settings = Settings()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = settings.GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718c818",
   "metadata": {},
   "source": [
    "# Simple LLM Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d084b4",
   "metadata": {},
   "source": [
    "Simple LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9200e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, alright, settle down folks! I've got one for ya...\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "...Because they make up *everything*!\n",
      "\n",
      "*ba-dum-tss!* I'll be here all week! Try the veal!\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "joke_agent = Agent(settings.MODEL_NAME,\n",
    "                instructions=\"You are a comedian, you tell jokes\",\n",
    ")\n",
    "result = await joke_agent.run(\"Tell me a joke\")\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c719f4",
   "metadata": {},
   "source": [
    "## Structured LLM Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d1cc1",
   "metadata": {},
   "source": [
    "We define the Pydantic model for the structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0016ac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joke=\"Why don't scientists trust atoms? Because they make up everything!\"\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class joke_output(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "joke_agent = Agent(settings.MODEL_NAME,\n",
    "                instructions=\"You are a comedian, you tell jokes\",\n",
    "                output_type=joke_output\n",
    ")\n",
    "result = await joke_agent.run(\"Tell me a joke\")\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88d346",
   "metadata": {},
   "source": [
    "what if we want 4 jokes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20204a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why didn't the skeleton cross the road? Because he had no guts!\",\n",
       " \"Why don't scientists trust atoms? Because they make up everything!\",\n",
       " \"Why don't scientists trust atoms? Because they make up everything!\",\n",
       " \"Why don't scientists trust atoms? Because they make up everything!\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_history = []\n",
    "for i in range(4):\n",
    "    result = await joke_agent.run(\"Tell me a joke\")\n",
    "    jokes_history.append(result.output.joke)\n",
    "\n",
    "jokes_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5cd2f5",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894f806",
   "metadata": {},
   "source": [
    "Add the JokeDependencies to keep track of the jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0952887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joke=\"Why don't scientists trust atoms? Because they make up everything!\"\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# We use dataclass because it allows us to add any object as a dependency, in this case a list of strings\n",
    "@dataclass\n",
    "class JokeDependencies:\n",
    "    previous_jokes: list[str]\n",
    "\n",
    "# Output defined by Pydantic\n",
    "class joke_output(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "joke_agent = Agent(settings.MODEL_NAME,\n",
    "                instructions=\"You are a comedian. You are given a list of previous jokes. You need to tell a new joke that is not in the list\",\n",
    "                deps_type=JokeDependencies,\n",
    "                output_type=joke_output)\n",
    "\n",
    "@joke_agent.system_prompt  \n",
    "async def add_previous_jokes(ctx: RunContext[JokeDependencies]) -> str:\n",
    "    return f\"The previous jokes are {ctx.deps.previous_jokes}\"\n",
    "\n",
    "result = await joke_agent.run(\"Tell me a joke\", deps=JokeDependencies(previous_jokes=[]))\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a6ff2",
   "metadata": {},
   "source": [
    "Now, what if we want 4 jokes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d1a678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why don't scientists trust atoms? Because they make up everything!\",\n",
       " 'I told my wife she was drawing her eyebrows too high. She looked surprised.',\n",
       " \"Parallel lines have so much in common. It's a shame they'll never meet.\",\n",
       " 'What do you call a fake noodle? An impasta.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_history = JokeDependencies(previous_jokes=[])\n",
    "for i in range(4):\n",
    "    result = await joke_agent.run(\"Tell me a joke\", deps=jokes_history)\n",
    "    jokes_history.previous_jokes.append(result.output.joke)\n",
    "\n",
    "jokes_history.previous_jokes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd6cc2",
   "metadata": {},
   "source": [
    "# Agent with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7165dd5",
   "metadata": {},
   "source": [
    "Definition of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88c0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "from random import randint\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# We use dataclass because it allows us to add any object as a dependency, in this case a list of strings\n",
    "@dataclass\n",
    "class JokeDependencies:\n",
    "    previous_jokes: list[str]\n",
    "\n",
    "# Output defined by Pydantic\n",
    "class joke_output(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "joke_agent = Agent(settings.MODEL_NAME,\n",
    "                instructions=\"You are a comedian. You are given a list of previous jokes. You need to tell a new joke that is not in the list\",\n",
    "                deps_type=JokeDependencies,\n",
    "                output_type=joke_output)\n",
    "\n",
    "@joke_agent.system_prompt  \n",
    "async def add_previous_joke(ctx: RunContext[JokeDependencies]) -> str:\n",
    "    return f\"The previous jokes are {ctx.deps.previous_jokes}\"\n",
    "\n",
    "async def tell_a_joke(previous_jokes: list[str]=[]) -> str:\n",
    "    \"\"\"Creates a new joke, provide a list of previous jokes, if there are no previous jokes, just provide an empty list\"\"\"\n",
    "    result = await joke_agent.run(\"Tell me a joke\", deps=JokeDependencies(previous_jokes=previous_jokes))\n",
    "    return result.output.joke\n",
    "\n",
    "def random_number(min_val: int = 1, max_val: int = 100) -> int:\n",
    "    \"\"\"Generates a random number in a given range.\"\"\"\n",
    "    return randint(min_val, max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98901928",
   "metadata": {},
   "source": [
    "## Agent that uses tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7362b1",
   "metadata": {},
   "source": [
    "We define the agent with the new output model and the tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df857ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserPromptNode(user_prompt='Please give me 3 random jokes and 5 random numbers. Then write a small poem about them.', instructions=None, instructions_functions=[], system_prompts=(), system_prompt_functions=[], system_prompt_dynamic_functions={})\n",
      "ModelRequestNode(request=ModelRequest(parts=[UserPromptPart(content='Please give me 3 random jokes and 5 random numbers. Then write a small poem about them.', timestamp=datetime.datetime(2025, 9, 3, 19, 21, 55, 358731, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tell_a_joke', args={'previous_jokes': []}, tool_call_id='pyd_ai_e241f74e0084433c836fa3edf8d7b0e8')], usage=RequestUsage(input_tokens=228, output_tokens=172, details={'thoughts_tokens': 154, 'text_prompt_tokens': 228}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 21, 57, 118682, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='VZW4aM6mCrXiqtsPlpWL2A8'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tell_a_joke', content=\"Why don't scientists trust atoms? Because they make up everything!\", tool_call_id='pyd_ai_e241f74e0084433c836fa3edf8d7b0e8', timestamp=datetime.datetime(2025, 9, 3, 19, 21, 58, 281389, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tell_a_joke', args={'previous_jokes': [\"Why don't scientists trust atoms? Because they make up everything!\"]}, tool_call_id='pyd_ai_8c4f88d601b042d99dd5f2b0bbecc67b')], usage=RequestUsage(input_tokens=278, output_tokens=107, details={'thoughts_tokens': 75, 'text_prompt_tokens': 278}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 21, 59, 391457, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='V5W4aLGFG_XzqtsPidWeuA8'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tell_a_joke', content='I told my wife she was drawing her eyebrows too high. She looked surprised.', tool_call_id='pyd_ai_8c4f88d601b042d99dd5f2b0bbecc67b', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 2, 911304, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='tell_a_joke', args={'previous_jokes': [\"Why don't scientists trust atoms? Because they make up everything!\", 'I told my wife she was drawing her eyebrows too high. She looked surprised.']}, tool_call_id='pyd_ai_0aced3dd82554e3f88638f87ca9b5009')], usage=RequestUsage(input_tokens=344, output_tokens=115, details={'thoughts_tokens': 66, 'text_prompt_tokens': 344}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 4, 17566, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='XJW4aOG6BLK3mtkP-eaDsA8'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='tell_a_joke', content='What do you call a fake noodle? An impasta!', tool_call_id='pyd_ai_0aced3dd82554e3f88638f87ca9b5009', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 5, 184359, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='random_number', args={}, tool_call_id='pyd_ai_9b86cb45714a426fa07f9921a8beaabd')], usage=RequestUsage(input_tokens=423, output_tokens=63, details={'thoughts_tokens': 53, 'text_prompt_tokens': 423}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 6, 201038, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='XpW4aP2OD8mmmtkPqtqUsA8'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='random_number', content=85, tool_call_id='pyd_ai_9b86cb45714a426fa07f9921a8beaabd', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 6, 202799, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='random_number', args={}, tool_call_id='pyd_ai_ebd64731d67e45df9aa90f0524d128cf')], usage=RequestUsage(input_tokens=451, output_tokens=86, details={'thoughts_tokens': 76, 'text_prompt_tokens': 451}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 7, 175057, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='X5W4aNT-DeLDqtsPy73SiQ0'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='random_number', content=3, tool_call_id='pyd_ai_ebd64731d67e45df9aa90f0524d128cf', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 7, 178398, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='random_number', args={}, tool_call_id='pyd_ai_f527c360d22048f5a67b7ae910a444cf')], usage=RequestUsage(input_tokens=478, output_tokens=84, details={'thoughts_tokens': 74, 'text_prompt_tokens': 478}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 8, 379039, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='YJW4aLa4GoCRmtkP9LaviA0'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='random_number', content=10, tool_call_id='pyd_ai_f527c360d22048f5a67b7ae910a444cf', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 8, 380098, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='random_number', args={}, tool_call_id='pyd_ai_01f09472c5c4443ca261b20c886bf57a')], usage=RequestUsage(input_tokens=506, output_tokens=62, details={'thoughts_tokens': 52, 'text_prompt_tokens': 506}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 9, 317491, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='YZW4aPDUFsOhqtsPhMfdwQw'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='random_number', content=27, tool_call_id='pyd_ai_01f09472c5c4443ca261b20c886bf57a', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 9, 321502, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='random_number', args={}, tool_call_id='pyd_ai_2d413c8c7fa74ebbbd02d04fec29338b')], usage=RequestUsage(input_tokens=534, output_tokens=69, details={'thoughts_tokens': 59, 'text_prompt_tokens': 534}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 10, 253733, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='YpW4aJftEsStqtsPktO4iA0'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='random_number', content=94, tool_call_id='pyd_ai_2d413c8c7fa74ebbbd02d04fec29338b', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 10, 254339, tzinfo=datetime.timezone.utc))]))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'poem': \"Three jokes were told, with laughter bright,\\nOf atoms, eyebrows, and noodle's plight.\\nThen numbers appeared, a curious few,\\n85, 3, 10, 27, and 94 too.\\nA mix of fun, a playful spree,\\nFor you and for me, a happy decree.\", 'numbers': [85, 3, 10, 27, 94], 'jokes': [\"Why don't scientists trust atoms? Because they make up everything!\", 'I told my wife she was drawing her eyebrows too high. She looked surprised.', 'What do you call a fake noodle? An impasta!']}, tool_call_id='pyd_ai_9c9cd0358351490e8a9ebb50d5ad337a')], usage=RequestUsage(input_tokens=562, output_tokens=406, details={'thoughts_tokens': 253, 'text_prompt_tokens': 562}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 12, 841190, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='ZJW4aOe6NsmvqtsPnZOawA8'))\n",
      "End(data=FinalResult(output=PoemOutput(jokes=[\"Why don't scientists trust atoms? Because they make up everything!\", 'I told my wife she was drawing her eyebrows too high. She looked surprised.', 'What do you call a fake noodle? An impasta!'], numbers=[85, 3, 10, 27, 94], poem=\"Three jokes were told, with laughter bright,\\nOf atoms, eyebrows, and noodle's plight.\\nThen numbers appeared, a curious few,\\n85, 3, 10, 27, and 94 too.\\nA mix of fun, a playful spree,\\nFor you and for me, a happy decree.\"), tool_name='final_result', tool_call_id='pyd_ai_9c9cd0358351490e8a9ebb50d5ad337a'))\n"
     ]
    }
   ],
   "source": [
    "class PoemOutput(BaseModel):\n",
    "    jokes: list[str]\n",
    "    numbers: list[int]\n",
    "    poem: str\n",
    "\n",
    "agent = Agent(settings.MODEL_NAME, tools=[tell_a_joke, random_number], output_type=PoemOutput)\n",
    "\n",
    "# Run agent\n",
    "nodes = []\n",
    "async with agent.iter(\n",
    "    \"Please give me 3 random jokes and 5 random numbers. Then write a small poem about them.\",\n",
    ") as agent_run:\n",
    "    async for node in agent_run:\n",
    "        # Each node represents a step in the agent's execution\n",
    "        print(node)\n",
    "        nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3469212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"jokes\": [\n",
      "    \"Why don't scientists trust atoms? Because they make up everything!\",\n",
      "    \"I told my wife she was drawing her eyebrows too high. She looked surprised.\",\n",
      "    \"What do you call a fake noodle? An impasta!\"\n",
      "  ],\n",
      "  \"numbers\": [\n",
      "    85,\n",
      "    3,\n",
      "    10,\n",
      "    27,\n",
      "    94\n",
      "  ],\n",
      "  \"poem\": \"Three jokes were told, with laughter bright,\\nOf atoms, eyebrows, and noodle's plight.\\nThen numbers appeared, a curious few,\\n85, 3, 10, 27, and 94 too.\\nA mix of fun, a playful spree,\\nFor you and for me, a happy decree.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nodes[-1].data.output.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c1109",
   "metadata": {},
   "source": [
    "# MCP Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072eeb24",
   "metadata": {},
   "source": [
    "## API MCPs: Context7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f61e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserPromptNode(user_prompt='Give me the code for a simple agent that is connected to an MCP, using ', instructions='You are a helpful assistant that can answer questions about code, you use Context7 to search first for the library and then ask some questions to context7 about that library, based on the results, you give an answer to the user', instructions_functions=[], system_prompts=(), system_prompt_functions=[], system_prompt_dynamic_functions={})\n",
      "ModelRequestNode(request=ModelRequest(parts=[UserPromptPart(content='Give me the code for a simple agent that is connected to an MCP, using ', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 23, 546851, tzinfo=datetime.timezone.utc))], instructions='You are a helpful assistant that can answer questions about code, you use Context7 to search first for the library and then ask some questions to context7 about that library, based on the results, you give an answer to the user'))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='resolve-library-id', args={'libraryName': 'MCP agent'}, tool_call_id='pyd_ai_f845e411993b45c3a319e7f49a05caab')], usage=RequestUsage(input_tokens=629, output_tokens=128, details={'thoughts_tokens': 109, 'text_prompt_tokens': 629}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 25, 572654, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='cZW4aMunJsauqtsP2bC4uQw'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='resolve-library-id', content=\"Available Libraries (top matches):\\n\\nEach result includes:\\n- Library ID: Context7-compatible identifier (format: /org/project)\\n- Name: Library or package name\\n- Description: Short summary\\n- Code Snippets: Number of available code examples\\n- Trust Score: Authority indicator\\n- Versions: List of versions if available. Use one of those versions if and only if the user explicitly provides a version in their query.\\n\\nFor best results, select libraries based on name match, trust score, snippet coverage, and relevance to your use case.\\n\\n----------\\n\\n- Title: 1MCP Agent\\n- Context7-compatible library ID: /1mcp-app/agent\\n- Description: 1MCP (One MCP) is a unified Model Context Protocol server that aggregates multiple MCP servers into one, simplifying AI assistant configuration and reducing resource usage.\\n- Code Snippets: 549\\n- Trust Score: 3.7\\n----------\\n- Title: Claude Desktop MCP Browser Agent\\n- Context7-compatible library ID: /imprvhub/mcp-browser-agent\\n- Description: A powerful Model Context Protocol (MCP) integration providing Claude Desktop with autonomous browser automation, featuring advanced browser interactions, API client capabilities, and AI agent functionalities.\\n- Code Snippets: 28\\n- Trust Score: 7.7\\n----------\\n- Title: LangGraph MCP Agents\\n- Context7-compatible library ID: /teddynote-lab/langgraph-mcp-agents\\n- Description: LangGraph-powered ReAct agent with Model Context Protocol (MCP) integration. A Streamlit web interface for dynamically configuring, deploying, and interacting with AI agents capable of accessing various data sources and APIs through MCP tools.\\n- Code Snippets: 45\\n- Trust Score: 7.3\\n----------\\n- Title: Agent-MCP\\n- Context7-compatible library ID: /rinadelph/agent-mcp\\n- Description: Agent-MCP is a multi-agent collaboration protocol for coordinated AI software development, functioning as a living knowledge graph for AI agents.\\n- Code Snippets: 196\\n- Trust Score: 8.5\\n----------\\n- Title: MCP Link\\n- Context7-compatible library ID: /automation-ai-labs/mcp-link\\n- Description: MCP Link automatically converts any OpenAPI V3 API into an MCP Server, enabling seamless integration with AI Agent calling standards without code modification.\\n- Code Snippets: 3\\n- Trust Score: 4.5\\n----------\\n- Title: Azure MCP Server\\n- Context7-compatible library ID: /azure/azure-mcp\\n- Description: The Azure MCP Server implements the MCP specification to seamlessly connect AI agents with Azure services, enhancing agent capabilities with Azure context for various Azure services.\\n- Code Snippets: 970\\n- Trust Score: 9.6\\n----------\\n- Title: MCPAgent\\n- Context7-compatible library ID: /lubyruffy/mcpagent\\n- Description: MCPAgent is an intelligent agent framework based on the Model Context Protocol (MCP), supporting multiple large language models and tool integrations, designed for testing the effectiveness of monolithic agents.\\n- Code Snippets: 10\\n- Trust Score: 9.3\\n----------\\n- Title: MCP Router\\n- Context7-compatible library ID: /mcp-router/mcp-router\\n- Description: MCP Router is a free desktop application for Windows and macOS that simplifies the management of Model Context Protocol (MCP) servers, offering secure, universal connectivity, and AI agent features.\\n- Code Snippets: 65\\n- Trust Score: 5.2\\n----------\\n- Title: Agent Knowledge MCP\\n- Context7-compatible library ID: /itshare4u/agentknowledgemcp\\n- Description: Agent Knowledge MCP is a complete knowledge management solution for AI assistants, featuring Elasticsearch search, document management, and validation.\\n- Code Snippets: 23\\n- Trust Score: 5.2\\n----------\\n- Title: Once UI System MCP\\n- Context7-compatible library ID: /once-ui-system/mcp\\n- Description: Once UI System MCP provides documentation for the Once UI agent-first design system, enabling AI to build responsive apps with minimal syntax and improved developer experience.\\n- Code Snippets: 552\\n- Trust Score: 7.8\\n----------\\n- Title: MCP Agent Graph\\n- Context7-compatible library ID: /keta1930/mcp-agent-graph\\n- Description: MCP Agent Graph (MAG) is an efficient, lightweight, and easy-to-use Agent development framework that allows for visual workflow orchestration and AI-generated agents from needs to agents.\\n- Code Snippets: 8\\n- Trust Score: 5.4\\n----------\\n- Title: Agent MCP Lab\\n- Context7-compatible library ID: /wavespeedai/agent-mcp-lab\\n- Description: The MCP Agent Ecosystem empowers developers to seamlessly integrate and activate advanced multimodal capabilities in AI agents through the WavespeedAI MCP platform.\\n- Code Snippets: 13\\n- Trust Score: 6.9\\n----------\\n- Title: Windows MCP\\n- Context7-compatible library ID: /cursortouch/windows-mcp\\n- Description: Windows MCP is a lightweight, open-source project that enables seamless integration between AI agents and the Windows operating system, allowing agents to perform tasks like file navigation, application control, and UI interaction.\\n- Code Snippets: 6\\n- Trust Score: 6.8\\n----------\\n- Title: MCP-Use\\n- Context7-compatible library ID: /mcp-use/mcp-use\\n- Description: MCP-Use is an open-source solution to connect any LLM to any MCP server, enabling the creation of custom MCP agents with tool access without relying on closed-source clients.\\n- Code Snippets: 435\\n- Trust Score: 5.6\\n----------\\n- Title: Unity MCP\\n- Context7-compatible library ID: /justinpbarnett/unity-mcp\\n- Description: Unity MCP enables AI assistants to interact directly with the Unity Editor, allowing LLMs to manage assets, control scenes, edit scripts, and automate tasks via a local MCP client.\\n- Code Snippets: 7\\n- Trust Score: 9.2\\n----------\\n- Title: MCP Hub\\n- Context7-compatible library ID: /camel-ai/mcp-hub\\n- Description: CAMEL MCP Hub is a community-driven directory for discovering and using verified MCP (Model Context Protocol) servers for building agent-based applications.\\n- Code Snippets: 7\\n- Trust Score: 8.3\\n----------\\n- Title: MCP Unity\\n- Context7-compatible library ID: /codergamester/mcp-unity\\n- Description: MCP Unity is a Unity Editor implementation of the Model Context Protocol, enabling AI assistants to interact with Unity projects via a Node.js server.\\n- Code Snippets: 689\\n- Trust Score: 8.7\\n----------\\n- Title: Crossplane MCP\\n- Context7-compatible library ID: /vfarcic/crossplane-mcp\\n- Description: An MCP server that manages Crossplane services, providing an AI agent with a programmatic interface to interact with Kubernetes for service creation, observation, and deletion.\\n- Code Snippets: 6\\n- Trust Score: 10\\n----------\\n- Title: MCP\\n- Context7-compatible library ID: /databrickslabs/mcp\\n- Description: An experimental collection of MCP servers to help AI agents fetch enterprise data from Databricks and automate developer actions, including a Unity Catalog server for accessing data and tools.\\n- Code Snippets: 23\\n- Trust Score: 9.1\\n----------\\n- Title: MCP Code Executor\\n- Context7-compatible library ID: /bazinga012/mcp_code_executor\\n- Description: The MCP Code Executor is an MCP server that allows LLMs to execute Python code within a specified Python environment, supporting incremental code generation and dependency management.\\n- Code Snippets: 5\\n- Trust Score: 6.9\\n----------\\n- Title: Django MCP Server\\n- Context7-compatible library ID: /omarbenhamid/django-mcp-server\\n- Description: Django MCP Server is a Django extension that implements the Model Context Protocol (MCP), enabling AI agents and MCP clients to interact with Django applications by exposing models and logic as MCP tools.\\n- Code Snippets: 23\\n- Trust Score: 7.5\\n----------\\n- Title: Memento MCP\\n- Context7-compatible library ID: /gannonh/memento-mcp\\n- Description: Memento MCP is a scalable knowledge graph memory system for LLMs, offering semantic retrieval, contextual recall, and temporal awareness for persistent long-term memory.\\n- Code Snippets: 45\\n- Trust Score: 8.6\\n----------\\n- Title: Browser MCP\\n- Context7-compatible library ID: /websites/docs_browsermcp_io-welcome\\n- Description: Browser MCP is an MCP server designed to automate browser interactions. It allows AI applications to navigate the web, fill out forms, and perform other browser-based tasks.\\n- Code Snippets: 2\\n- Trust Score: 7.5\\n----------\\n- Title: MCP HubSpot\\n- Context7-compatible library ID: /ajbmachon/mcp-hubspot\\n- Description: A Model Context Protocol (MCP) server that connects AI assistants to HubSpot CRM data, enabling direct interaction with contacts, companies, and engagements, with built-in vector storage and caching for improved performance.\\n- Code Snippets: 9\\n- Trust Score: 5\\n----------\\n- Title: MCP-Use\\n- Context7-compatible library ID: /pietrozullo/mcp-use\\n- Description: mcp-use is the easiest way to interact with mcp servers with custom agents\\n- Code Snippets: 358\\n- Trust Score: 6.6\\n----------\\n- Title: monday.com MCP\\n- Context7-compatible library ID: /mondaycom/mcp\\n- Description: monday.com's open framework for connecting AI agents into your work OS, providing secure access to structured data and tools for reliable operation in real workflows.\\n- Code Snippets: 19\\n- Trust Score: 8.1\\n----------\\n- Title: MCP Agent\\n- Context7-compatible library ID: /lastmile-ai/mcp-agent\\n- Description: Build effective agents using Model Context Protocol and simple workflow patterns\\n- Code Snippets: 1091\\n- Trust Score: 8.8\\n----------\\n- Title: Playwright MCP\\n- Context7-compatible library ID: /microsoft/playwright-mcp\\n- Description: A Model Context Protocol (MCP) server that provides browser automation capabilities using Playwright, enabling LLMs to interact with web pages through structured accessibility snapshots without needing vision models.\\n- Code Snippets: 23\\n- Trust Score: 9.9\\n----------\\n- Title: Magic MCP\\n- Context7-compatible library ID: /21st-dev/magic-mcp\\n- Description: Magic Component Platform (MCP) is an AI-driven tool that instantly generates UI components from natural language descriptions, integrating seamlessly with popular IDEs for streamlined UI development.\\n- Code Snippets: 8\\n- Trust Score: 6.5\\n----------\\n- Title: Browser MCP\\n- Context7-compatible library ID: /websites/docs_browsermcp_io\\n- Description: Browser MCP is an MCP server that enables AI applications to automate web browsers, allowing them to navigate the web, fill out forms, and interact with online services.\\n- Code Snippets: 2\\n- Trust Score: 7.5\", tool_call_id='pyd_ai_f845e411993b45c3a319e7f49a05caab', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 26, 828154, tzinfo=datetime.timezone.utc))], instructions='You are a helpful assistant that can answer questions about code, you use Context7 to search first for the library and then ask some questions to context7 about that library, based on the results, you give an answer to the user'))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='get-library-docs', args={'context7CompatibleLibraryID': '/lastmile-ai/mcp-agent', 'topic': 'simple agent'}, tool_call_id='pyd_ai_cf2a9ea163da458d95d6a0eec59f80ec')], usage=RequestUsage(input_tokens=3367, cache_read_tokens=908, output_tokens=466, details={'cached_content_tokens': 908, 'thoughts_tokens': 431, 'text_prompt_tokens': 3367, 'text_cache_tokens': 908}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 29, 837455, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='dZW4aPmgNpmkqtsPv-2pyQ8'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='get-library-docs', content='========================\\nCODE SNIPPETS\\n========================\\nTITLE: Basic Finder Agent Example\\nDESCRIPTION: Demonstrates a simple agent that uses fetch and filesystem servers to look up a file, read a blog post from a URL, and summarize the content into a tweet. It showcases agent initialization, tool listing, LLM attachment, and multi-turn interactions.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_snippet_1\\n\\nLANGUAGE: python\\nCODE:\\n```\\nimport asyncio\\nimport os\\n\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\napp = MCPApp(name=\"hello_world_agent\")\\n\\nasync def example_usage():\\n    async with app.run() as mcp_agent_app:\\n        logger = mcp_agent_app.logger\\n        # This agent can read the filesystem or fetch URLs\\n        finder_agent = Agent(\\n            name=\"finder\",\\n            instruction=\"\"\"You can read local files or fetch URLs.\\n                Return the requested information when asked.\"\"\",\\n            server_names=[\"fetch\", \"filesystem\"], # MCP servers this Agent can use\\n        )\\n\\n        async with finder_agent:\\n            # Automatically initializes the MCP servers and adds their tools for LLM use\\n            tools = await finder_agent.list_tools()\\n            logger.info(f\"Tools available:\", data=tools)\\n\\n            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)\\n            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n            # This will perform a file lookup and read using the filesystem server\\n            result = await llm.generate_str(\\n                message=\"Show me what\\'s in README.md verbatim\"\\n            )\\n            logger.info(f\"README.md contents: {result}\")\\n\\n            # Uses the fetch server to fetch the content from URL\\n            result = await llm.generate_str(\\n                message=\"Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents\"\\n            )\\n            logger.info(f\"Blog intro: {result}\")\\n\\n            # Multi-turn interactions by default\\n            result = await llm.generate_str(\"Summarize that in a 128-char tweet\")\\n            logger.info(f\"Tweet: {result}\")\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(example_usage())\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: Quick Start Agent Example\\nDESCRIPTION: Demonstrates how to create a simple agent using mcp-agent that can read local files and fetch web content. It shows agent initialization, LLM attachment (OpenAIAugmentedLLM), and performing tasks like reading a file and summarizing content.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/index.mdx#_snippet_0\\n\\nLANGUAGE: python\\nCODE:\\n```\\nimport asyncio\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\napp = MCPApp(name=\"finder_agent\")\\n\\nasync def main():\\n    async with app.run() as mcp_agent_app:\\n        # Create an agent with access to fetch and filesystem servers\\n        finder_agent = Agent(\\n            name=\"finder\",\\n            instruction=\"You can read local files or fetch URLs. Return the requested information when asked.\",\\n            server_names=[\"fetch\", \"filesystem\"]\\n        )\\n\\n        async with finder_agent:\\n            # Attach an LLM to the agent\\n            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n            # Ask the agent to read a file\\n            result = await llm.generate_str(\"Show me what\\'s in README.md\")\\n            print(result)\\n\\n            # Multi-turn conversation\\n            result = await llm.generate_str(\"Summarize that in a tweet\")\\n            print(result)\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(main())\\n```\\n\\n----------------------------------------\\n\\nTITLE: Basic Agent Workflow Example\\nDESCRIPTION: A simple mcp-agent workflow definition that uses a single agent to perform a research task, fetching data and returning a string result.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/advanced/temporal.mdx#_snippet_5\\n\\nLANGUAGE: python\\nCODE:\\n```\\n@app.workflow\\nclass SimpleAgentWorkflow(Workflow[str]):\\n    @app.workflow_run\\n    async def run(self, query: str) -> WorkflowResult[str]:\\n        agent = Agent(\\n            name=\"researcher\",\\n            instruction=\"Research and provide detailed answers\",\\n            server_names=[\"fetch\", \"filesystem\"]\\n        )\\n        \\n        async with agent:\\n            result = await agent.generate_str(query)\\n            return WorkflowResult(value=result)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Create and Use a Basic Agent\\nDESCRIPTION: Demonstrates how to instantiate an Agent, attach an LLM, and generate a response using filesystem and web fetching tools.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/concepts/agents.mdx#_snippet_0\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\n# Create an agent with access to specific tools\\nfinder_agent = Agent(\\n    name=\"finder\",\\n    instruction=\"\"\"\\nYou are an agent with access to the filesystem\\n    and web fetching capabilities. Your job is to find and retrieve\\n    information based on user requests.\"\"\",\\n    server_names=[\"fetch\", \"filesystem\"],\\n)\\n\\n# Use the agent in an async context\\nasync with finder_agent:\\n    # Attach an LLM to the agent\\n    llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n    # Generate a response\\n    result = await llm.generate_str(\\n        message=\"Find and show me the contents of the README file\"\\n    )\\n    print(result)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Streamlit Simple RAG Chatbot\\nDESCRIPTION: This Streamlit application facilitates Question Answering over a text corpus using a Qdrant vector database, accessed through an MCP server. It\\'s a practical example of implementing a Retrieval-Augmented Generation (RAG) pipeline.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_8\\n\\nLANGUAGE: python\\nCODE:\\n```\\nimport streamlit as st\\nfrom mcp_agent.app import MCPApp\\n\\napp = MCPApp()\\n\\n@app.agent\\ndef rag_chatbot():\\n    return \"A chatbot that answers questions using a Qdrant vector database.\"\\n\\nst.title(\"RAG Chatbot\")\\n\\nquery = st.text_input(\"Ask a question:\")\\n\\nif query:\\n    response = app.invoke(query)\\n    st.write(response)\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Bedrock Agent Configuration\\nDESCRIPTION: Example YAML configuration for the MCP Bedrock Agent, specifying AWS region, credentials, and default model.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_snippet_4\\n\\nLANGUAGE: yaml\\nCODE:\\n```\\nbedrock:\\n  default_model: anthropic.claude-3-haiku-20240307-v1:0\\n  aws_region:\\n  aws_access_key_id:\\n  aws_secret_access_key:\\n  aws_session_token:\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone and Navigate MCP Agent Repository\\nDESCRIPTION: Clones the mcp-agent repository from GitHub and navigates into the basic agent example directory.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/mcp_basic_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/basic/mcp_basic_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Sync MCP Agent Dependencies\\nDESCRIPTION: Synchronizes the dependencies for the mcp-agent project using \\'uv\\'.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_snippet_2\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv sync\\n```\\n\\n----------------------------------------\\n\\nTITLE: Create Orchestrator with create_orchestrator\\nDESCRIPTION: Factory function for the Planner–workers–synthesizer pattern, enabling fast and simple task execution. It takes a list of available agents, LLM provider, model preferences, and context.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_10\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.workflows.factory import create_orchestrator\\nfrom mcp.types import ModelPreferences\\n\\norch = create_orchestrator(\\n    available_agents=[planner_llm, *specs],\\n    provider=\"anthropic\",\\n    model=ModelPreferences(costPriority=0.2, speedPriority=0.3, intelligencePriority=0.5),\\n    context=context,\\n)\\nprint(await orch.generate_str(\"Summarize key components in this repo\"))\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone and Navigate MCP Agent Repository\\nDESCRIPTION: Clones the MCP Agent repository from GitHub and navigates into the specific example directory for the basic Azure agent.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_azure_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/model_providers/mcp_basic_azure_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Marimo File Finder Agent\\nDESCRIPTION: An implementation of the \\'file finder\\' agent using Marimo, a reactive Python notebook environment that serves as an alternative to Jupyter and Streamlit.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_snippet_7\\n\\nLANGUAGE: python\\nCODE:\\n```\\nLink to code: [examples/usecases/marimo_mcp_basic_agent](./examples/usecases/marimo_mcp_basic_agent/)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone Repository and Navigate\\nDESCRIPTION: Clones the mcp-agent repository and changes the directory to the MCP Bedrock Finder Agent example.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/model_providers/mcp_basic_bedrock_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Auto-loaded Subagents Configuration\\nDESCRIPTION: Demonstrates how to add markdown agents to specific directories for auto-loading. This allows for flexible agent discovery and integration.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_2\\n\\nLANGUAGE: python\\nCODE:\\n```\\n# Add markdown agents to .claude/agents or .mcp-agent/agents in the project or home directory,\\n# or use the inline examples in mcp_agent.config.yaml.\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Google Agent Configuration\\nDESCRIPTION: Example YAML configuration for the MCP Google Agent, specifying API key and optional Vertex AI settings.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_google_agent/README.md#_snippet_4\\n\\nLANGUAGE: yaml\\nCODE:\\n```\\ngoogle:\\n  api_key: \"your-google-api-key\"\\n  vertexai: false\\n  # Include these if using VertexAI\\n  # project: \"your-google-cloud-project\"\\n  # location: \"us-central1\"\\n```\\n\\n----------------------------------------\\n\\nTITLE: Define a Simple Workflow\\nDESCRIPTION: Demonstrates how to define a basic workflow using the `@app.workflow` and `@app.workflow_run` decorators. This includes the workflow class and its run method, which contains the core logic.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/temporal/README.md#_snippet_9\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom temporalio import Workflow\\nfrom temporalio.common import WorkflowResult\\n\\n# Assuming \\'app\\' is an instance of your application framework\\n\\n@app.workflow\\nclass SimpleWorkflow(Workflow[str]):\\n    @app.workflow_run\\n    async def run(self, input_data: str) -> WorkflowResult[str]:\\n        # Workflow logic here\\n        result = f\"Processed: {input_data}\"\\n        return WorkflowResult(value=result)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run Finder Agent Locally\\nDESCRIPTION: Navigates to the example directory and runs the main Python script to start the Finder agent.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_snippet_5\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ncd examples/model_providers/mcp_basic_bedrock_agent\\n\\nuv run main.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Finder Agent Example\\nDESCRIPTION: This Python script demonstrates a basic \\'finder\\' agent using mcp-agent. It utilizes the fetch and filesystem servers to read files and retrieve content from URLs, showcasing agent initialization, tool listing, LLM attachment, and multi-turn interactions.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_3\\n\\nLANGUAGE: python\\nCODE:\\n```\\nimport asyncio\\nimport os\\n\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\napp = MCPApp(name=\"hello_world_agent\")\\n\\nasync def example_usage():\\n    async with app.run() as mcp_agent_app:\\n        logger = mcp_agent_app.logger\\n        # This agent can read the filesystem or fetch URLs\\n        finder_agent = Agent(\\n            name=\"finder\",\\n            instruction=\"\"\"You can read local files or fetch URLs.\\n                Return the requested information when asked.\"\"\",\\n            server_names=[\"fetch\", \"filesystem\"], # MCP servers this Agent can use\\n        )\\n\\n        async with finder_agent:\\n            # Automatically initializes the MCP servers and adds their tools for LLM use\\n            tools = await finder_agent.list_tools()\\n            logger.info(f\"Tools available:\", data=tools)\\n\\n            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)\\n            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n            # This will perform a file lookup and read using the filesystem server\\n            result = await llm.generate_str(\\n                message=\"Show me what\\'s in README.md verbatim\"\\n            )\\n            logger.info(f\"README.md contents: {result}\")\\n\\n            # Uses the fetch server to fetch the content from URL\\n            result = await llm.generate_str(\\n                message=\"Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents\"\\n            )\\n            logger.info(f\"Blog intro: {result}\")\\n\\n            # Multi-turn interactions by default\\n            result = await llm.generate_str(\"Summarize that in a 128-char tweet\")\\n            logger.info(f\"Tweet: {result}\")\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(example_usage())\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Agent Server for Claude Desktop\\nDESCRIPTION: This example demonstrates wrapping an mcp-agent application within an MCP server, exposing agents and workflows to Claude Desktop for user request servicing. It showcases a multi-agent evaluation task where agents assess poem aspects and an aggregator synthesizes findings.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_6\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.app import MCPApp\\n\\napp = MCPApp()\\n\\n@app.agent\\ndef poem_evaluator():\\n    return \"An agent that evaluates aspects of a poem.\"\\n\\n@app.workflow\\ndef parallel_workflow():\\n    return \"A workflow that runs agents in parallel.\"\\n\\nif __name__ == \"__main__\":\\n    app.run()\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: FanIn: Aggregate String Outputs with Agent Names\\nDESCRIPTION: Aggregates string outputs from multiple agents, including agent names in the attribution. It takes a dictionary mapping agent names to their string outputs and returns a single combined string.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_267\\n\\nLANGUAGE: python\\nCODE:\\n```\\nclass FanIn:\\n    def aggregate_messages(self, messages: Dict[str, str]) -> str:\\n        \"\"\"Aggregate string outputs with agent names.\\n\\n        Args:\\n            messages: Dictionary mapping agent names to their string outputs\\n\\n        Returns:\\n            str: Combined string with agent attributions\\n        \"\"\"\\n        # Implementation details would go here\\n        pass\\n```\\n\\n----------------------------------------\\n\\nTITLE: ConsoleTransport Implementation\\nDESCRIPTION: A simple transport that prints events to the console. It inherits from FilteredEventTransport, allowing for optional event filtering.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_141\\n\\nLANGUAGE: python\\nCODE:\\n```\\nimport sys\\nfrom typing import Optional\\nfrom .event import Event\\nfrom .event_filter import EventFilter\\n\\nclass ConsoleTransport(FilteredEventTransport):\\n    \"\"\"Simple transport that prints events to console.\"\"\"\\n\\n    def __init__(self, event_filter: Optional[EventFilter] = None):\\n        super().__init__(event_filter)\\n\\n    def send_matched_event(self, event: Event) -> None:\\n        \"\"\"Print the event to standard output.\"\"\"\\n        print(event, file=sys.stdout)\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: Application Integration with MCPApp\\nDESCRIPTION: Shows how to integrate agents into a full application using the `MCPApp` class. This includes setting up the application, running it within a context, and creating/using agents for specific tasks.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/concepts/agents.mdx#_snippet_8\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.app import MCPApp\\n\\napp = MCPApp(name=\"my_application\")\\n\\nasync def main():\\n    async with app.run() as agent_app:\\n        logger = agent_app.logger\\n        context = agent_app.context\\n\\n        # Create and use agents within the app context\\n        agent = Agent(\\n            name=\"assistant\",\\n            instruction=\"You are a helpful assistant.\",\\n            server_names=[\"filesystem\", \"fetch\"]\\n        )\\n\\n        async with agent:\\n            llm = await agent.attach_llm(OpenAIAugmentedLLM)\\n            result = await llm.generate_str(\"Help me organize my files\")\\n            logger.info(\"Task completed\", data={\"result\": result})\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone and Navigate MCP Agent Repo\\nDESCRIPTION: Clones the MCP agent repository and navigates into the Slack agent example directory. This is the initial step for setting up the project.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/mcp_basic_slack_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/usecases/mcp_basic_slack_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Core MCP Agent Dependency\\nDESCRIPTION: Installs the main MCP Agent package with all optional features enabled.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/reliable_conversation/requirements.txt#_snippet_0\\n\\nLANGUAGE: python\\nCODE:\\n```\\nmcp-agent[all]\\n```\\n\\n----------------------------------------\\n\\nTITLE: Load Agent Specs\\nDESCRIPTION: Provides functions to load agent specifications programmatically from text, files, or directories. This is useful for working directly with agent configuration files.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_16\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom pathlib import Path\\nfrom mcp_agent.workflows.factory import (\\n  load_agent_specs_from_text,\\n  load_agent_specs_from_file,\\n  load_agent_specs_from_dir,\\n)\\n\\nspecs = load_agent_specs_from_file(str(Path(__file__).parent / \"agents.yaml\"), context=context)\\nspecs_from_dir = load_agent_specs_from_dir(\".mcp-agent/agents\", context=context)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Human Input Integration with Console Callback\\nDESCRIPTION: Shows how to integrate human input into the agent\\'s workflow using a console callback. This enables the LLM to request clarification or input from a user during execution, making the agent more interactive.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/concepts/agents.mdx#_snippet_5\\n\\nLANGUAGE: python\\nCODE:\\n```\\n# The agent can automatically request human input when needed\\n# This is handled through the human_input_callback mechanism\\n# and appears as a tool the LLM can call\\nfrom mcp_agent.human_input.handler import console_input_callback\\n\\napp = MCPApp(name=\"my_application\", human_input_callback=console_input_callback)\\n\\n# ...rest of your code\\n\\nresult = await llm.generate_str(\\n    \"Please review this analysis and ask me any questions you need clarification on.\"\\n)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run MCP Google Finder Agent\\nDESCRIPTION: Executes the main script for the MCP Google Finder Agent locally.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_google_agent/README.md#_snippet_5\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ncd examples/model_providers/mcp_basic_google_agent\\n\\nuv run main.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Agent Specifications (YAML/JSON)\\nDESCRIPTION: Defines agents using `AgentSpec` in separate YAML or JSON files. These files are discovered through configured search paths.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_6\\n\\nLANGUAGE: yaml\\nCODE:\\n```\\nagents:\\n  - name: finder\\n    instruction: You can read files and fetch URLs\\n    server_names: [filesystem, fetch]\\n  - name: coder\\n    instruction: You can inspect and modify code files in the repository\\n    server_names: [filesystem]\\n```\\n\\n----------------------------------------\\n\\nTITLE: Inline Agent Definitions (YAML)\\nDESCRIPTION: Defines agents directly within the configuration file using YAML. This method offers the highest precedence for agent definitions.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_5\\n\\nLANGUAGE: yaml\\nCODE:\\n```\\nagents:\\n  enabled: true\\n  search_paths:\\n    - \".claude/agents\"\\n    - \"~/.claude/agents\"\\n    - \".mcp-agent/agents\"\\n    - \"~/.mcp-agent/agents\"\\n  pattern: \"**/*.*\"\\n  definitions:\\n    - name: inline-coder\\n      instruction: |\\n        Senior software engineer. Proactively read and edit files.\\n        Prefer small, safe changes and explain briefly.\\n      servers: [filesystem]\\n    - name: inline-researcher\\n      instruction: |\\n        Web research specialist. Use fetch tools to gather and summarize information.\\n      servers: [fetch]\\n```\\n\\n----------------------------------------\\n\\nTITLE: Claude-style Markdown Agents\\nDESCRIPTION: Defines agents using Markdown files with frontmatter specifying agent metadata. The `tools` field in the frontmatter maps to `server_names`.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_7\\n\\nLANGUAGE: markdown\\nCODE:\\n```\\n---\\nname: code-reviewer\\ndescription: Expert code reviewer, use proactively\\ntools: filesystem, fetch\\n---\\n\\nReview code rigorously. Provide findings by priority.\\n```\\n\\n----------------------------------------\\n\\nTITLE: Basic Agent Setup with OpenAI\\nDESCRIPTION: Demonstrates how to set up a basic MCP-Agent application, create an agent with specific capabilities (filesystem and fetch), attach an OpenAI LLM, and generate a response using MCP tools.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_26\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\napp = MCPApp(name=\"my_agent\")\\n\\nasync def main():\\n    async with app.run() as agent_app:\\n        # Create an agent with filesystem and fetch capabilities\\n        agent = Agent(\\n            name=\"finder\",\\n            instruction=\"You help find and analyze files and web content\",\\n            server_names=[\"fetch\", \"filesystem\"]\\n        )\\n        \\n        async with agent:\\n            # Attach an LLM to the agent\\n            llm = await agent.attach_llm(OpenAIAugmentedLLM)\\n            \\n            # Generate responses using MCP tools\\n            result = await llm.generate_str(\\n                message=\"Find and read the config file\"\\n            )\\n            print(result)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Agent Architecture Diagram\\nDESCRIPTION: A plaintext diagram illustrating the interaction between the Marimo notebook, the Finder Agent, and the Fetch and Filesystem MCP Servers.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/marimo_mcp_basic_agent/README.md#_snippet_6\\n\\nLANGUAGE: plaintext\\nCODE:\\n```\\n┌──────────┐      ┌──────────┐      ┌──────────────┐\\n│ marimo   │─────▶│  Finder  │──┬──▶│  Fetch       │\\n│ notebook │      │  Agent   │  │   │  MCP Server  │\\n└──────────┘      └──────────┘  │   └──────────────┘\\n                                │   ┌──────────────┐\\n                                └──▶│  Filesystem  │\\n                                    │  MCP Server  │\\n                                    └──────────────┘\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone Repository and Navigate\\nDESCRIPTION: Clones the mcp-agent repository and changes the directory to the marimo agent example.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/marimo_mcp_basic_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/usecases/marimo_mcp_basic_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Agent Architecture Overview\\nDESCRIPTION: A visual representation of the MCP agent example\\'s architecture, illustrating the interaction between the MCP server (exposing resources and prompts) and the Python-based agent utilizing an LLM.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/mcp/mcp_prompts_and_resources/README.md#_snippet_1\\n\\nLANGUAGE: plaintext\\nCODE:\\n```\\n┌────────────────────┐\\n│   demo_server      │\\n│   MCP Server       │\\n│ (resources, prompts)│\\n└─────────┬──────────┘\\n          │\\n          ▼\\n┌────────────────────┐\\n│  Agent (Python)    │\\n│  + LLM (OpenAI)    │\\n└─────────┬──────────┘\\n          │\\n          ▼\\n   [User/Developer]\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone Repository and Navigate\\nDESCRIPTION: Clones the mcp-agent repository and navigates into the specific example directory for the MCP Google Finder Agent.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_google_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/model_providers/mcp_basic_google_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Server Aggregator for Claude Desktop\\nDESCRIPTION: This example demonstrates an mcp-agent application wrapped in an MCP server, exposing agents and workflows to Claude Desktop. It showcases a multi-agent evaluation task where agents assess a poem and an aggregator summarizes their findings.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_snippet_4\\n\\nLANGUAGE: python\\nCODE:\\n```\\nLink to code: [examples/basic/mcp_server_aggregator](./examples/basic/mcp_server_aggregator)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Main Agent Logic\\nDESCRIPTION: Sets up the MCP agent, attaches an OpenAI LLM, and demonstrates reading local files, fetching web content, and multi-turn conversations.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/quickstart.mdx#_snippet_4\\n\\nLANGUAGE: python\\nCODE:\\n```\\nimport asyncio\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\n# Create the MCP app\\n\\napp = MCPApp(name=\"finder_agent\")\\n\\nasync def main():\\n    async with app.run() as mcp_agent_app:\\n        logger = mcp_agent_app.logger\\n\\n        # Create an agent with access to fetch and filesystem servers\\n        finder_agent = Agent(\\n            name=\"finder\",\\n            instruction=\"\"\"You can read local files or fetch URLs.\\n                Return the requested information when asked.\"\"\",\\n            server_names=[\"fetch\", \"filesystem\"]\\n        )\\n\\n        async with finder_agent:\\n            # List available tools\\n            list_tools_result = await finder_agent.list_tools()\\n            logger.info(\"Available tools:\", data=[tool.name for tool in list_tools_result.tools])\\n\\n            # Attach an OpenAI LLM to the agent\\n            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n            # Example 1: Read a local file\\n            print(\"\\\\n🔍 Reading local file...\")\\n            result = await llm.generate_str(\\n                \"Create a simple README.md file, then show me its contents\"\\n            )\\n            print(f\"📄 Result: {result}\")\\n\\n            # Example 2: Fetch web content\\n            print(\"\\\\n🌐 Fetching web content...\")\\n            result = await llm.generate_str(\\n                \"Fetch the first two paragraphs from https://www.anthropic.com/research/building-effective-agents\"\\n            )\\n            print(f\"📰 Result: {result}\")\\n\\n            # Example 3: Multi-turn conversation\\n            print(\"\\\\n💬 Multi-turn conversation...\")\\n            result = await llm.generate_str(\\n                \"Summarize that content in a 140-character tweet\"\\n            )\\n            print(f\"🐦 Tweet: {result}\")\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(main())\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: Install uv\\nDESCRIPTION: Installs the \\'uv\\' package manager if it\\'s not already installed.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_snippet_1\\n\\nLANGUAGE: bash\\nCODE:\\n```\\npip install uv\\n```\\n\\n----------------------------------------\\n\\nTITLE: SimpleMemory Class Methods\\nDESCRIPTION: An in-memory implementation for storing messages, offering methods to extend, set, append, retrieve, and clear the message history.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_199\\n\\nLANGUAGE: python\\nCODE:\\n```\\nclass SimpleMemory:\\n    def extend(self, messages: List[MessageParamT]):\\n        \"\"\"Extend the memory with a list of messages.\"\"\"\\n        pass\\n\\n    def set(self, messages: List[MessageParamT]):\\n        \"\"\"Set the memory to a specific list of messages.\"\"\"\\n        pass\\n\\n    def append(self, message: MessageParamT):\\n        \"\"\"Append a single message to the memory.\"\"\"\\n        pass\\n\\n    def get(self) -> List[MessageParamT]:\\n        \"\"\"Get all messages from memory.\"\"\"\\n        pass\\n\\n    def clear(self):\\n        \"\"\"Clear all messages from memory.\"\"\"\\n        pass\\n```\\n\\n----------------------------------------\\n\\nTITLE: Basic Temporal Workflow Example\\nDESCRIPTION: Demonstrates a simple agent workflow with filesystem access using Temporal. This example serves as a starting point for understanding Temporal\\'s capabilities within the MCP Agent.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/advanced/temporal.mdx#_snippet_11\\n\\nLANGUAGE: markdown\\nCODE:\\n```\\nExplore complete Temporal examples:\\n\\n<CardGroup cols={2}>\\n  <Card title=\"Basic Workflow\" icon=\"play\" href=\"https://github.com/lastmile-ai/mcp-agent/tree/main/examples/temporal/basic\">\\n    Simple agent workflow with filesystem access\\n  </Card>\\n</CardGroup>\\n```\\n\\n----------------------------------------\\n\\nTITLE: Agent Configuration Programmatically\\nDESCRIPTION: Demonstrates how to configure MCP agent settings programmatically using Python classes for execution engine, MCP servers, and LLM providers.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/concepts/agents.mdx#_snippet_2\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.config import Settings, MCPSettings, MCPServerSettings\\n\\nsettings = Settings(\\n    execution_engine=\"asyncio\",\\n    mcp=MCPSettings(\\n        servers={\\n            \"fetch\": MCPServerSettings(\\n                command=\"uvx\",\\n                args=[\"mcp-server-fetch\"],\\n            ),\\n            \"filesystem\": MCPServerSettings(\\n                command=\"npx\",\\n                args=[\"-y\", \"@modelcontextprotocol/server-filesystem\"],\\n            ),\\n        }\\n    ),\\n    openai=OpenAISettings(\\n        default_model=\"gpt-4o-mini\",\\n    ),\\n)\\n```\\n\\n----------------------------------------\\n\\nTITLE: ConsoleSignalHandler\\nDESCRIPTION: A simple signal handler implementation that interacts with the console and blocks on input.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_106\\n\\nLANGUAGE: python\\nCODE:\\n```\\nclass ConsoleSignalHandler:\\n    # Implementation details for console-based signal handling\\n```\\n\\n----------------------------------------\\n\\nTITLE: Setup: Clone Repository and Navigate\\nDESCRIPTION: Commands to clone the `mcp-agent` GitHub repository and change the current directory to the specific example location for MCP primitives.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/mcp_primitives/mcp_basic_agent/README.md#_snippet_1\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/mcp_primitives/mcp_basic_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Install Example Requirements\\nDESCRIPTION: Installs the Python requirements specific to this example using \\'uv pip\\'.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_snippet_3\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv pip install -r requirements.txt\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Agent System Architecture\\nDESCRIPTION: Visual representation of the MCP agent system, showing the interaction flow from the MCP server (demo_server.py) providing resources and prompts, to the Python agent integrating an LLM (OpenAI), and finally to the user/developer.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/mcp_primitives/mcp_basic_agent/README.md#_snippet_0\\n\\nLANGUAGE: plaintext\\nCODE:\\n```\\n┌────────────────────┐\\n│   demo_server      │\\n│   MCP Server       │\\n│ (resources, prompts)│\\n└─────────┬──────────┘\\n          │\\n          ▼\\n┌────────────────────┐\\n│  Agent (Python)    │\\n│  + LLM (OpenAI)    │\\n└─────────┬──────────┘\\n          │\\n          ▼\\n   [User/Developer]\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Convenience on AugmentedLLM\\nDESCRIPTION: Demonstrates how to use MCP helper functions exposed through an `AugmentedLLM`\\'s underlying `Agent`. These functions allow interaction with tools, resources, and prompts on specified servers.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_17\\n\\nLANGUAGE: python\\nCODE:\\n```\\nawait llm.list_tools(server_name=\"filesystem\")\\nawait llm.list_resources(server_name=\"filesystem\")\\nawait llm.read_resource(\"file://README.md\", server_name=\"filesystem\")\\nawait llm.list_prompts(server_name=\"some-server\")\\nawait llm.get_prompt(\"my-prompt\", server_name=\"some-server\")\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone Repository and Navigate\\nDESCRIPTION: Clones the mcp-agent repository and navigates into the MCP Basic Ollama Agent example directory.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_ollama_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/model_providers/mcp_basic_ollama_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Updating Agent Instructions for Domain\\nDESCRIPTION: Python code snippet demonstrating how to update agent instructions with domain-specific details.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/mcp_realtor_agent/README.md#_snippet_5\\n\\nLANGUAGE: python\\nCODE:\\n```\\ndomain_research_agent = Agent(\\n    name=\"domain_researcher\",\\n    instruction=f\"\"\"You are a world-class {YOUR_DOMAIN} researcher.\\n    \\n    Use domain-specific tools to gather data:\\n    1. Call get_domain_data for {LOCATION/ENTITY}\\n    2. Call analyze_domain_metrics for analysis\\n    3. If API fails, use web search fallback\\n    \\n    Focus on {DOMAIN_SPECIFIC_METRICS}...\\n    \"\"\",\\n    server_names=[\"domain_api\", \"g-search\", \"fetch\"],\\n)\\n```\\n\\n----------------------------------------\\n\\nTITLE: Agent Configuration via YAML\\nDESCRIPTION: Shows how to configure MCP agent settings, including execution engine, logging, MCP servers (tools), and LLM providers using a YAML file.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/concepts/agents.mdx#_snippet_1\\n\\nLANGUAGE: yaml\\nCODE:\\n```\\n# mcp_agent.config.yaml\\n$schema: ../../schema/mcp-agent.config.schema.json\\n\\nexecution_engine: asyncio\\n\\n# Configure logging\\nlogger:\\n  transports: [console, file]\\n  level: debug\\n  progress_display: true\\n\\n# Define available MCP servers (tools)\\nmcp:\\n  servers:\\n    fetch:\\n      command: \"uvx\"\\n      args: [\"mcp-server-fetch\"]\\n    filesystem:\\n      command: \"npx\"\\n      args: [\"-y\", \"@modelcontextprotocol/server-filesystem\"]\\n\\n# LLM provider configuration\\nopenai:\\n  default_model: \"gpt-4o-mini\"\\n```\\n\\n----------------------------------------\\n\\nTITLE: Agent Resource Management\\nDESCRIPTION: Defines resources for agents and agent function results, intended for tool calls that process agents or their results. Includes classes like AgentResource, AgentFunctionResultResource, and AgentFunctionResult.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_299\\n\\nLANGUAGE: python\\nCODE:\\n```\\nclass AgentResource(EmbeddedResource):\\n    agent: Optional[\\'Agent\\'] = None\\n    model_config = ConfigDict(extra=\\'allow\\', arbitrary_types_allowed=True)\\n\\nclass AgentFunctionResultResource(EmbeddedResource):\\n    result: \\'AgentFunctionResult\\'\\n    model_config = ConfigDict(extra=\\'allow\\', arbitrary_types_allowed=True)\\n\\nclass AgentFunctionResult(BaseModel):\\n    value: str = \\'\\'\\n    agent: Agent | None = None\\n    context_variables: dict = {}\\n    model_config = ConfigDict(extra=\\'allow\\', arbitrary_types_allowed=True)\\n\\ndef create_agent_resource(agent: \\'Agent\\') -> AgentResource:\\n    pass\\n\\ndef create_agent_function_result_resource(result: \\'AgentFunctionResult\\') -> AgentFunctionResultResource:\\n    pass\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: Sync MCP Agent Dependencies\\nDESCRIPTION: Synchronizes the dependencies for the \\'mcp-agent\\' project using the \\'uv\\' package manager.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_google_agent/README.md#_snippet_2\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv sync\\n```\\n\\n----------------------------------------\\n\\nTITLE: Evaluator-Optimizer Workflow Example\\nDESCRIPTION: Demonstrates the usage of the EvaluatorOptimizerLLM for refining agent responses. It initializes an optimizer and an evaluator agent, then uses them with a specified LLM factory to generate a refined output based on a quality criterion.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_snippet_14\\n\\nLANGUAGE: python\\nCODE:\\n```\\noptimizer = Agent(name=\"cover_letter_writer\", server_names=[\"fetch\"], instruction=\"Generate a cover letter ...\")\\nevaluator = Agent(name=\"critiquer\", instruction=\"Evaluate clarity, specificity, relevance...\")\\n\\neo_llm = EvaluatorOptimizerLLM(\\n    optimizer=optimizer,\\n    evaluator=evaluator,\\n    llm_factory=OpenAIAugmentedLLM,\\n    min_rating=QualityRating.EXCELLENT, # Keep iterating until the minimum quality bar is reached\\n)\\n\\nresult = await eo_llm.generate_str(\"Write a job cover letter for an AI framework developer role at LastMile AI.\")\\nprint(\"Final refined cover letter:\", result)\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Agent Token Counter Architecture\\nDESCRIPTION: A plaintext representation of the MCP Agent\\'s token counter architecture, showing the interaction between TokenMonitor, TokenCounter, Finder Agent, TokenProgressDisplay, and Analyzer Agent.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/token_counter/README.md#_snippet_3\\n\\nLANGUAGE: plaintext\\nCODE:\\n```\\n┌────────────────┐      ┌──────────────┐\\n│ TokenMonitor   │◀────▶│ TokenCounter │\\n│ (Custom Watch) │      │              │\\n└────────────────┘      └──────────────┘\\n        │                       │\\n        ▼                       ▼\\n┌────────────────┐      ┌──────────────┐\\n│ Finder Agent   │      │ TokenProgress│\\n│ (OpenAI)       │      │ Display      │\\n└────────────────┘      └──────────────┘\\n        │\\n        ▼\\n┌────────────────┐\\n│ Analyzer Agent │\\n│ (Anthropic)    │\\n└────────────────┘\\n```\\n\\n----------------------------------------\\n\\nTITLE: MCP Agent Setup and Execution\\nDESCRIPTION: Instructions for setting up and running the MCP agent example. This involves cloning the repository, navigating to the example directory, and executing the agent script using uv.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/mcp/mcp_prompts_and_resources/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/mcp/mcp_prompts_and_resources\\nuv run main.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone Repository and Navigate\\nDESCRIPTION: Clones the mcp-agent repository and navigates into the browser agent example directory.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/mcp_browser_agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/usecases/mcp_browser_agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone Repository and Navigate to Example\\nDESCRIPTION: Clones the mcp-agent repository from GitHub and changes the current directory to the basic-agent example for the MCP server aggregator.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/mcp_server_aggregator/README.md#_snippet_1\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/basic/mcp_server_aggregator\\n```\\n\\n----------------------------------------\\n\\nTITLE: Console Agent Architecture\\nDESCRIPTION: A diagram illustrating the flow of information between the Console, Browser Agent, and Puppeteer MCP Server.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/mcp_browser_agent/README.md#_snippet_7\\n\\nLANGUAGE: plaintext\\nCODE:\\n```\\n┌─────────┐      ┌───────────┐      ┌──────────────┐\\n│ Console │─────▶│  Browser  │─────▶│  Puppeteer   │\\n└─────────┘      │  Agent    │      │  MCP Server  │\\n                 └───────────┘      └──────────────┘\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run MCP Agent Hello World application locally\\nDESCRIPTION: Execute the main application script to run the MCP Agent locally.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/mcp_hello_world/README.md#_snippet_2\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run main.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Install Example Requirements\\nDESCRIPTION: Installs the Python requirements specific to this Marimo agent example.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/marimo_mcp_basic_agent/README.md#_snippet_3\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv pip install -r requirements.txt\\n```\\n\\n----------------------------------------\\n\\nTITLE: Updating Agent Instructions with Elicitation and Fallback\\nDESCRIPTION: Python snippet for updating agent instructions, emphasizing domain expertise, elicitation, and web search fallback.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/mcp_realtor_agent/README.md#_snippet_8\\n\\nLANGUAGE: python\\nCODE:\\n```\\ninstruction = f\"\"\"You are a {DOMAIN} expert. Use domain tools with elicitation, \\nfallback to web search if APIs fail. Focus on {DOMAIN_GOALS}.\"\"\"\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run MCP Agent Locally\\nDESCRIPTION: Starts the MCP Agent application locally using \\'uv run\\'.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/functions/README.md#_snippet_5\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run main.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone and Navigate to Functions Example\\nDESCRIPTION: Clones the mcp-agent repository and navigates into the functions example directory.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/functions/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/basic/functions\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run Agent Factory Examples\\nDESCRIPTION: Executes various demonstration scripts for the Agent Factory, showcasing different workflow patterns and features.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_1\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run examples/basic/agent_factory/load_and_route.py\\n```\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run examples/basic/agent_factory/orchestrator_demo.py\\n```\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run examples/basic/agent_factory/parallel_demo.py\\n```\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run examples/basic/agent_factory/auto_loaded_subagents.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Marimo File Finder Agent\\nDESCRIPTION: This example demonstrates the \\'file finder\\' agent, originally from the Quickstart guide, implemented using Marimo, a reactive Python notebook environment. It showcases how mcp-agent can be integrated into modern notebook interfaces.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_9\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom marimo import ui\\nfrom mcp_agent.app import MCPApp\\n\\napp = MCPApp()\\n\\n@app.agent\\ndef file_finder():\\n    return \"An agent that finds files based on user queries.\"\\n\\n@app.output\\ndef find_files_ui():\\n    query = ui.text_input(\"Enter file name or pattern:\")\\n    if query:\\n        results = app.invoke(f\"Find files matching: {query}\")\\n        return ui.markdown(f\"Found: {results}\")\\n    return ui.markdown(\"Enter a query to search for files.\")\\n\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: Get Temporal Pseudo-Random Number Generator\\nDESCRIPTION: Obtains an instance of Temporal\\'s deterministic pseudo-random number generator. This generator is suitable for deterministic operations but not for security-sensitive applications.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_86\\n\\nLANGUAGE: python\\nCODE:\\n```\\ndef get_temporal_random_generator():\\n    \"\"\"\\n    Get an instance of Temporal\\'s deterministic pseudo-random number generator.\\n    Note, this random number generator is not cryptographically safe and should not be used for security purposes.\\n    Returns:\\n        The deterministically-seeded pseudo-random number generator.\\n    \"\"\"\\n    pass\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run MCP Agent Locally\\nDESCRIPTION: Executes the main Python script for the MCP Agent application using the \\'uv run\\' command.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/mcp_basic_agent/README.md#_snippet_7\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run main.py\\n```\\n\\n----------------------------------------\\n\\nTITLE: Create Intent Classifier LLM\\nDESCRIPTION: Creates an intent classifier using an LLM to determine user intent based on provided intents and their descriptions. It requires a list of Intent objects and the LLM provider.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_snippet_15\\n\\nLANGUAGE: python\\nCODE:\\n```\\nfrom mcp_agent.workflows.factory import create_intent_classifier_llm\\nfrom mcp_agent.workflows.intent_classifier.intent_classifier_base import Intent\\n\\nintents = [\\n  Intent(key=\"search\", description=\"Web search and summarize\"),\\n  Intent(key=\"code\", description=\"Read or modify local code files\"),\\n]\\nclf = await create_intent_classifier_llm(intents=intents, provider=\"openai\", context=context)\\nprint(await clf.classify(\"Open the README and summarize it\"))\\n```\\n\\n----------------------------------------\\n\\nTITLE: Clone and Navigate MCP Agent Example\\nDESCRIPTION: Clones the mcp-agent repository and navigates to the mcp_sse_with_headers example directory.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/mcp/mcp_sse_with_headers/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/mcp/mcp_sse_with_headers\\n```\\n\\n----------------------------------------\\n\\nTITLE: Run MCP Agent\\nDESCRIPTION: This command starts the MCP agent with tracing enabled. It assumes the agent\\'s tracing configuration is set up to log spans to the console.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/tracing/agent/README.md#_snippet_0\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv run tracing/agent\\n```\\n\\n----------------------------------------\\n\\nTITLE: Standalone mcp-agent Application Example\\nDESCRIPTION: Illustrates the usage of mcp-agent applications in a standalone fashion, not necessarily tied to an MCP client or host. The examples directory contains such applications.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_snippet_26\\n\\nLANGUAGE: python\\nCODE:\\n```\\n# Refer to the /examples directory for standalone application implementations.\\n```\\n\\n----------------------------------------\\n\\nTITLE: Install Example Requirements\\nDESCRIPTION: Installs the Python requirements specific to the MCP Google Finder Agent example using \\'uv\\'.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_google_agent/README.md#_snippet_3\\n\\nLANGUAGE: bash\\nCODE:\\n```\\nuv pip install -r requirements.txt\\n```\\n\\n----------------------------------------\\n\\nTITLE: Project Setup and Running Example\\nDESCRIPTION: Instructions for setting up and running an example agent. This involves cloning the repository, navigating to an example directory, configuring secrets (either via YAML or .env file), and running the main Python script.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_snippet_3\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ncd examples/basic/mcp_basic_agent # Or any other example\\n# Option A: secrets YAML\\n# cp mcp_agent.secrets.yaml.example mcp_agent.secrets.yaml && edit mcp_agent.secrets.yaml\\n# Option B: .env\\ncp .env.example .env && edit .env\\nuv run main.py\\n\\n```\\n\\n----------------------------------------\\n\\nTITLE: Project Setup and Dependency Installation\\nDESCRIPTION: Clones the MCP Agent repository and installs necessary dependencies using uv and npm.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/usecases/mcp_realtor_agent/README.md#_snippet_1\\n\\nLANGUAGE: bash\\nCODE:\\n```\\ngit clone https://github.com/lastmile-ai/mcp-agent.git\\ncd mcp-agent/examples/usecases/mcp_research_agent\\nuv init\\nuv sync\\nuv add mcp-agent fastmcp aiohttp\\nnpm install -g g-search-mcp\\nnpm install -g @modelcontextprotocol/server-filesystem\\n```\\n\\n----------------------------------------\\n\\nTITLE: CohereEmbeddingIntentClassifier\\nDESCRIPTION: Implements an intent classifier using Cohere\\'s embedding models. It inherits from `EmbeddingIntentClassifier` and leverages Cohere for semantic similarity calculations.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/LLMS.txt#_snippet_192\\n\\nLANGUAGE: python\\nCODE:\\n```\\nclass CohereEmbeddingIntentClassifier(EmbeddingIntentClassifier):\\n    \"\"\"An intent classifier that uses Cohere\\'s embedding models for computing semantic simiarity based classifications.\"\"\"\\n\\n    def __init__(self, intents: List[Intent], embedding_model: CohereEmbeddingModel | None = None, context: Optional[\\'Context\\'] = None):\\n        \"\"\"Initializes the CohereEmbeddingIntentClassifier.\\n\\n        Args:\\n            intents: A list of intents.\\n            embedding_model: The Cohere embedding model to use (defaults to None).\\n            context: Optional context for the classifier.\\n        \"\"\"\\n        pass\\n\\n    @classmethod\\n    def create(cls, intents: List[Intent], embedding_model: CohereEmbeddingModel | None = None, context: Optional[\\'Context\\'] = None) -> \\'CohereEmbeddingIntentClassifier\\':\\n        \"\"\"Factory method to create and initialize a Cohere embedding classifier.\\n        Use this instead of constructor since we need async initialization.\\n\\n        Args:\\n            intents: A list of intents.\\n            embedding_model: The Cohere embedding model to use (defaults to None).\\n            context: Optional context for the classifier (defaults to None).\\n\\n        Returns:\\n            An initialized CohereEmbeddingIntentClassifier instance.\\n        \"\"\"\\n        pass\\n```\\n\\n----------------------------------------\\n\\nTITLE: Agent Architecture Diagram\\nDESCRIPTION: Visual representation of the agent and workflow framework, illustrating the relationships and interactions between core components like Agent, AugmentedLLM, Orchestrator, and others.\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/codeboarding/agent-workflow-framework.mdx#_snippet_0\\n\\nLANGUAGE: mermaid\\nCODE:\\n```\\ngraph LR\\n    Agent[\"Agent\"]\\n    AugmentedLLM[\"AugmentedLLM\"]\\n    Orchestrator[\"Orchestrator\"]\\n    ParallelLLM[\"ParallelLLM\"]\\n    Swarm[\"Swarm\"]\\n    Router[\"Router\"]\\n    IntentClassifier[\"IntentClassifier\"]\\n    Executor[\"Executor\"]\\n    MCPConnectionManager[\"MCPConnectionManager\"]\\n    ContextDependent[\"ContextDependent\"]\\n\\n    Agent -- \"Uses\" --> AugmentedLLM\\n    Agent -- \"Delegates to\" --> Executor\\n    AugmentedLLM -- \"Used by\" --> Agent\\n    AugmentedLLM -- \"Used by\" --> Orchestrator\\n    AugmentedLLM -- \"Used by\" --> ParallelLLM\\n    AugmentedLLM -- \"Used by\" --> Swarm\\n    AugmentedLLM -- \"Used by\" --> Router\\n    Orchestrator -- \"Coordinates\" --> Agent\\n    Orchestrator -- \"Uses\" --> AugmentedLLM\\n    ParallelLLM -- \"Coordinates\" --> Agent\\n    ParallelLLM -- \"Uses\" --> AugmentedLLM\\n    Swarm -- \"Coordinates\" --> Agent\\n    Swarm -- \"Uses\" --> AugmentedLLM\\n    Router -- \"Directs tasks to\" --> Agent\\n    Router -- \"Relies on\" --> IntentClassifier\\n    IntentClassifier -- \"Used by\" --> Router\\n    IntentClassifier -- \"Uses\" --> AugmentedLLM\\n    Executor -- \"Executes tasks for\" --> Agent\\n    Executor -- \"Manages\" --> Orchestrator\\n    Executor -- \"Manages\" --> ParallelLLM\\n    Executor -- \"Manages\" --> Swarm\\n    MCPConnectionManager -- \"Facilitates communication for\" --> Agent\\n    MCPConnectionManager -- \"Integrates with\" --> Orchestrator\\n    MCPConnectionManager -- \"Integrates with\" --> Router\\n    ContextDependent -- \"Provides context to\" --> Agent\\n    ContextDependent -- \"Provides context to\" --> Orchestrator\\n    ContextDependent -- \"Provides context to\" --> ParallelLLM\\n    ContextDependent -- \"Provides context to\" --> Swarm\\n    ContextDependent -- \"Provides context to\" --> Router\\n    ContextDependent -- \"Provides context to\" --> IntentClassifier\\n    ContextDependent -- \"Provides context to\" --> Executor\\n    ContextDependent -- \"Provides context to\" --> AugmentedLLM\\n    ContextDependent -- \"Provides context to\" --> MCPConnectionManager\\n```\\n\\n========================\\nQUESTIONS AND ANSWERS\\n========================\\nTOPIC: Agent Factory - mcp-agent\\nQ: What types of agent definitions are supported by the Agent Factory?\\nA: The Agent Factory supports simple YAML agents and auto-loading subagents from inline definitions and directories as specified in `mcp_agent.config.yaml`.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/agent_factory/README.md#_qa_1\\n\\n----------------------------------------\\n\\nTOPIC: MCP Functions Agent Example\\nQ: What is the purpose of the MCP Functions Agent Example?\\nA: The MCP Functions Agent Example demonstrates a \\'math\\' Agent that uses manually-defined functions to calculate simple math results based on user requests. It shows how the agent determines which functions to call and in what sequence.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/functions/README.md#_qa_0\\n\\n----------------------------------------\\n\\nTOPIC: MCP Bedrock Agent Example - Finder Agent\\nQ: What is the purpose of the MCP Bedrock Agent example in the mcp-agent project?\\nA: The MCP Bedrock Agent example demonstrates how to create and run a basic \"Finder\" Agent. This agent utilizes AWS Bedrock and MCP, and has access to the `fetch` MCP server to retrieve information from URLs.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_qa_0\\n\\n----------------------------------------\\n\\nTOPIC: Basic MCP Agent Example\\nQ: What is the purpose of the basic MCP Agent example in the /lastmile-ai/mcp-agent project?\\nA: The basic MCP Agent example demonstrates a \\'finder\\' Agent that can access MCP servers like \\'fetch\\' and \\'filesystem\\'. It allows users to query information about local files or URLs, and the agent intelligently decides which server to use to fulfill the request.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/basic/mcp_basic_agent/README.md#_qa_0\\n\\n----------------------------------------\\n\\nTOPIC: MCP Agent - Build Effective Agents with Model Context Protocol\\nQ: What is the goal of the \\'Building Effective Agents\\' research by Anthropic?\\nA: The research focuses on providing simple, composable patterns for developers to build production-ready AI agents effectively.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_qa_6\\n\\n----------------------------------------\\n\\nTOPIC: MCP Agent Server Examples\\nQ: What does \\'Workflow Encapsulation\\' mean in the context of MCP Agent Servers?\\nA: Workflow Encapsulation means that complex agent workflows are packaged and exposed as simple MCP tools. This hides the complexity of the agent\\'s internal logic and presents a straightforward interface for interaction.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/mcp_agent_server/README.md#_qa_4\\n\\n----------------------------------------\\n\\nTOPIC: MCP Agent - Build Effective Agents with Model Context Protocol\\nQ: What are the two foundational updates from Anthropic that inspired mcp-agent?\\nA: The inspiration for mcp-agent comes from Anthropic\\'s Model Context Protocol, a standardized interface for AI assistants to access software via MCP servers, and their research on \\'Building Effective Agents,\\' which outlines simple, composable patterns for AI agent development.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/README.md#_qa_1\\n\\n----------------------------------------\\n\\nTOPIC: MCP Bedrock Agent Example - Finder Agent\\nQ: What functionality does the MCP Bedrock Agent\\'s \\'Finder\\' agent have?\\nA: The \\'Finder\\' agent has the capability to retrieve information from URLs using the `fetch` MCP server.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/examples/model_providers/mcp_basic_bedrock_agent/README.md#_qa_1\\n\\n----------------------------------------\\n\\nTOPIC: Agent & Workflow Framework Documentation\\nQ: What is an Agent in the context of the Agent & Workflow Framework?\\nA: An Agent is the fundamental building block of the AI system. It encapsulates an agent\\'s core logic, capabilities, and interaction patterns, acting as the primary autonomous entity for performing tasks.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/codeboarding/agent-workflow-framework.mdx#_qa_1\\n\\n----------------------------------------\\n\\nTOPIC: MCP Servers in mcp-agent\\nQ: How do \\'Tools\\' provided by MCP Servers function?\\nA: Tools provided by MCP Servers are functions that agents can invoke to execute specific actions. These can range from simple calculations to complex operations like fetching data.\\n\\n\\nSOURCE: https://github.com/lastmile-ai/mcp-agent/blob/main/docs/concepts/mcp-servers.mdx#_qa_8', tool_call_id='pyd_ai_cf2a9ea163da458d95d6a0eec59f80ec', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 30, 732080, tzinfo=datetime.timezone.utc))], instructions='You are a helpful assistant that can answer questions about code, you use Context7 to search first for the library and then ask some questions to context7 about that library, based on the results, you give an answer to the user'))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[TextPart(content='```python\\nimport asyncio\\nimport os\\n\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\napp = MCPApp(name=\"hello_world_agent\")\\n\\nasync def example_usage():\\n    async with app.run() as mcp_agent_app:\\n        logger = mcp_agent_app.logger\\n        # This agent can read the filesystem or fetch URLs\\n        finder_agent = Agent(\\n            name=\"finder\",\\n            instruction=\"\"\"You can read local files or fetch URLs.\\n                Return the requested information when asked.\"\"\",\\n            server_names=[\"fetch\", \"filesystem\"], # MCP servers this Agent can use\\n        )\\n\\n        async with finder_agent:\\n            # Automatically initializes the MCP servers and adds their tools for LLM use\\n            tools = await finder_agent.list_tools()\\n            logger.info(f\"Tools available:\", data=tools)\\n\\n            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)\\n            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n            # This will perform a file lookup and read using the filesystem server\\n            result = await llm.generate_str(\\n                message=\"Show me what\\'s in README.md verbatim\"\\n            )\\n            logger.info(f\"README.md contents: {result}\")\\n\\n            # Uses the fetch server to fetch the content from URL\\n            result = await llm.generate_str(\\n                message=\"Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents\"\\n            )\\n            logger.info(f\"Blog intro: {result}\")\\n\\n            # Multi-turn interactions by default\\n            result = await llm.generate_str(\"Summarize that in a 128-char tweet\")\\n            logger.info(f\"Tweet: {result}\")\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(example_usage())\\n```'), TextPart(content='\\n\\nThis code demonstrates a basic \"finder\" agent connected to an MCP using the `mcp-agent` library. Here\\'s a breakdown of what it does:\\n\\n1.  **Initializes the MCPApp**: `app = MCPApp(name=\"hello_world_agent\")` creates an instance of the MCP application.\\n2.  **Creates an Agent**: `finder_agent = Agent(...)` defines an agent named \"finder\" with instructions and specifies the MCP servers it can use (`\"fetch\"` for URLs and `\"filesystem\"` for local files).\\n3.  **Lists Available Tools**: `await finder_agent.list_tools()` shows the tools that the agent can access from its connected MCP servers.\\n4.  **Attaches an LLM**: `llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)` connects an OpenAI Large Language Model (LLM) to the agent.\\n5.  **Performs Tasks**:\\n    *   It asks the LLM to read a local file (`README.md`) using the `filesystem` server.\\n    *   It then asks the LLM to fetch and print content from a URL using the `fetch` server.\\n    *   Finally, it demonstrates a multi-turn interaction by asking the LLM to summarize the previously fetched content into a tweet.\\n\\nTo run this code, you would need to have the `mcp-agent` library installed and potentially configure your OpenAI API key. You might also need the `mcp-server-fetch` and `@modelcontextprotocol/server-filesystem` MCP servers running, which `mcp-agent` can manage.')], usage=RequestUsage(input_tokens=20630, cache_read_tokens=3007, output_tokens=986, details={'cached_content_tokens': 3007, 'thoughts_tokens': 166, 'text_prompt_tokens': 20630, 'text_cache_tokens': 3007}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 38, 209973, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='fpW4aM7tD8qfqtsPoeTbwA8'))\n",
      "End(data=FinalResult(output='```python\\nimport asyncio\\nimport os\\n\\nfrom mcp_agent.app import MCPApp\\nfrom mcp_agent.agents.agent import Agent\\nfrom mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\\n\\napp = MCPApp(name=\"hello_world_agent\")\\n\\nasync def example_usage():\\n    async with app.run() as mcp_agent_app:\\n        logger = mcp_agent_app.logger\\n        # This agent can read the filesystem or fetch URLs\\n        finder_agent = Agent(\\n            name=\"finder\",\\n            instruction=\"\"\"You can read local files or fetch URLs.\\n                Return the requested information when asked.\"\"\",\\n            server_names=[\"fetch\", \"filesystem\"], # MCP servers this Agent can use\\n        )\\n\\n        async with finder_agent:\\n            # Automatically initializes the MCP servers and adds their tools for LLM use\\n            tools = await finder_agent.list_tools()\\n            logger.info(f\"Tools available:\", data=tools)\\n\\n            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)\\n            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\\n\\n            # This will perform a file lookup and read using the filesystem server\\n            result = await llm.generate_str(\\n                message=\"Show me what\\'s in README.md verbatim\"\\n            )\\n            logger.info(f\"README.md contents: {result}\")\\n\\n            # Uses the fetch server to fetch the content from URL\\n            result = await llm.generate_str(\\n                message=\"Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents\"\\n            )\\n            logger.info(f\"Blog intro: {result}\")\\n\\n            # Multi-turn interactions by default\\n            result = await llm.generate_str(\"Summarize that in a 128-char tweet\")\\n            logger.info(f\"Tweet: {result}\")\\n\\nif __name__ == \"__main__\":\\n    asyncio.run(example_usage())\\n```\\n\\n\\n\\nThis code demonstrates a basic \"finder\" agent connected to an MCP using the `mcp-agent` library. Here\\'s a breakdown of what it does:\\n\\n1.  **Initializes the MCPApp**: `app = MCPApp(name=\"hello_world_agent\")` creates an instance of the MCP application.\\n2.  **Creates an Agent**: `finder_agent = Agent(...)` defines an agent named \"finder\" with instructions and specifies the MCP servers it can use (`\"fetch\"` for URLs and `\"filesystem\"` for local files).\\n3.  **Lists Available Tools**: `await finder_agent.list_tools()` shows the tools that the agent can access from its connected MCP servers.\\n4.  **Attaches an LLM**: `llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)` connects an OpenAI Large Language Model (LLM) to the agent.\\n5.  **Performs Tasks**:\\n    *   It asks the LLM to read a local file (`README.md`) using the `filesystem` server.\\n    *   It then asks the LLM to fetch and print content from a URL using the `fetch` server.\\n    *   Finally, it demonstrates a multi-turn interaction by asking the LLM to summarize the previously fetched content into a tweet.\\n\\nTo run this code, you would need to have the `mcp-agent` library installed and potentially configure your OpenAI API key. You might also need the `mcp-server-fetch` and `@modelcontextprotocol/server-filesystem` MCP servers running, which `mcp-agent` can manage.'))\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "\n",
    "context7_server = MCPServerStreamableHTTP(\n",
    "    url ='https://mcp.context7.com/mcp',\n",
    "    headers={'CONTEXT7_API_KEY': settings.CONTEXT7_API_KEY}\n",
    ")  \n",
    "\n",
    "mcp_agent = Agent(\n",
    "    settings.MODEL_NAME, toolsets=[context7_server], \n",
    "    instructions=\"You are a helpful assistant that can answer questions about code, you use Context7 to search first for the library and then ask some questions to context7 about that library, based on the results, you give an answer to the user\"\n",
    ")  \n",
    "# Run the Agent\n",
    "async with mcp_agent:  \n",
    "    nodes = []\n",
    "    async with mcp_agent.iter(\n",
    "        \"Give me the code for a simple agent that is connected to an MCP, using \",\n",
    "    ) as agent_run:\n",
    "        async for node in agent_run:\n",
    "            # Each node represents a step in the agent's execution\n",
    "            print(node)\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de230aa3",
   "metadata": {},
   "source": [
    "# Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae67a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import asyncio\n",
      "import os\n",
      "\n",
      "from mcp_agent.app import MCPApp\n",
      "from mcp_agent.agents.agent import Agent\n",
      "from mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM\n",
      "\n",
      "app = MCPApp(name=\"hello_world_agent\")\n",
      "\n",
      "async def example_usage():\n",
      "    async with app.run() as mcp_agent_app:\n",
      "        logger = mcp_agent_app.logger\n",
      "        # This agent can read the filesystem or fetch URLs\n",
      "        finder_agent = Agent(\n",
      "            name=\"finder\",\n",
      "            instruction=\"\"\"You can read local files or fetch URLs.\n",
      "                Return the requested information when asked.\"\"\",\n",
      "            server_names=[\"fetch\", \"filesystem\"], # MCP servers this Agent can use\n",
      "        )\n",
      "\n",
      "        async with finder_agent:\n",
      "            # Automatically initializes the MCP servers and adds their tools for LLM use\n",
      "            tools = await finder_agent.list_tools()\n",
      "            logger.info(f\"Tools available:\", data=tools)\n",
      "\n",
      "            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)\n",
      "            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)\n",
      "\n",
      "            # This will perform a file lookup and read using the filesystem server\n",
      "            result = await llm.generate_str(\n",
      "                message=\"Show me what's in README.md verbatim\"\n",
      "            )\n",
      "            logger.info(f\"README.md contents: {result}\")\n",
      "\n",
      "            # Uses the fetch server to fetch the content from URL\n",
      "            result = await llm.generate_str(\n",
      "                message=\"Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents\"\n",
      "            )\n",
      "            logger.info(f\"Blog intro: {result}\")\n",
      "\n",
      "            # Multi-turn interactions by default\n",
      "            result = await llm.generate_str(\"Summarize that in a 128-char tweet\")\n",
      "            logger.info(f\"Tweet: {result}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    asyncio.run(example_usage())\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "This code demonstrates a basic \"finder\" agent connected to an MCP using the `mcp-agent` library. Here's a breakdown of what it does:\n",
      "\n",
      "1.  **Initializes the MCPApp**: `app = MCPApp(name=\"hello_world_agent\")` creates an instance of the MCP application.\n",
      "2.  **Creates an Agent**: `finder_agent = Agent(...)` defines an agent named \"finder\" with instructions and specifies the MCP servers it can use (`\"fetch\"` for URLs and `\"filesystem\"` for local files).\n",
      "3.  **Lists Available Tools**: `await finder_agent.list_tools()` shows the tools that the agent can access from its connected MCP servers.\n",
      "4.  **Attaches an LLM**: `llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)` connects an OpenAI Large Language Model (LLM) to the agent.\n",
      "5.  **Performs Tasks**:\n",
      "    *   It asks the LLM to read a local file (`README.md`) using the `filesystem` server.\n",
      "    *   It then asks the LLM to fetch and print content from a URL using the `fetch` server.\n",
      "    *   Finally, it demonstrates a multi-turn interaction by asking the LLM to summarize the previously fetched content into a tweet.\n",
      "\n",
      "To run this code, you would need to have the `mcp-agent` library installed and potentially configure your OpenAI API key. You might also need the `mcp-server-fetch` and `@modelcontextprotocol/server-filesystem` MCP servers running, which `mcp-agent` can manage.\n"
     ]
    }
   ],
   "source": [
    "print(nodes[-1].data.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2a3a3",
   "metadata": {},
   "source": [
    "## Command MCPs: DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ba7bf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserPromptNode(user_prompt='What is the weather in Tokyo?', instructions='You are a helpful assistant that can use the DuckDuckGo MCP server to search the web and obtain current information, you always search first and then fetch the content of the search results you think are relevant to the question, finally you answer the question based on the content of the search results', instructions_functions=[], system_prompts=(), system_prompt_functions=[], system_prompt_dynamic_functions={})\n",
      "ModelRequestNode(request=ModelRequest(parts=[UserPromptPart(content='What is the weather in Tokyo?', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 46, 811758, tzinfo=datetime.timezone.utc))], instructions='You are a helpful assistant that can use the DuckDuckGo MCP server to search the web and obtain current information, you always search first and then fetch the content of the search results you think are relevant to the question, finally you answer the question based on the content of the search results'))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='search', args={'query': 'weather in Tokyo'}, tool_call_id='pyd_ai_ce50e96df43c4aa5873472a9a0bb99b3')], usage=RequestUsage(input_tokens=233, output_tokens=43, details={'thoughts_tokens': 28, 'text_prompt_tokens': 233}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 47, 602586, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='h5W4aKaHKLHVz7IPjfrr8A4'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='search', content=\"Found 10 search results:\\n\\n1. Tokyo, Tokyo, Japan Weather Forecast | AccuWeather\\n   URL: https://www.accuweather.com/en/jp/tokyo/226396/weather-forecast/226396\\n   Summary: Tokyo,Tokyo, JapanWeatherForecast, with current conditions, wind, air quality, and what to expect for the next 3 days.\\n\\n2. Tokyo, Japan 14 day weather forecast - timeanddate.com\\n   URL: https://www.timeanddate.com/weather/japan/tokyo/ext\\n   Summary: 2 Week Extended Forecast inTokyo, Japan ... Hour-by-hourweatherforTokyonext 7 days\\n\\n3. Tokyo, Tokyo Prefecture, Japan - The Weather Channel\\n   URL: https://weather.com/weather/today/l/4ba28384e2da53b2861f5b5c70b7332e4ba1dc83e75b948e6fbd2aaceeeceae3\\n   Summary: Today's and tonight'sTokyo,TokyoPrefecture, Japanweatherforecast,weatherconditions and Doppler radar from TheWeatherChannel andWeather.com\\n\\n4. Tokyo - BBC Weather\\n   URL: https://www.bbc.com/weather/1850147\\n   Summary: 14-dayweatherforecast forTokyo.BBCWeatherinassociation with MeteoGroup All times are Japan Standard Time (Asia/Tokyo, GMT+9) unless otherwise stated.\\n\\n5. Tokyo, Japan Weather Forecast\\n   URL: https://www.weather-forecast.com/locations/Tokyo-1/forecasts/latest\\n   Summary: 12 dayTokyo, JapanWeatherForecast. LiveWeatherWarnings, hourlyweatherupdates. AccurateTokyoweathertoday, forecast for sun, rain, wind and temperature.\\n\\n6. Weather in Tokyo, Japan - 7-Day Forecast & Live Conditions\\n   URL: https://weather.now/jp/tokyo\\n   Summary: Get the latestweatherforecast forTokyo, Japan. View live conditions, a 7-day forecast, hourly updates, air quality index, and more.\\n\\n7. Tokyo, 13, JP 14 Days Weather - The Weather Network\\n   URL: https://www.theweathernetwork.com/en/city/jp/tokyo/tokyo/14-days\\n   Summary: Tokyo, 13, JP temperature trend for the next 14 Days. Find daytime highs and nighttime lows from TheWeatherNetwork.com.\\n\\n8. Tokyo Weather - Tokyo, JP\\n   URL: https://www.worldweatheronline.com/tokyo-weather/tokyo/jp.aspx\\n   Summary: LatestweatherinTokyo,Tokyo, Japan for today, tomorrow and the next 14 days. Get hourlyweatherup to 14 days, meteograms, radar maps, historicalweather, FAQ andweatheraverages.\\n\\n9. Tokyo Prefecture, Tokyo Prefecture, Japan Weather - The Weather Channel\\n   URL: https://weather.com/en-NA/weather/tenday/l/Tokyo+Prefecture+Tokyo+Prefecture+Japan?placeId=ed4da556fdab676b346a10ebd9a8fc2b2f612e1194009a72350620a6ee6dfae8\\n   Summary: Be prepared with the most accurate 10-day forecast forTokyoPrefecture,TokyoPrefecture, Japan with highs, lows, chance of precipitation from TheWeatherChannel andWeather.com\\n\\n10. Tokyo, Japan 10-Day Weather Forecast | Weather Underground\\n   URL: https://www.wunderground.com/forecast/jp/tokyo\\n   Summary: TokyoWeatherForecasts.WeatherUnderground provides local & long-rangeweatherforecasts, weatherreports, maps & tropicalweatherconditions for theTokyoarea.\\n\", tool_call_id='pyd_ai_ce50e96df43c4aa5873472a9a0bb99b3', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 48, 882880, tzinfo=datetime.timezone.utc))], instructions='You are a helpful assistant that can use the DuckDuckGo MCP server to search the web and obtain current information, you always search first and then fetch the content of the search results you think are relevant to the question, finally you answer the question based on the content of the search results'))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[ToolCallPart(tool_name='fetch_content', args={'url': 'https://www.accuweather.com/en/jp/tokyo/226396/weather-forecast/226396'}, tool_call_id='pyd_ai_9f3109e784dd48b89790573f8a3f8860')], usage=RequestUsage(input_tokens=1176, output_tokens=48, details={'text_prompt_tokens': 1176}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 49, 430130, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='iZW4aKK5HbnVz7IPzYyu6A4'))\n",
      "ModelRequestNode(request=ModelRequest(parts=[ToolReturnPart(tool_name='fetch_content', content='Tokyo, Tokyo, Japan Weather Forecast | AccuWeather Go Back For Business | Warnings Data Suite Forensics Advertising Superior Accuracy™ Tokyo, Tokyo 81°F Location Chevron down Location News Videos Use Current Location Recent Tokyo Tokyo 81° No results found. Try searching for a city, zip code or point of interest. settings Tokyo, Tokyo Weather Today WinterCast Local {stormName} Tracker Hourly Daily Radar MinuteCast® Monthly Air Quality Health & Activities Around the Globe Hurricane Tracker Severe Weather Radar & Maps News News & Features Astronomy Business Climate Health Recreation Sports Travel For Business Warnings Data Suite Forensics Advertising Superior Accuracy™ Video Today Hourly Daily Radar MinuteCast® Monthly Air Quality Health & Activities 2 Heavy Rain Advisory for Inundation Today\\'s Weather Thu, Sep 4 Cloudy, very humid and not as hot; occasional rain in the afternoon Hi: 83° Tonight: A thunderstorm around in the evening; otherwise, cloudy and very humid Lo: 77° Current Weather 4:22 AM 81°F RealFeel® 88° Light rain More Details Wind NNE 6 mph Wind Gusts 11 mph Air Quality Poor MINUTECAST™ Rain will continue for 48 min Now 5:22 AM Looking Ahead Thunderstorms, some heavy, Friday Tokyo Weather Radar Static Radar Temporarily Unavailable Thank you for your patience as we work to get everything up and running again. Refresh Page Clouds Temperature Hourly Weather Chevron left 5 AM 79° 20% 6 AM 80° 16% 7 AM 80° 7% 8 AM 81° 7% 9 AM 82° 6% 10 AM 83° 5% 11 AM 82° 5% 12 PM 81° 8% 1 PM 81° 55% 2 PM 81° 61% 3 PM 80° 49% 4 PM 80° 27% Chevron right 10-Day Weather Forecast Today 9/4 83° 77° Humid; a little p.m. rain Night: Humid; a t-storm around early 75% Fri 9/5 81° 75° Heavy afternoon thunderstorms A few evening showers; humid 98% Sat 9/6 88° 75° Partly sunny and humid Partly cloudy and humid 1% Sun 9/7 91° 77° Humid; breezy in the p.m. Clear, warm and very humid 2% Mon 9/8 95° 79° Mostly sunny, hot and humid Humid; a shower in spots late 6% Tue 9/9 91° 77° Partly sunny, hot and humid Mainly clear, warm and humid 25% Wed 9/10 79° 69° Not as warm; a p.m. t-storm Some rain and a thunderstorm 55% Thu 9/11 78° 70° Cloudy with a stray t-storm Some rain and a t-storm late 55% Fri 9/12 78° 70° A couple of morning showers Humid with a bit of rain 57% Sat 9/13 88° 74° Very warm with rain Humid with periods of rain 65% Sun & Moon 12 hrs 51 mins Rise 5:14 AM Set 6:05 PM Waxing Gibbous Rise 4:08 PM Set 2:00 AM Air Quality See More Air Quality Poor The air has reached a high level of pollution and is unhealthy for sensitive groups. Reduce time spent outside if you are feeling symptoms such as difficulty breathing or throat irritation. Allergy Outlook See All Dust & Dander Extreme Data is not supported in this location Top Stories Hurricane Hurricane Kiko to impact Hawaii with wind, rain before mid-September 44 minutes ago Weather Forecasts Fall foliage 2025: Where to expect the best color 8 hours ago Weather News October-like chill to grip central US, cause temperatures to tumble 56 minutes ago Hurricane Tropical activity to ramp up before peak of Atlantic hurricane season 41 minutes ago Astronomy 85% of world population may see total lunar eclipse on Sunday 1 day ago More Stories Featured Stories Weather News At least 1,400 killed as earthquake rocks eastern Afghanistan 9 hours ago Recreation Powerball win or a lightning strike: Which has better odds? 6 hours ago Weather News Scientists have created rechargeable, multicolored, glow-in-the-dark s... 4 hours ago Weather News How the iconic Titanic discovery unfolded 1 day ago Live Blog Clearing the air: Leaves are falling but it\\'s not autumn yet LATEST ENTRY Why are there so many leaves falling? Is this an early autumn? 6 days ago World Asia Japan Tokyo Tokyo Weather Near Tokyo: Funabashi-shi, Chiba Hachioji-shi, Tokyo Kawasaki-shi, Kanagawa Company Proven Superior Accuracy™ About AccuWeather Digital Advertising Careers Press Contact Us Products & Services For Business For Partners For Advertising AccuWeather APIs AccuWeather Connect RealFeel® and RealFeel Shade™ Personal Weather Stations Apps & Downloads iPhone App Android App See all Apps & Downloads Subscription Services AccuWeather Premium AccuWeather Professional More AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Company Proven Superior Accuracy™ About AccuWeather Digital Advertising Careers Press Contact Us Products & Services For Business For Partners For Advertising AccuWeather APIs AccuWeather Connect RealFeel® and RealFeel Shade™ Personal Weather Stations Apps & Downloads iPhone App Android App See all Apps & Downloads Subscription Services AccuWeather Premium AccuWeather Professional More AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News © 2025 AccuWeather, Inc. \"AccuWeather\" and sun design are registered trademarks of AccuWeather, Inc. All Rights Reserved. Terms of Use | Privacy Policy | Cookie Policy | About Your Privacy Do Not Sell or Share My Personal Information ... ... ... ... ...', tool_call_id='pyd_ai_9f3109e784dd48b89790573f8a3f8860', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 50, 478680, tzinfo=datetime.timezone.utc))], instructions='You are a helpful assistant that can use the DuckDuckGo MCP server to search the web and obtain current information, you always search first and then fetch the content of the search results you think are relevant to the question, finally you answer the question based on the content of the search results'))\n",
      "CallToolsNode(model_response=ModelResponse(parts=[TextPart(content='The weather in Tokyo, Japan, as of 4:22 AM, is 81°F with light rain and a RealFeel® of 88°. Wind is from the NNE at 6 mph with gusts up to 11 mph. The air quality is poor.\\n\\nThe forecast for today, September 4th, is cloudy, very humid, and not as hot, with occasional rain in the afternoon, reaching a high of 83°. Tonight, there will be a thunderstorm around in the evening, otherwise cloudy and very humid, with a low of 77°. Rain is expected to continue for the next 48 minutes. Thunderstorms, some heavy, are expected on Friday.')], usage=RequestUsage(input_tokens=2551, cache_read_tokens=873, output_tokens=147, details={'cached_content_tokens': 873, 'text_prompt_tokens': 2551, 'text_cache_tokens': 873}), model_name='gemini-2.5-flash', timestamp=datetime.datetime(2025, 9, 3, 19, 22, 53, 938026, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='jZW4aPW7PPDhz7IP9anLwQo'))\n",
      "End(data=FinalResult(output='The weather in Tokyo, Japan, as of 4:22 AM, is 81°F with light rain and a RealFeel® of 88°. Wind is from the NNE at 6 mph with gusts up to 11 mph. The air quality is poor.\\n\\nThe forecast for today, September 4th, is cloudy, very humid, and not as hot, with occasional rain in the afternoon, reaching a high of 83°. Tonight, there will be a thunderstorm around in the evening, otherwise cloudy and very humid, with a low of 77°. Rain is expected to continue for the next 48 minutes. Thunderstorms, some heavy, are expected on Friday.'))\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "ddg_server = MCPServerStdio(  \n",
    "    'uvx',\n",
    "    args=[\n",
    "        'duckduckgo-mcp-server',\n",
    "    ]\n",
    ")\n",
    "mcp_agent = Agent(settings.MODEL_NAME, toolsets=[ddg_server], \n",
    "                  instructions=\"You are a helpful assistant that can use the DuckDuckGo MCP server to search the web and obtain current information, you always search first and then fetch the content of the search results you think are relevant to the question, finally you answer the question based on the content of the search results\")  \n",
    "# Run the Agent\n",
    "async with mcp_agent:  \n",
    "    nodes = []\n",
    "    async with mcp_agent.iter(\n",
    "        \"What is the weather in Tokyo?\",\n",
    "    ) as agent_run:\n",
    "        async for node in agent_run:\n",
    "            # Each node represents a step in the agent's execution\n",
    "            print(node)\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80907e",
   "metadata": {},
   "source": [
    "# Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7fe5be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Tokyo, Japan, as of 4:22 AM, is 81°F with light rain and a RealFeel® of 88°. Wind is from the NNE at 6 mph with gusts up to 11 mph. The air quality is poor.\n",
      "\n",
      "The forecast for today, September 4th, is cloudy, very humid, and not as hot, with occasional rain in the afternoon, reaching a high of 83°. Tonight, there will be a thunderstorm around in the evening, otherwise cloudy and very humid, with a low of 77°. Rain is expected to continue for the next 48 minutes. Thunderstorms, some heavy, are expected on Friday.\n"
     ]
    }
   ],
   "source": [
    "print(nodes[-1].data.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60cab2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the fundamentals of creating AI agents using Pydantic AI:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Simple Agents**: Created basic agents that can generate text responses with customizable instructions\n",
    "2. **Structured Output**: Used Pydantic models to ensure agents return well-formatted, typed data instead of plain text\n",
    "3. **Dependencies**: Implemented stateful agents that can maintain context (like previous jokes) between interactions\n",
    "4. **Tool Integration**: Built agents that can use external tools (random number generation, joke creation) to perform complex tasks\n",
    "5. **MCP Integration**: Connected agents to external services through Model Context Protocol (MCP) servers:\n",
    "   - **API MCPs**: Used Context7 for code documentation and library search\n",
    "   - **Command MCPs**: Used DuckDuckGo for real-time web search and content fetching\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "- Pydantic AI makes it easy to build reliable agents with structured outputs\n",
    "- Dependencies allow agents to maintain state and context across interactions\n",
    "- Tools enable agents to perform actions beyond text generation\n",
    "- MCP servers provide a standardized way to connect agents to external services\n",
    "- Agents can automatically chain tool calls to complete complex, multi-step tasks\n",
    "\n",
    "This foundation prepares us for building more sophisticated agent architectures in the following notebooks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
