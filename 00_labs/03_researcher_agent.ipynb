{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49911226",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "The goal of this notebook is to create a researcher agent that uses MCPs to search the web for information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba38f2",
   "metadata": {},
   "source": [
    "# Define Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c41085",
   "metadata": {},
   "source": [
    "We define the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc2558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "import os\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY: str\n",
    "    MODEL_NAME: str\n",
    "    CONTEXT7_API_KEY: str\n",
    "    TAVILY_API_KEY: str\n",
    "    class Config:\n",
    "        #ignore extra fields\n",
    "        extra = \"ignore\"\n",
    "        env_file = \".env\"\n",
    "\n",
    "settings = Settings()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = settings.GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905b32a",
   "metadata": {},
   "source": [
    "# Outline from our planner agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904d8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = \"\"\"# Report Outline: Creating Agents with Pydantic-AI\n",
    "\n",
    "## 1. Summary\n",
    "*   Brief overview of AI agents and the critical role of data validation.\n",
    "*   Introduction to Pydantic as a solution for robust agent development.\n",
    "*   Key benefits and applications of Pydantic in various agent architectural components.\n",
    "\n",
    "## 2. Introduction\n",
    "*   **2.1. What are AI Agents?**\n",
    "    *   Definition, characteristics, and common use cases (e.g., autonomous systems, chatbots, data processing agents).\n",
    "    *   Components of an AI agent (perception, deliberation, action).\n",
    "*   **2.2. The Growing Need for Data Validation in AI Systems**\n",
    "    *   Challenges with unstructured and untrustworthy data inputs/outputs in agent interactions.\n",
    "    *   Risks of invalid data (runtime errors, unexpected behavior, security vulnerabilities, incorrect decisions).\n",
    "    *   Why traditional validation methods fall short in complex AI scenarios.\n",
    "*   **2.3. Introducing Pydantic-AI**\n",
    "    *   Brief introduction to Pydantic and its core value proposition (data parsing, validation, and settings management).\n",
    "    *   Why Pydantic is a natural fit for building reliable AI agents.\n",
    "\n",
    "## 3. Pydantic Fundamentals for Agent Creation\n",
    "*   **3.1. Data Models for Agent State and Communication**\n",
    "    *   **3.1.1. Defining Agent State:** Using `BaseModel` to define internal states, beliefs, and goals.\n",
    "    *   **3.1.2. Input/Output Schemas:** Structuring data for agent-to-agent communication, tool calls, and LLM prompts/responses.\n",
    "    *   **3.1.3. Type Hinting and Enforceability:** How Pydantic leverages Python type hints for clarity and validation.\n",
    "*   **3.2. Settings Management with Pydantic BaseSettings**\n",
    "    *   **3.2.1. Agent Configuration:** Managing API keys, model parameters, and other environment-dependent settings.\n",
    "    *   **3.2.2. Loading from Environment Variables, .env files, etc.:** Seamless configuration loading.\n",
    "*   **3.3. Validation and Error Handling**\n",
    "    *   **3.3.1. Automatic Data Validation:** How Pydantic validates data upon instantiation.\n",
    "    *   **3.3.2. Handling Validation Errors:** `ValidationError` and strategies for graceful error recovery in agents.\n",
    "    *   **3.3.3. Customizing Error Messages:** Providing clear feedback for debugging.\n",
    "\n",
    "## 4. Applying Pydantic in Agent Architectures\n",
    "*   **4.1. Defining Tools and Action Schemas**\n",
    "    *   **4.1.1. Tool Definition:** Using Pydantic models to define the input parameters and expected output of agent tools (e.g., API calls, database queries).\n",
    "    *   **4.1.2. OpenAPI/JSON Schema Generation:** Leveraging Pydantic to automatically generate schemas for tool descriptions, useful for LLM integration.\n",
    "    *   **4.1.3. Function Calling with LLMs:** How Pydantic schemas facilitate structured function calls from LLMs.\n",
    "*   **4.2. Managing Memory and Context**\n",
    "    *   **4.2.1. Structuring Conversational History:** Defining models for messages, turns, and conversation summaries.\n",
    "    *   **4.2.2. Persistent Memory Storage:** Using Pydantic for serializing/deserializing agent memory components to/from databases or files.\n",
    "    *   **4.2.3. Contextual Information:** Modeling external data sources or user profiles relevant to agent operations.\n",
    "*   **4.3. Interacting with Large Language Models (LLMs)**\n",
    "    *   **4.3.1. Prompt Engineering with Structured Outputs:** Guiding LLMs to produce Pydantic-valid JSON outputs.\n",
    "    *   **4.3.2. Parsing LLM Responses:** Robustly parsing and validating LLM-generated text into structured Pydantic objects.\n",
    "    *   **4.3.3. Handling Malformed LLM Outputs:** Strategies for re-prompting or error recovery when LLM outputs fail validation.\n",
    "\n",
    "## 5. Advanced Pydantic Features for Agents\n",
    "*   **5.1. Custom Validators and Root Validators**\n",
    "    *   **5.1.1. Field-level Validation:** Implementing specific validation logic for individual fields.\n",
    "    *   **5.1.2. Model-level (Root) Validation:** Cross-field validation for complex interdependencies within an agent's state or actions.\n",
    "*   **5.2. Generics for Flexible Agent Components**\n",
    "    *   **5.2.1. Building Reusable Components:** Creating generic tool interfaces, memory structures, or agent templates.\n",
    "    *   **5.2.2. Adapting to Different Agent Types:** How generics allow for more adaptable and extensible agent designs.\n",
    "*   **5.3. Serialization and Deserialization for Persistence**\n",
    "    *   **5.3.1. `model_dump()` and `model_validate()`:** Efficiently converting agent states to and from JSON/dictionaries.\n",
    "    *   **5.3.2. Saving and Loading Agent Snapshots:** Persisting agent progress, memory, and configurations.\n",
    "\n",
    "## 6. Conclusion\n",
    "*   **6.1. Recap of Benefits:** Reinforcing how Pydantic enhances agent reliability, maintainability, and development speed.\n",
    "*   **6.2. Future Directions:** Potential for Pydantic in emergent agent architectures, multi-agent systems, and ethical AI development.\n",
    "*   **6.3. Final Thoughts:** Encouraging the adoption of robust data validation practices in AI agent creation.\n",
    "\n",
    "## 7. References\n",
    "*   [Placeholder for academic papers, articles, official Pydantic documentation, relevant AI agent frameworks, etc.]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574e86f",
   "metadata": {},
   "source": [
    "## Define Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120a779",
   "metadata": {},
   "source": [
    "We define the Agent with the Data models, MPC Server and Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "\n",
    "tavily_server = MCPServerStreamableHTTP(\n",
    "    url =f'https://mcp.tavily.com/mcp/?tavilyApiKey={settings.TAVILY_API_KEY}'\n",
    ")\n",
    "\n",
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"The title/subtitle of the section\")\n",
    "    content: str = Field(description=\"The content of the section, that answers the title of the section\")\n",
    "    references: str = Field(description=\"The references of the section, that are used to answer the title of the section\")\n",
    "\n",
    "\n",
    "class documentationOutput(BaseModel):\n",
    "    sections: list[Section] = Field(description=\"The sections of the report, that are used to answer the outline\")\n",
    "    \n",
    "\n",
    "mcp_agent = Agent(settings.MODEL_NAME, toolsets=[tavily_server], \n",
    "instructions=\"\"\"You are a helpful AI assistant tasked with getting content for a comprehensive report based on a given outline. Your goal is to research and compile current information for each section and subsection of the outline using the Tavily MCP server. Follow these steps to complete the task:\n",
    "\n",
    "1. Review the provided outline\n",
    "\n",
    "2. For each section and subsection in the outline:\n",
    "   a. Use the Tavily MCP server to search for current information related to the topic.\n",
    "   b. Review the search results and identify the most relevant and reliable sources.\n",
    "   c. After fetching the content, analyze and summarize the information relevant to the outline section.\n",
    "\n",
    "3. Write the report section by section, following the structure of the outline. For each section:\n",
    "   a. Provide a brief introduction to the topic.\n",
    "   b. Include relevant information gathered from your research.\n",
    "   c. Ensure that the content is well-organized and flows logically.\n",
    "   d. Use appropriate transitions between subsections and main sections.\n",
    "\n",
    "4. Throughout the writing process, keep track of the sources you've used. For each source, note:\n",
    "   - The title of the webpage or article\n",
    "   - The author (if available)\n",
    "   - The website name\n",
    "   - The URL\n",
    "   - The date you accessed the information\n",
    "\"\"\",\n",
    "    output_type=documentationOutput\n",
    ")\n",
    "# Run the Researcher Agent\n",
    "async with mcp_agent:  \n",
    "    nodes = []\n",
    "    async with mcp_agent.iter(\n",
    "        f\"The outline of the report is: {outline}\",\n",
    "    ) as agent_run:\n",
    "        async for node in agent_run:\n",
    "            # Each node represents a step in the agent's execution\n",
    "            print(node)\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e65ca3",
   "metadata": {},
   "source": [
    "# Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ab6a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sections\": [\n",
      "        {\n",
      "            \"title\": \"1. Summary\",\n",
      "            \"content\": \"AI agents are autonomous software programs that can perceive their environment, make decisions, and act to achieve specific goals. As these agents become more integrated into critical applications, ensuring the reliability and integrity of the data they process is paramount. Data validation is the practice of ensuring that data is accurate, consistent, and well-structured. Pydantic is a Python library for data validation and settings management that has become a cornerstone for building robust and reliable AI agents. It provides a simple and intuitive way to define data schemas using Python type hints, which are then used to validate, serialize, and deserialize data. The key benefits of using Pydantic in AI agent development include improved reliability, faster development cycles, and enhanced maintainability. Pydantic's applications span various architectural components of AI agents, from defining the agent's internal state and communication protocols to managing configurations and validating inputs and outputs of tools and large language models (LLMs).\",\n",
      "            \"references\": \"- https://www.schneier.com/blog/archives/2025/08/ai-agents-need-data-integrity.html\\n- https://github.com/pydantic/pydantic-ai\\n- https://aws.amazon.com/what-is/ai-agents/\\n- https://pydantic.dev/articles/hugging-face-inference-providers-in-pydantic-ai\\n- https://ai.dogas.info/pydantic-ai/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"2. Introduction\",\n",
      "            \"content\": \"This section provides a foundational understanding of AI agents, the critical need for data validation in AI systems, and an introduction to Pydantic as a solution.\",\n",
      "            \"references\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"2.1. What are AI Agents?\",\n",
      "            \"content\": \"An AI agent is a software entity that can perceive its environment through sensors, process the information, and act upon that environment through actuators to achieve a specific goal. Key characteristics of AI agents include autonomy (acting without direct human control), reactivity (responding to changes in the environment), and proactiveness (initiating actions to achieve goals). Common use cases for AI agents include:\\n\\n*   **Autonomous Systems:** Self-driving cars, drones, and robots.\\n*   **Chatbots and Virtual Assistants:** Customer service bots, personal assistants.\\n*   **Data Processing Agents:** Automated data cleaning, analysis, and reporting.\\n\\nThe core components of an AI agent are:\\n\\n*   **Perception:** The ability to gather information from the environment.\\n*   **Deliberation:** The process of reasoning and decision-making based on the perceived information and the agent's goals.\\n*   **Action:** The execution of the chosen action to interact with the environment.\",\n",
      "            \"references\": \"- https://www.conductor.com/academy/ai-agent/\\n- https://www.softwebsolutions.com/resources/what-are-ai-agents.html\\n- https://aws.amazon.com/what-is/ai-agents/\\n- https://www.designveloper.com/blog/ai-agent-architecture-diagram/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"2.2. The Growing Need for Data Validation in AI Systems\",\n",
      "            \"content\": \"AI agents often operate with unstructured and untrustworthy data from various sources, such as user inputs, external APIs, and sensors. This presents significant challenges, as invalid data can lead to a range of problems:\\n\\n*   **Runtime Errors:** Malformed data can cause the agent to crash or behave unexpectedly.\\n*   **Unexpected Behavior:** Incorrect data can lead to flawed decision-making and actions.\\n*   **Security Vulnerabilities:** Maliciously crafted inputs can be used to exploit vulnerabilities in the agent's logic.\\n*   **Incorrect Decisions:** Inaccurate or incomplete data can result in poor or even harmful decisions.\\n\\nTraditional validation methods, such as simple type checking or regular expressions, often fall short in complex AI scenarios where data structures can be nested and interdependent.\",\n",
      "            \"references\": \"- https://kpmg.com/xx/en/our-insights/regulatory-insights/validating-ai-models.html\\n- https://www.simbo.ai/blog/best-practices-for-ensuring-data-quality-in-ai-integration-cleansing-validation-and-governance-frameworks-1856141/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"2.3. Introducing Pydantic-AI\",\n",
      "            \"content\": \"Pydantic is a Python library that uses type hints to validate data. Its core value proposition lies in its ability to parse, validate, and serialize data with minimal code. Pydantic is a natural fit for building reliable AI agents because it provides a declarative and expressive way to define data schemas, which can be used to validate the inputs and outputs of every component of the agent's architecture. This ensures that the agent is always operating on valid and predictable data, which significantly reduces the risk of errors and unexpected behavior.\",\n",
      "            \"references\": \"- https://github.com/pydantic/pydantic-ai\\n- https://medium.com/data-science-collective/building-a-data-analyst-agent-with-streamlit-and-pydantic-ai-step-by-step-guide-part-1-6403fd2ec243\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"3. Pydantic Fundamentals for Agent Creation\",\n",
      "            \"content\": \"This section explores the fundamental features of Pydantic that are most relevant to creating AI agents.\",\n",
      "            \"references\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"3.1. Data Models for Agent State and Communication\",\n",
      "            \"content\": \"Pydantic's `BaseModel` is the cornerstone for creating data models. In the context of AI agents, `BaseModel` can be used to define:\\n\\n*   **Agent State:** The agent's internal beliefs, goals, and knowledge can be represented as a Pydantic model, ensuring that the agent's state is always well-defined and consistent.\\n*   **Input/Output Schemas:**  Pydantic models can define the structure of data for communication between agents, tool calls, and interactions with LLMs. This ensures that all data exchanged between components is valid and conforms to the expected format.\\n*   **Type Hinting and Enforceability:** Pydantic leverages Python's standard type hints to define the data types of fields in a model. This not only improves code clarity and readability but also allows Pydantic to enforce these types at runtime, automatically validating and converting data as needed.\",\n",
      "            \"references\": \"- https://medium.com/data-science-collective/building-a-data-analyst-agent-with-streamlit-and-pydantic-ai-step-by-step-guide-part-1-6403fd2ec243/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"3.2. Settings Management with Pydantic BaseSettings\",\n",
      "            \"content\": \"Pydantic's `BaseSettings` provides a convenient way to manage application settings and secrets. For AI agents, this is useful for:\\n\\n*   **Agent Configuration:**  Managing API keys for external services, model parameters for LLMs, and other environment-dependent settings.\\n*   **Loading from Environment Variables, .env files, etc.:** `BaseSettings` can automatically load configuration from various sources, including environment variables and `.env` files, making it easy to configure agents for different environments (development, staging, production) without modifying the code.\",\n",
      "            \"references\": \"- https://www.vjoker.blog/2025/08/07/ai-application-development-frameworks/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"3.3. Validation and Error Handling\",\n",
      "            \"content\": \"Pydantic's validation capabilities are central to its value proposition.\\n\\n*   **Automatic Data Validation:** When an instance of a Pydantic model is created, the data is automatically validated against the defined schema. If the data is invalid, Pydantic raises a `ValidationError`.\\n*   **Handling Validation Errors:** The `ValidationError` provides detailed information about the validation errors, including the location of the error and a descriptive message. This allows developers to implement graceful error handling and recovery strategies in their agents.\\n*   **Customizing Error Messages:** Pydantic allows for the customization of error messages, which can be useful for providing more specific and helpful feedback for debugging and user interaction.\",\n",
      "            \"references\": \"- https://ai.pydantic.dev/api/agent/\\n- https://github.com/pydantic/pydantic-ai\\n- https://latenode.com/blog/11-open-source-ai-agent-frameworks-that-will-transform-your-development-2025-complete-guide\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"4. Applying Pydantic in Agent Architectures\",\n",
      "            \"content\": \"This section delves into how Pydantic can be applied to the various components of an AI agent's architecture.\",\n",
      "            \"references\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"4.1. Defining Tools and Action Schemas\",\n",
      "            \"content\": \"Pydantic is an excellent choice for defining the inputs and outputs of agent tools.\\n\\n*   **Tool Definition:** Pydantic models can be used to define the input parameters and expected output of an agent's tools, such as API calls or database queries. This ensures that tools are always called with the correct arguments and that their outputs are in the expected format.\\n*   **OpenAPI/JSON Schema Generation:** Pydantic can automatically generate OpenAPI and JSON Schema definitions from `BaseModel` classes. This is particularly useful for integrating with LLMs, as the generated schemas can be used to describe the available tools to the LLM.\\n*   **Function Calling with LLMs:**  The generated JSON schemas from Pydantic models can be used to enable structured function calling from LLMs. The LLM can be instructed to generate a JSON object that conforms to the schema, which can then be used to call the corresponding tool with the correct parameters.\",\n",
      "            \"references\": \"- https://latenode.com/blog/11-open-source-ai-agent-frameworks-that-will-transform-your-development-2025-complete-guide/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"4.2. Managing Memory and Context\",\n",
      "            \"content\": \"Pydantic can be used to manage the agent's memory and contextual information.\\n\\n*   **Structuring Conversational History:** Pydantic models can be used to define the structure of messages, turns, and conversation summaries, providing a consistent and validated representation of the conversational history.\\n*   **Persistent Memory Storage:** Pydantic's serialization capabilities make it easy to serialize and deserialize agent memory components to and from databases or files, allowing the agent to maintain its state across sessions.\\n*   **Contextual Information:** Pydantic models can be used to represent external data sources or user profiles that are relevant to the agent's operation, ensuring that this contextual information is always well-structured and valid.\",\n",
      "            \"references\": \"- https://www.reddit.com/r/LocalLLaMA/comments/1mvgw9k/diffmem_using_git_as_a_differential_memory/\\n- https://ai.dogas.info/pydantic-ai/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"4.3. Interacting with Large Language Models (LLMs)\",\n",
      "            \"content\": \"Pydantic is a powerful tool for interacting with LLMs.\\n\\n*   **Prompt Engineering with Structured Outputs:** By providing the LLM with the JSON schema of a Pydantic model, you can guide it to produce a structured JSON output that is guaranteed to be valid.\\n*   **Parsing LLM Responses:** Pydantic can be used to robustly parse and validate the JSON output from an LLM, converting it into a structured Pydantic object that can be easily accessed and manipulated.\\n*   **Handling Malformed LLM Outputs:** If the LLM's output fails to validate against the Pydantic schema, the `ValidationError` can be caught, and strategies for re-prompting the LLM or recovering from the error can be implemented.\",\n",
      "            \"references\": \"- https://pydantic.dev/articles/hugging-face-inference-providers-in-pydantic-ai\\n- https://towardsdatascience.com/generating-structured-outputs-from-llms/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"5. Advanced Pydantic Features for Agents\",\n",
      "            \"content\": \"This section explores some of Pydantic's more advanced features that can be leveraged for building sophisticated AI agents.\",\n",
      "            \"references\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"5.1. Custom Validators and Root Validators\",\n",
      "            \"content\": \"Pydantic allows for the implementation of custom validation logic.\\n\\n*   **Field-level Validation:** Custom validators can be defined for individual fields to implement specific validation logic that is not covered by the standard validators.\\n*   **Model-level (Root) Validation:** Root validators can be used to implement validation logic that depends on the values of multiple fields, allowing for the enforcement of complex interdependencies within the agent's state or actions.\",\n",
      "            \"references\": \"- https://stackoverflow.com/questions/79741947/pydantic-agent-the-agent-tool-toolset-decorator-does-not-work-on-top-of-method\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"5.2. Generics for Flexible Agent Components\",\n",
      "            \"content\": \"Pydantic's support for generics enables the creation of flexible and reusable agent components.\\n\\n*   **Building Reusable Components:** Generics can be used to create generic tool interfaces, memory structures, or agent templates that can be adapted to different types of agents and use cases.\\n*   **Adapting to Different Agent Types:** Generics allow for the development of more adaptable and extensible agent designs, as components can be designed to work with a variety of data types without sacrificing the benefits of static type checking and validation.\",\n",
      "            \"references\": \"- https://stackoverflow.com/questions/79741947/pydantic-agent-the-agent-tool-toolset-decorator-does-not-work-on-top-of-method\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"5.3. Serialization and Deserialization for Persistence\",\n",
      "            \"content\": \"Pydantic provides efficient mechanisms for serializing and deserializing data.\\n\\n*   **`model_dump()` and `model_validate()`:** The `model_dump()` method can be used to convert a Pydantic model into a dictionary or JSON object, while the `model_validate()` method can be used to create a Pydantic model from a dictionary or JSON object.\\n*   **Saving and Loading Agent Snapshots:** These serialization and deserialization capabilities are essential for persisting the agent's progress, memory, and configurations, allowing the agent to be stopped and restarted without losing its state.\",\n",
      "            \"references\": \"- https://stackoverflow.com/questions/79741947/pydantic-agent-the-agent-tool-toolset-decorator-does-not-work-on-top-of-method\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"6. Conclusion\",\n",
      "            \"content\": \"This section summarizes the key benefits of using Pydantic for AI agent development and discusses future directions.\",\n",
      "            \"references\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"6.1. Recap of Benefits\",\n",
      "            \"content\": \"Pydantic significantly enhances the reliability, maintainability, and development speed of AI agents. By enforcing data validation at every stage of the agent's operation, Pydantic helps to prevent runtime errors, unexpected behavior, and security vulnerabilities. The declarative and expressive nature of Pydantic models improves code clarity and maintainability, while the automatic validation and serialization capabilities accelerate the development process.\",\n",
      "            \"references\": \"- https://latenode.com/blog/11-open-source-ai-agent-frameworks-that-will-transform-your-development-2025-complete-guide/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"6.2. Future Directions\",\n",
      "            \"content\": \"Pydantic is well-positioned to play a crucial role in the future of AI agent development. As agent architectures become more complex and multi-agent systems become more prevalent, the need for robust data validation and communication protocols will only increase. Pydantic's ability to define clear and enforceable data schemas will be essential for ensuring the interoperability and reliability of these systems. Furthermore, in the context of ethical AI development, Pydantic can be used to define and enforce constraints on the agent's behavior and decision-making processes, helping to ensure that agents operate in a safe and responsible manner.\",\n",
      "            \"references\": \"- https://www.linkedin.com/pulse/ai-mlops-robotics-newsletter-116-sage-elliott-63mlc\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"6.3. Final Thoughts\",\n",
      "            \"content\": \"The adoption of robust data validation practices is essential for the development of reliable and trustworthy AI agents. Pydantic provides a powerful and easy-to-use tool for implementing these practices, and its use should be encouraged in all AI agent development projects. By embracing data validation from the outset, developers can build more robust, maintainable, and secure AI agents that are better equipped to handle the complexities of the real world.\",\n",
      "            \"references\": \"- https://latenode.com/blog/11-open-source-ai-agent-frameworks-that-will-transform-your-development-2025-complete-guide/\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"7. References\",\n",
      "            \"content\": \"- https://www.schneier.com/blog/archives/2025/08/ai-agents-need-data-integrity.html\\n- https://github.com/pydantic/pydantic-ai\\n- https://aws.amazon.com/what-is/ai-agents/\\n- https://pydantic.dev/articles/hugging-face-inference-providers-in-pydantic-ai\\n- https://ai.dogas.info/pydantic-ai/\\n- https://www.conductor.com/academy/ai-agent/\\n- https://www.softwebsolutions.com/resources/what-are-ai-agents.html\\n- https://www.designveloper.com/blog/ai-agent-architecture-diagram/\\n- https://kpmg.com/xx/en/our-insights/regulatory-insights/validating-ai-models.html\\n- https://www.simbo.ai/blog/best-practices-for-ensuring-data-quality-in-ai-integration-cleansing-validation-and-governance-frameworks-1856141/\\n- https://medium.com/data-science-collective/building-a-data-analyst-agent-with-streamlit-and-pydantic-ai-step-by-step-guide-part-1-6403fd2ec243/\\n- https://www.vjoker.blog/2025/08/07/ai-application-development-frameworks/\\n- https://ai.pydantic.dev/api/agent/\\n- https://latenode.com/blog/11-open-source-ai-agent-frameworks-that-will-transform-your-development-2025-complete-guide/\\n- https://www.reddit.com/r/LocalLLaMA/comments/1mvgw9k/diffmem_using-git-as-a-differential-memory/\\n- https://towardsdatascience.com/generating-structured-outputs-from-llms/\\n- https://stackoverflow.com/questions/79741947/pydantic-agent-the-agent-tool-toolset-decorator-does-not-work-on-top-of-method\\n- https://www.linkedin.com/pulse/ai-mlops-robotics-newsletter-116-sage-elliott-63mlc\",\n",
      "            \"references\": \"- https://www.schneier.com/blog/archives/2025/08/ai-agents-need-data-integrity.html\\n- https://github.com/pydantic/pydantic-ai\\n- https://aws.amazon.com/what-is/ai-agents/\\n- https://pydantic.dev/articles/hugging-face-inference-providers-in-pydantic-ai\\n- https://ai.dogas.info/pydantic-ai/\\n- https://www.conductor.com/academy/ai-agent/\\n- https://www.softwebsolutions.com/resources/what-are-ai-agents.html\\n- https://www.designveloper.com/blog/ai-agent-architecture-diagram/\\n- https://kpmg.com/xx/en/our-insights/regulatory-insights/validating-ai-models.html\\n- https://www.simbo.ai/blog/best-practices-for-ensuring-data-quality-in-ai-integration-cleansing-validation-and-governance-frameworks-1856141/\\n- https://medium.com/data-science-collective/building-a-data-analyst-agent-with-streamlit-and-pydantic-ai-step-by-step-guide-part-1-6403fd2ec243/\\n- https://www.vjoker.blog/2025/08/07/ai-application-development-frameworks/\\n- https://ai.pydantic.dev/api/agent/\\n- https://latenode.com/blog/11-open-source-ai-agent-frameworks-that-will-transform-your-development-2025-complete-guide/\\n- https://www.reddit.com/r/LocalLLaMA/comments/1mvgw9k/diffmem_using-git-as-a-differential-memory/\\n- https://towardsdatascience.com/generating-structured-outputs-from-llms/\\n- https://stackoverflow.com/questions/79741947/pydantic-agent-the-agent-tool-toolset-decorator-does-not-work-on-top-of-method\\n- https://www.linkedin.com/pulse/ai-mlops-robotics-newsletter-116-sage-elliott-63mlc\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nodes[-1].data.output.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7228ee71",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to create a **Researcher Agent** that transforms plans into comprehensive, well-researched content:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Plan-to-Content Pipeline**: Built an agent that takes a structured outline and systematically researches each section to create detailed content\n",
    "2. **Web Research Integration**: Used Tavily MCP server to perform real-time web searches and gather current information\n",
    "3. **Structured Content Generation**: Defined comprehensive Pydantic models (`Section`, `documentationOutput`) to ensure consistent, well-organized output\n",
    "4. **Systematic Research Process**: Implemented a methodical approach where the agent searches, analyzes, and synthesizes information for each outline section\n",
    "5. **Source Tracking**: Built-in reference management to track and cite sources used in the research process\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "- **Research Automation**: Agents can autonomously conduct systematic research following a predefined structure\n",
    "- **Information Synthesis**: AI agents can effectively gather, analyze, and synthesize information from multiple web sources\n",
    "- **Structured Documentation**: Pydantic models ensure that research outputs are consistently formatted and include proper citations\n",
    "- **Agent Specialization**: Research agents excel at focused, systematic information gathering tasks\n",
    "- **Quality Control**: The agent follows specific instructions to prioritize reliable sources and maintain research quality\n",
    "\n",
    "### The Research Process Demonstrated\n",
    "\n",
    "1. **Outline Analysis**: Agent reviews the provided plan/outline to understand research requirements\n",
    "2. **Systematic Search**: For each section, performs targeted web searches using relevant keywords\n",
    "3. **Source Evaluation**: Reviews search results to identify reliable and relevant sources\n",
    "4. **Content Synthesis**: Analyzes and summarizes information to create coherent section content\n",
    "5. **Reference Management**: Tracks and properly cites all sources used in the research\n",
    "\n",
    "### Agent Workflow Integration\n",
    "\n",
    "This researcher agent perfectly complements the planner agent from the previous notebook:\n",
    "- **Planner Agent**: Creates structured outlines and research plans\n",
    "- **Researcher Agent**: Executes the research plan and generates detailed content\n",
    "\n",
    "This demonstrates how specialized agents can work together in a pipeline to accomplish complex, multi-stage tasks - from planning to execution to content creation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
